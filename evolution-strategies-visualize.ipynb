{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evolution-strategies\n",
    "\n",
    "Copyright (c) 2019 Patrick Deubel\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in\n",
    "all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "THE SOFTWARE.\n",
    "\n",
    "evolution-strategies includes:\n",
    "\n",
    "evolution-strategies-starter\n",
    "Copyright (c) 2016 OpenAI (http://openai.com)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in\n",
    "all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "This notebook can be used to evaluate the data which was generated during the training. Provided the main folder of the experiment or multiple experiments to the `get_experiments()` folder and use the method `evaluate()` on experiments to evaluate.\n",
    "\n",
    "Still under construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import gym\n",
    "\n",
    "import pybullet, pybullet_envs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gym import wrappers\n",
    "from ipywidgets import Video\n",
    "import ipywidgets as widgets\n",
    "from multiprocessing import Pool, Process\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%javascript\n",
    "#IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Model\n",
    "\n",
    "Since we use a custom initializer and this gets serialized during the saving process of the model we need to pass it on when we load it again. Unfortunately with the issue of the background TensorFlow session when importing TensorFlow and multiprocessing we cannot define the initializer one time and use it here again. So we define it twice, one inside the create_model() function and here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load load-model.py\n",
    "def load_model(model_path):   \n",
    "    import tensorflow as tf\n",
    "\n",
    "    class Normc_initializer(tf.keras.initializers.Initializer):\n",
    "        def __init__(self, std=1.0):\n",
    "            self.std=std\n",
    "\n",
    "        def __call__(self, shape, dtype=None, partition_info=None):\n",
    "            out = np.random.randn(*shape).astype(np.float32)\n",
    "            out *= self.std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            return tf.constant(out)\n",
    "    \n",
    "    class ObservationNormalizationLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, ob_mean, ob_std, **kwargs):\n",
    "            self.ob_mean = ob_mean\n",
    "            self.ob_std = ob_std\n",
    "            super(ObservationNormalizationLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):\n",
    "            return tf.clip_by_value((x - self.ob_mean) / self.ob_std, -5.0, 5.0)\n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(ObservationNormalizationLayer, self).get_config()\n",
    "            base_config['ob_mean'] = self.ob_mean\n",
    "            base_config['ob_std'] = self.ob_std\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "        \n",
    "    class DiscretizeActionsUniformLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, num_ac_bins, adim, ahigh, alow, **kwargs):\n",
    "            self.num_ac_bins = num_ac_bins\n",
    "            self.adim = adim\n",
    "            # ahigh, alow are NumPy arrays when extracting from the environment, but when the model is loaded from a h5\n",
    "            # File they get initialised as a normal list, where operations like subtraction does not work, thereforce\n",
    "            # cast them explicitly\n",
    "            self.ahigh = np.array(ahigh)\n",
    "            self.alow = np.array(alow)\n",
    "            super(DiscretizeActionsUniformLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):            \n",
    "            # Reshape to [n x i x j] where n is dynamically chosen, i equals action dimension and j equals the number\n",
    "            # of bins\n",
    "            scores_nab = tf.reshape(x, [-1, self.adim, self.num_ac_bins])\n",
    "            # This picks the bin with the greatest value\n",
    "            a = tf.argmax(scores_nab, 2)\n",
    "            \n",
    "            # Then transform the interval from [0, num_ac_bins - 1] to [-1, 1] which equals alow and ahigh\n",
    "            ac_range_1a = (self.ahigh - self.alow)[None, :]\n",
    "            return 1. / (self.num_ac_bins - 1.) * tf.keras.backend.cast(a, 'float32') * ac_range_1a + self.alow[None, :]        \n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(DiscretizeActionsUniformLayer, self).get_config()\n",
    "            base_config['num_ac_bins'] = self.num_ac_bins\n",
    "            base_config['adim'] = self.adim\n",
    "            base_config['ahigh'] = self.ahigh\n",
    "            base_config['alow'] = self.alow\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "    \n",
    "    custom_objects = {'Normc_initializer' : Normc_initializer, \n",
    "                      'ObservationNormalizationLayer' : ObservationNormalizationLayer,\n",
    "                      'DiscretizeActionsUniformLayer' : DiscretizeActionsUniformLayer}\n",
    "    \n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "    except IOError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_evaluation(env, model, render=False, timestep_limit=None, random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "\n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    t = 0\n",
    "\n",
    "    ob = env.reset()\n",
    "    for _ in range(timestep_limit):\n",
    "        if render:\n",
    "            env.render()\n",
    "        ac = model.predict_on_batch(ob[None])[0]\n",
    "        try:\n",
    "            ob, rew, done, _ = env.step(ac)\n",
    "        except AssertionError:\n",
    "            # Is thrown when for example ac is a list which has at least one entry with NaN\n",
    "            raise \n",
    "            \n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    return np.array(rews, dtype=np.float32), t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x_value, x_label, y_value, y_label, y_std=None, config=None):\n",
    "    if config is not None:\n",
    "        print(json.dumps(config, indent=4))\n",
    "    plt.plot(x_value, y_value)\n",
    "    # Draw an area around the mean curve which represents the standard deviation\n",
    "    if y_std is not None:\n",
    "        plt.fill_between(x_value, y_value - y_std, y_value + y_std, alpha=0.5)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainingRun():\n",
    "    def __init__(self, save_directory, log, config, model_file_paths, evaluation=None, video_file=None):\n",
    "        self.save_directory = save_directory\n",
    "        self.log = log\n",
    "        self.config = config\n",
    "        \n",
    "        if not model_file_paths:\n",
    "            self.no_models = True\n",
    "            self.model_file_paths = None\n",
    "        else:\n",
    "            self.no_models = False\n",
    "            self.model_file_paths = [os.path.join(save_directory, model) for model in model_file_paths]\n",
    "            \n",
    "        if evaluation is not None:\n",
    "            self.no_evaluation = False\n",
    "            self.evaluation = evaluation\n",
    "            self.data = self.merge_log_eval()\n",
    "        else:\n",
    "            self.no_evaluation = True\n",
    "            self.evaluation = None\n",
    "            self.data = None\n",
    "            \n",
    "        if video_file is not None:\n",
    "            self.no_video = False\n",
    "        else:\n",
    "            self.no_video = True\n",
    "        self.video_file = video_file\n",
    "        \n",
    "        if self.log is None or self.config is None:\n",
    "            print(\"This TrainingRun is missing either the log file or the configuration file. It will not \"\n",
    "                 + \"work as expected.\")\n",
    "    \n",
    "    def merge_log_eval(self):\n",
    "        if self.log is not None and self.evaluation is not None:\n",
    "            return self.log.merge(self.evaluation[['Generation', 'Eval_Rew_Mean', 'Eval_Rew_Std', 'Eval_Len_Mean']],\n",
    "                           on='Generation')\n",
    "        return None\n",
    "        \n",
    "    def parse_generation_number(self, model_file_path):\n",
    "        try: \n",
    "            number = int(model_file_path.split('snapshot_')[-1].split('.h5')[0])\n",
    "            return number\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    def evaluate(self, force=False, eval_count=5, skip=None, save=False, delete_models=False):       \n",
    "        if not force:\n",
    "            if self.data is not None:\n",
    "                return self.data\n",
    "            \n",
    "        if self.no_models:\n",
    "            print(\"No models given for that training run, so no new evaluation is possible. You can still plot\" + \n",
    "                  \" your data if you have an evaluation.csv or log.csv.\")\n",
    "            return None\n",
    "            \n",
    "        head_row = ['Generation', 'Eval_per_Gen', 'Eval_Rew_Mean', 'Eval_Rew_Std', 'Eval_Len_Mean']   \n",
    "        \n",
    "        for i in range(eval_count):\n",
    "            head_row.append('Rew_' + str(i))\n",
    "            head_row.append('Len_' + str(i))\n",
    "\n",
    "        data = []\n",
    "        \n",
    "        results_list = []\n",
    "        pool = Pool(os.cpu_count())\n",
    "\n",
    "        for model_file_path in self.model_file_paths[::skip]:\n",
    "            results = []\n",
    "            gen = self.parse_generation_number(model_file_path)\n",
    "\n",
    "            for _ in range(eval_count):\n",
    "                results.append(pool.apply_async(func=self.run_model, args=(model_file_path,)))\n",
    "            results_list.append((results, gen))\n",
    "            \n",
    "        for (results, gen) in results_list:\n",
    "            for i in range(len(results)):\n",
    "                results[i] = results[i].get()\n",
    "                if results[i] == [None, None]:\n",
    "                    print(\"The provided model file produces non finite numbers. Stopping.\")\n",
    "                    return\n",
    "\n",
    "            rewards = np.array(results)[:, 0]\n",
    "            lengths = np.array(results)[:, 1]\n",
    "            \n",
    "            row = [gen,\n",
    "                   eval_count,\n",
    "                   np.mean(rewards),\n",
    "                   np.std(rewards),\n",
    "                   np.mean(lengths)]\n",
    "\n",
    "            assert len(rewards) == len(lengths)\n",
    "            for i in range(len(rewards)):\n",
    "                row.append(rewards[i])\n",
    "                row.append(lengths[i])\n",
    "\n",
    "            data.append(row)\n",
    "            \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        self.evaluation = pd.DataFrame(data, columns = head_row)\n",
    "        if save:\n",
    "            self.save_evaluation()\n",
    "        # Only copy the mean values in the merged data\n",
    "        self.data = self.merge_log_eval()\n",
    "        \n",
    "        if delete_models:\n",
    "            self.delete_model_files\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def delete_model_files(self, save_last=False):\n",
    "        if save_last:\n",
    "            self.model_file_paths = self.model_file_paths[:-1]\n",
    "        for model_file_path in self.model_file_paths:\n",
    "            os.remove(model_file_path)\n",
    "    \n",
    "    def plot_reward_timestep(self):\n",
    "        if self.data is not None:\n",
    "            plot(self.data.TimestepsSoFar, 'Timesteps', self.data.Eval_Rew_Mean, 'Cummulative reward')\n",
    "        else:\n",
    "            print(\"You did not evaluate these results. The evaluated mean reward displayed was computed during training\"\n",
    "                  + \"and can have missing values!\")\n",
    "            plot(self.log.TimestepsSoFar, 'Timesteps', self.log.EvalGenRewardMean, 'Cummulative reward')\n",
    "            \n",
    "    def save_evaluation(self):\n",
    "        if self.evaluation is not None:\n",
    "            self.evaluation.to_csv(os.path.join(self.save_directory, 'evaluation.csv'))\n",
    "            \n",
    "    def visualize(self, force=False):\n",
    "        if self.no_models:\n",
    "            # Error message in Experiment\n",
    "            return None\n",
    "        if not force:\n",
    "            if self.video_file is not None:\n",
    "                return self.video_file\n",
    "            \n",
    "        latest_model = self.model_file_paths[-1]\n",
    "\n",
    "        with Pool(os.cpu_count()) as pool:\n",
    "            pool.apply(func=self.run_model, args=(latest_model, True))\n",
    "\n",
    "        for file in os.listdir(self.save_directory):\n",
    "            if file.endswith('.mp4'):\n",
    "                self.video_file = os.path.join(self.save_directory, file)\n",
    "\n",
    "        return self.video_file\n",
    "    \n",
    "    def run_model(self, model_file_path, record=False):\n",
    "        env = gym.make(self.config['config']['env_id'])\n",
    "        env.reset()\n",
    "\n",
    "        if record:\n",
    "            env = wrappers.Monitor(env, self.save_directory, force=True)\n",
    "\n",
    "        model = load_model(model_file_path)\n",
    "\n",
    "        try:\n",
    "            rewards, length = rollout_evaluation(env, model)\n",
    "        except AssertionError:\n",
    "            # Is thrown when for example ac is a list which has at least one entry with NaN\n",
    "            return [None, None]\n",
    "\n",
    "        return [rewards.sum(), length]\n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self, config, training_runs):        \n",
    "        self.config = config\n",
    "        self.training_runs = training_runs\n",
    "        self.num_training_runs = len(self.training_runs)\n",
    "        self.mean_data = None\n",
    "        self.std_data = None\n",
    "        \n",
    "        self.runs_evaluated = True\n",
    "        for run in self.training_runs:\n",
    "            if run.no_evaluation:\n",
    "                self.runs_evaluated = False\n",
    "                \n",
    "        # Every run has already an evaluation, therefore initialize self.mean_data and self.std_data with it\n",
    "        if self.runs_evaluated is True:\n",
    "            self.evaluate()\n",
    "    \n",
    "    def evaluate(self, force=False, eval_count=5, skip=None, save=False, delete_models=False):\n",
    "        data = []\n",
    "        no_models = False\n",
    "        if not self.runs_evaluated:\n",
    "            for training_run in self.training_runs:\n",
    "                no_models = training_run.no_models\n",
    "                if no_models is True:\n",
    "                    break\n",
    "\n",
    "        if no_models:\n",
    "            print(\"The training runs do not provide model files, therefore the experiment cannot be evaluated.\" +\n",
    "                  \"Please provide at least one .h5 file.\")\n",
    "        else:\n",
    "            for training_run in self.training_runs:\n",
    "                d = training_run.evaluate(force, eval_count, skip, save, delete_models)\n",
    "                if d is None:\n",
    "                    return\n",
    "                data.append(d)\n",
    "            concatenated = pd.concat([d for d in data])\n",
    "            self.mean_data = concatenated.groupby(by='Generation', level=0).mean()\n",
    "            self.std_data = concatenated.groupby(by='Generation', level=0).std()\n",
    "                    \n",
    "    def visualize(self, force=False):\n",
    "        for run in self.training_runs:\n",
    "            self.video_file = run.visualize(force=force)\n",
    "            if self.video_file is not None:\n",
    "                break\n",
    "        if self.video_file is None:\n",
    "            print(\"The training runs do not provide model files, therefore the experiment cannot be visualized.\" +\n",
    "                  \"Please provide at least one .h5 file so a video can be recorded.\")\n",
    "        return self.video_file\n",
    "            \n",
    "    def delete_model_files(self, save_last=False):\n",
    "        for run in self.training_runs:\n",
    "            run.delete_model_files(save_last)\n",
    "    \n",
    "    def get_num_training_runs(self):\n",
    "        return self.num_training_runs\n",
    "    \n",
    "    def get_all_training_runs(self):\n",
    "        return [run for run in self.training_runs]\n",
    "        \n",
    "    def get_all_logs(self):\n",
    "        return [run.log for run in self.training_runs]\n",
    "    \n",
    "    def get_all_evaluations(self):\n",
    "        return [run.evaluation for run in self.training_runs]\n",
    "    \n",
    "    def print_config(self):\n",
    "        print(json.dumps(self.config, indent=4))\n",
    "    \n",
    "    def plot_reward_timestep(self):\n",
    "        if self.mean_data is None:\n",
    "            print(\"You did not evaluate the results. Please run evaluate() on this experiment. The plotted results\"\n",
    "                 + \" are used from the log file.\")\n",
    "            for run in self.training_runs:\n",
    "                run.plot_reward_timestep()\n",
    "        else:\n",
    "            y_std = None\n",
    "            # If we only have one training run the standard deviation will be NaN across all values and therefore\n",
    "            # not be plotted. Use standard deviation from the only evaluation we have\n",
    "            if self.num_training_runs > 1:\n",
    "                y_std = self.std_data.Eval_Rew_Mean\n",
    "            plot(self.mean_data.TimestepsSoFar, 'Timesteps', \n",
    "                      self.mean_data.Eval_Rew_Mean, 'Cummulative reward',\n",
    "                      y_std)\n",
    "            print(\"Displayed is the mean reward of {} different runs over timesteps with different random seeds.\" +\n",
    "                  \" If there was more than one run, the shaded region is the standard deviation of the mean reward.\")\n",
    "            \n",
    "    def plot_reward_generation(self):\n",
    "        if self.mean_data is None:\n",
    "            print(\"You did not evaluate the results. Please run evaluate() on this experiment.\")\n",
    "        else:\n",
    "            y_std = None\n",
    "            # If we only have one training run the standard deviation will be NaN across all values and therefore\n",
    "            # not be plotted. Use standard deviation from the only evaluation we have\n",
    "            if self.num_training_runs > 1:\n",
    "                y_std = self.std_data.Eval_Rew_Mean\n",
    "            plot(self.mean_data.Generation, 'Generation', \n",
    "                      self.mean_data.Eval_Rew_Mean, 'Cummulative reward',\n",
    "                      y_std)\n",
    "            print(\"Displayed is the mean reward of {} different runs over timesteps with different random seeds.\" +\n",
    "                  \" If there was more than one run, the shaded region is the standard deviation of the mean reward.\")\n",
    "    \n",
    "    def plot_timesteps_timeelapsed(self):\n",
    "        if self.mean_data is None:\n",
    "            print(\"You did not evaluate the results. Please run evaluate() on this experiment.\")\n",
    "        else:\n",
    "            y_std = None\n",
    "            # If we only have one training run the standard deviation will be NaN across all values and therefore\n",
    "            # not be plotted. Use standard deviation from the only evaluation we have\n",
    "            if self.num_training_runs > 1:\n",
    "                y_std = self.std_data.TimestepsSoFar\n",
    "            plot(self.mean_data.TimeElapsed, 'Time elapsed (s)', \n",
    "                      self.mean_data.TimestepsSoFar, 'Timesteps',\n",
    "                      y_std)\n",
    "            print(\"Displayed is the mean reward of {} different runs over timesteps with different random seeds.\" +\n",
    "                  \" If there was more than one run, the shaded region is the standard deviation of the mean reward.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiments(main_directory):\n",
    "    index = {}\n",
    "    for root, dirs, files in os.walk(main_directory):\n",
    "        if 'log.csv' in files and 'config.json' in files:\n",
    "            index[root] = files\n",
    "\n",
    "    training_runs = []\n",
    "    for sub_dir in index:\n",
    "        models, log, evaluation, config, video_file  = [], None, None, None, None\n",
    "        for file in index[sub_dir]:\n",
    "            if file.endswith('.h5'):\n",
    "                models.append(file)\n",
    "                continue\n",
    "            elif file.endswith('log.csv'):\n",
    "                try:\n",
    "                    log = pd.read_csv(os.path.join(sub_dir, file))\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(\"The log file {} is empty. Skipping this folder({}).\".format(\n",
    "                    file, sub_dir))\n",
    "                continue\n",
    "            elif file.endswith('evaluation.csv'):\n",
    "                try:\n",
    "                    evaluation = pd.read_csv(os.path.join(sub_dir, file))\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(\"The evaluation file {} is empty. Continuing.\".format(file))\n",
    "                continue\n",
    "            elif file.endswith('config.json'):\n",
    "                with open(os.path.join(sub_dir, file), encoding='utf-8') as f:\n",
    "                    try:\n",
    "                        config = json.load(f)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(\"The config file {} is empty or cannot be parsed. Skipping this folder ({}).\".format(\n",
    "                        file, sub_dir))\n",
    "                continue\n",
    "            elif file.endswith('.mp4'):\n",
    "                video_file = os.path.join(sub_dir, file)\n",
    "                continue\n",
    "        models.sort()\n",
    "        if log is not None and config is not None:\n",
    "            training_runs.append(TrainingRun(sub_dir, log, config, models, evaluation, video_file))\n",
    "\n",
    "    configs_and_runs = []\n",
    "    for run in training_runs:\n",
    "        found = False\n",
    "        for c in configs_and_runs:\n",
    "            if c[0] == run.config:\n",
    "                c[1].append(run)\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            configs_and_runs.append((run.config, [run]))\n",
    "            \n",
    "    return [Experiment(config, runs) for (config, runs) in configs_and_runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = '/home/jovyan/work/evolution-strategies/training_runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = get_experiments(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in experiments:\n",
    "    e.print_config()\n",
    "    e.plot_reward_timestep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in experiments:\n",
    "    for log in e.get_all_logs():\n",
    "        print(\"Timesteps overall\", log.TimestepsSoFar.iloc[-1])\n",
    "        print(\"Time elapsed\", log.TimeElapsed.iloc[-1])\n",
    "    e.plot_timesteps_timeelapsed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in experiments:\n",
    "    e.evaluate(force=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in experiments:\n",
    "    e.plot_reward_timestep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in experiments:\n",
    "    e.print_config()\n",
    "    for run in e.get_all_training_runs():\n",
    "        print(\"Max timesteps\", run.log.TimestepsSoFar.iloc[-1])\n",
    "        display(run.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = []\n",
    "for e in experiments:\n",
    "    video_files.append((e, e.visualize(force=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (e, v) in video_files:\n",
    "    e.print_config()\n",
    "    video = Video.from_file(v)\n",
    "    display(video)\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = widgets.Dropdown(\n",
    "    options=[\"{} {}\".format(e.config['config']['env_id'], e.config['config']['population_size']) for e in experiments],\n",
    "    description='Experiment:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def on_change_dropdown_exp(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        e = change['new']\n",
    "        print(e)\n",
    "\n",
    "w.observe(on_change_dropdown_exp)\n",
    "\n",
    "display(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
