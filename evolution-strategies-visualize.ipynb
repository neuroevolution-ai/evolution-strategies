{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import gym\n",
    "import roboschool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gym import wrappers\n",
    "from ipywidgets import Video\n",
    "from multiprocessing import Pool, Process\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Model\n",
    "\n",
    "Since we use a custom initializer and this gets serialized during the saving process of the model we need to pass it on when we load it again. Unfortunately with the issue of the background TensorFlow session when importing TensorFlow and multiprocessing we cannot define the initializer one time and use it here again. So we define it twice, one inside the create_model() function and here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):   \n",
    "    import tensorflow as tf\n",
    "\n",
    "    class Normc_initializer(tf.keras.initializers.Initializer):\n",
    "        \"\"\"\n",
    "        Create a TensorFlow constant with random numbers normed in the given shape.\n",
    "        :param std:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        def __init__(self, std=1.0):\n",
    "            self.std = std\n",
    "\n",
    "        def __call__(self, shape, dtype=None, partition_info=None):\n",
    "            out = np.random.randn(*shape).astype(np.float32)\n",
    "            out *= self.std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            return tf.constant(out)\n",
    "        \n",
    "    class ObservationNormalizationLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, ob_mean, ob_std, **kwargs):\n",
    "            self.ob_mean = ob_mean\n",
    "            self.ob_std = ob_std\n",
    "            super(ObservationNormalizationLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, input):\n",
    "            return tf.clip_by_value((input - self.ob_mean) / self.ob_std, -5.0, 5.0)\n",
    "          \n",
    "        def get_config(self):\n",
    "            base_config = super(ObservationNormalizationLayer, self).get_config()\n",
    "            base_config['ob_mean'] = self.ob_mean\n",
    "            base_config['ob_std'] = self.ob_std\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "        \n",
    "    class DiscretizeActionsUniformLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, num_ac_bins, adim, ahigh, alow, **kwargs):\n",
    "            self.num_ac_bins = num_ac_bins\n",
    "            self.adim = adim\n",
    "            self.ahigh = ahigh\n",
    "            self.alow = alow\n",
    "            super(DiscretizeActionsUniformLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):            \n",
    "            # Reshape to [n x i x j] where n is dynamically chosen, i equals action dimension and j equals the number\n",
    "            # of bins\n",
    "            scores_nab = tf.reshape(x, [-1, self.adim, self.num_ac_bins])\n",
    "            # This picks the bin with the greatest value\n",
    "            a = tf.argmax(scores_nab, 2)\n",
    "            \n",
    "            # Then transform the interval from [0, num_ac_bins - 1] to [-1, 1] which equals alow and ahigh\n",
    "            ac_range_1a = (self.ahigh - self.alow)[None, :]\n",
    "            return 1. / (self.num_ac_bins - 1.) * tf.keras.backend.cast(a, 'float32') * ac_range_1a + self.alow[None, :]        \n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(DiscretizeActionsUniformLayer, self).get_config()\n",
    "            base_config['num_ac_bins'] = self.num_ac_bins\n",
    "            base_config['adim'] = self.adim\n",
    "            base_config['ahigh'] = self.ahigh\n",
    "            base_config['alow'] = self.alow\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "    \n",
    "    custom_objects = {'Normc_initializer' : Normc_initializer, \n",
    "                      'ObservationNormalizationLayer' : ObservationNormalizationLayer,\n",
    "                      'DiscretizeActionsUniformLayer' : DiscretizeActionsUniformLayer}\n",
    "    \n",
    "    return tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "\n",
    "def rollout(env, model, render=False, timestep_limit=None, random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "\n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    t = 0\n",
    "\n",
    "    ob = env.reset()\n",
    "    for _ in range(timestep_limit):\n",
    "        if render:\n",
    "            env.render()\n",
    "        ac = act(ob[None], model, random_stream=random_stream)[0]\n",
    "        ob, rew, done, _ = env.step(ac)\n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    return np.array(rews, dtype=np.float32), t\n",
    "\n",
    "def act(ob, model, random_stream=None):   \n",
    "    action = model.predict_on_batch(ob)\n",
    "    \n",
    "    #if random_stream is not None and model_structure.ac_noise_std != 0:\n",
    "    #    action += random_stream.randn(*action.shape) * model_structure.ac_noise_std\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(env_id, save_directory, model_file_path, record=False):\n",
    "    env = gym.make(env_id)\n",
    "    env.reset()\n",
    "    \n",
    "    if record:\n",
    "        video_directory = os.path.join(save_directory, 'videos/')\n",
    "        env = wrappers.Monitor(env, video_directory, force=True)\n",
    "        \n",
    "    model = load_model(model_file_path)\n",
    "    \n",
    "    rewards, length = rollout(env, model)\n",
    "    \n",
    "    if record:\n",
    "        return video_directory\n",
    "    \n",
    "    return [rewards.sum(), length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainingRun():\n",
    "    def __init__(self, save_directory, log, config, model_file_paths, evaluation=None):\n",
    "        self.save_directory = save_directory\n",
    "        self.log = log\n",
    "        self.config = config\n",
    "        self.model_file_paths = [os.path.join(save_directory, model) for model in model_file_paths]\n",
    "        if evaluation is not None:\n",
    "            self.evaluation = evaluation\n",
    "            self.data = self.merge_log_eval()\n",
    "        else:\n",
    "            self.evaluation = None\n",
    "            self.data = None\n",
    "        self.video = None\n",
    "        self.video_file = None\n",
    "    \n",
    "    def merge_log_eval(self):\n",
    "        if self.log is not None and self.evaluation is not None:\n",
    "            return self.log.merge(self.evaluation[['Generation', 'Eval_Rew_Mean', 'Eval_Rew_Std', 'Eval_Len_Mean']],\n",
    "                           on='Generation')     #.set_index('Generation')\n",
    "        return None\n",
    "        \n",
    "    def parse_generation_number(self, model_file_path):\n",
    "        try: \n",
    "            number = int(model_file_path.split('snapshot_')[-1].split('.h5')[0])\n",
    "            return number\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    def evaluate(self, force=False, eval_count=5, skip=None, save=False):\n",
    "        if not force:\n",
    "            if self.data is not None:\n",
    "                return self.data\n",
    "            \n",
    "        head_row = ['Generation', 'Eval_per_Gen', 'Eval_Rew_Mean', 'Eval_Rew_Std', 'Eval_Len_Mean']   \n",
    "        \n",
    "        for i in range(eval_count):\n",
    "            head_row.append('Rew_' + str(i))\n",
    "            head_row.append('Len_' + str(i))\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for model_file_path in self.model_file_paths[::skip]:\n",
    "            results = []\n",
    "            with Pool(os.cpu_count()) as pool:\n",
    "                for _ in range(eval_count):\n",
    "                    results.append(pool.apply_async(func=run_model, args=(self.config['config']['env_id'], \n",
    "                                                                          self.save_directory, \n",
    "                                                                          model_file_path)))\n",
    "\n",
    "                for i in range(len(results)):\n",
    "                    results[i] = results[i].get()\n",
    "\n",
    "            rewards = np.array(results)[:, 0]\n",
    "            lengths = np.array(results)[:, 1]\n",
    "\n",
    "            gen = self.parse_generation_number(model_file_path)\n",
    "            \n",
    "            row = [gen,\n",
    "                   eval_count,\n",
    "                   np.mean(rewards),\n",
    "                   np.std(rewards),\n",
    "                   np.mean(lengths)]\n",
    "\n",
    "            assert len(rewards) == len(lengths)\n",
    "            for i in range(len(rewards)):\n",
    "                row.append(rewards[i])\n",
    "                row.append(lengths[i])\n",
    "\n",
    "            data.append(row)\n",
    "\n",
    "        self.evaluation = pd.DataFrame(data, columns = head_row)\n",
    "        if save:\n",
    "            self.save_evaluation()\n",
    "        # Only copy the mean values in the merged data\n",
    "        self.data = self.merge_log_eval()\n",
    "        return self.data\n",
    "    \n",
    "    def plot_reward_timestep(self):\n",
    "        if self.data is not None:\n",
    "            self.plot(self.data.TimestepsSoFar, 'Timesteps', self.data.Eval_Rew_Mean, 'Cummulative reward')\n",
    "        else:\n",
    "            print(\"You did not evaluate these results. The evaluated mean reward displayed was computed during training\"\n",
    "                  + \"and can have missing values!\")\n",
    "            self.plot(self.log.TimestepsSoFar, 'Timesteps', self.log.EvalGenRewardMean, 'Cummulative reward')\n",
    "            \n",
    "    def plot(self, x_value, x_label, y_value, y_label):\n",
    "        plt.plot(x_value, y_value)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.show()\n",
    "    \n",
    "    def save_evaluation(self):\n",
    "        if self.evaluation is not None:\n",
    "            self.evaluation.to_csv(os.path.join(self.save_directory, 'evaluation.csv'))\n",
    "            \n",
    "    def visualize(self, force=False):\n",
    "        if not force:\n",
    "            if self.video is not None and self.video_file is not None:\n",
    "                return self.video\n",
    "            \n",
    "        if len(self.model_file_paths) < 1:\n",
    "            print(\"There are no model files indexed. You must provide at leas one .h5 file!\")\n",
    "            return\n",
    "        \n",
    "        latest_model = self.model_file_paths[-1]\n",
    "\n",
    "        with Pool(os.cpu_count()) as pool:\n",
    "            video_directory = pool.apply(func=run_model, args=(self.config['config']['env_id'],\n",
    "                                                               self.save_directory,\n",
    "                                                               latest_model,\n",
    "                                                               True))\n",
    "\n",
    "        for file in os.listdir(video_directory):\n",
    "            if file.endswith('.mp4'):\n",
    "                self.video_file = file\n",
    "                self.video = Video.from_file(os.path.join(video_directory, file))\n",
    "\n",
    "        return self.video\n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self, main_directory):\n",
    "        self.main_directory = main_directory\n",
    "        index = self.index_main_directory(main_directory)\n",
    "        self.training_runs = self.load_data(index)\n",
    "        self.num_training_runs = len(self.training_runs)\n",
    "        self.mean_data = None\n",
    "        self.std_data = None\n",
    "    \n",
    "    def evaluate(self, force=False, eval_count=5, skip=None, save=False):\n",
    "        data = []\n",
    "        for training_run in self.training_runs:\n",
    "            data.append(training_run.evaluate(force, eval_count, skip, save))\n",
    "        \n",
    "        concatenated = pd.concat([d for d in data])\n",
    "        self.mean_data = concatenated.groupby(by='Generation', level=0).mean()\n",
    "        self.std_data = concatenated.groupby(by='Generation', level=0).std()       \n",
    "    \n",
    "    def plot_reward_timestep(self):\n",
    "        if self.mean_data is None:\n",
    "            print(\"You did not evaluate the results. Please run evaluate() on this experiment.\")\n",
    "        else:\n",
    "            y_std = None\n",
    "            # If we only have one training run the standard deviation will be NaN across all values and therefore\n",
    "            # not be plotted. Use standard deviation from the only evaluation we have\n",
    "            if self.num_training_runs > 1:\n",
    "                y_std = self.std_data.Eval_Rew_Mean\n",
    "            self.plot(self.mean_data.TimestepsSoFar, 'Timesteps', \n",
    "                      self.mean_data.Eval_Rew_Mean, 'Cummulative reward',\n",
    "                      y_std)\n",
    "    \n",
    "    def plot(self, x_value, x_label, y_value, y_label, y_std=None):\n",
    "        plt.plot(x_value, y_value)\n",
    "        # Draw an area around the mean curve which represents the standard deviation\n",
    "        if y_std is not None:\n",
    "            plt.fill_between(x_value, y_value - y_std, y_value + y_std)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def index_main_directory(self, main_directory):\n",
    "        index = {}\n",
    "        for root, dirs, files in os.walk(main_directory):\n",
    "            if 'log.csv' in files and 'config.json' in files:\n",
    "                index[root] = files\n",
    "        return index\n",
    "    \n",
    "    def load_data(self, index):\n",
    "        training_runs = []\n",
    "        for sub_dir in index:\n",
    "            models, log, evaluation, config,  = [], None, None, None\n",
    "            for file in index[sub_dir]:\n",
    "                if file.endswith('.h5'):\n",
    "                    models.append(file)\n",
    "                elif file.endswith('log.csv'):\n",
    "                    log = pd.read_csv(os.path.join(sub_dir, file))\n",
    "                elif file.endswith('evaluation.csv'):\n",
    "                    evaluation = pd.read_csv(os.path.join(sub_dir, file))\n",
    "                elif file.endswith('config.json'):\n",
    "                    with open(os.path.join(sub_dir, file), encoding='utf-8') as f:\n",
    "                        config = json.load(f)\n",
    "            models.sort()\n",
    "            training_runs.append(TrainingRun(sub_dir, log, config, models, evaluation))\n",
    "\n",
    "        return training_runs\n",
    "    \n",
    "    def visualize(self, force=False):\n",
    "        if len(self.training_runs) > 0:\n",
    "            video = self.training_runs[-1].visualize(force=force)\n",
    "            return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = '/tmp/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Experiment(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.evaluate(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "video = e.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openaigym.video.0.3113.video000000.mp4'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.training_runs[-1].video_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.plot_reward_timestep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%javascript\n",
    "#IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import JSON\n",
    "for (log, config, _) in data:\n",
    "    print(json.dumps(config, indent=4))\n",
    "    #display(log)\n",
    "    %matplotlib inline\n",
    "\n",
    "    plt.plot(log.TimestepsSoFar, log.GenLenMean)\n",
    "    plt.xlabel('Timesteps')\n",
    "    plt.ylabel('Cummulative reward')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = model_file_paths[-1]\n",
    "video_file = visualize_model(save_directory, model_file_path, config_file)\n",
    "\n",
    "if video_file is not None:\n",
    "    video = Video.from_file(video_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
