{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"calc_obstat_prob\": 0.01,\n",
    "    \"episodes_per_batch\": 15,\n",
    "    \"eval_prob\": 0.003,\n",
    "    \"l2coeff\": 0.005,\n",
    "    \"noise_stdev\": 0.02,\n",
    "    \"snapshot_freq\": 1,\n",
    "    \"timesteps_per_batch\": 100000,\n",
    "    \"return_proc_mode\": \"centered_rank\",\n",
    "    \"episode_cutoff_mode\": \"env_default\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gym, roboschool # Roboschool import needed to register the environments within gym\n",
    "env = gym.make(\"RoboschoolInvertedPendulum-v1\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorflow Session"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Policy setup\n",
    "\n",
    "Currently saves the arguments as local variable, then creates a TensorFlow variable scope where the neural network\n",
    "architecture gets created.\n",
    "\n",
    "Currently emitted:\n",
    "1. Observation normalization\n",
    "2. Obseration clipping\n",
    "3. _act function\n",
    "4. _setfromflat\n",
    "5. _getfromflat\n",
    "6. set_all_vars"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "args = {\n",
    "      \"ac_bins\": \"continuous:\",\n",
    "      \"ac_noise_std\": 0.01,\n",
    "      #\"connection_type\": \"ff\",\n",
    "      \"hidden_dims\": [\n",
    "        256,\n",
    "        256\n",
    "      ],\n",
    "      \"nonlin_type\": \"tanh\"\n",
    "}\n",
    "\n",
    "ob_space= env.observation_space\n",
    "ac_space = env.action_space\n",
    "ac_bins = args[\"ac_bins\"]\n",
    "ac_noise_std = args[\"ac_noise_std\"]\n",
    "hidden_dims = args[\"hidden_dims\"]\n",
    "nonlin = args[\"nonlin_type\"]\n",
    "\n",
    "with tf.variable_scope(\"RoboschoolPolicy\") as scope:\n",
    "    # Observation normalization\n",
    "    #ob_mean = tf.get_variable(\n",
    "    #    'ob_mean', ob_space.shape, tf.float32, tf.constant_initializer(np.nan), trainable=False)\n",
    "    #ob_std = tf.get_variable(\n",
    "    #    'ob_std', ob_space.shape, tf.float32, tf.constant_initializer(np.nan), trainable=False)\n",
    "    #in_mean = tf.placeholder(tf.float32, ob_space.shape)\n",
    "    #in_std = tf.placeholder(tf.float32, ob_space.shape)\n",
    "    #self._set_ob_mean_std = U.function([in_mean, in_std], [], updates=[\n",
    "        #tf.assign(ob_mean, in_mean),\n",
    "        #tf.assign(ob_std, in_std),\n",
    "    #])\n",
    "\n",
    "    # Policy network\n",
    "\n",
    "    # Create a placeholder of type float32 with dimension None and the shape of the observation space\n",
    "    o = tf.placeholder(tf.float32, [None] + list(ob_space.shape))\n",
    "\n",
    "    # Normalize observation space and clip to [-5.0, 5.0]\n",
    "    #o = tf.clip_by_value((o - ob_mean) / ob_std, -5.0, 5.0)\n",
    "\n",
    "\n",
    "    # Feed-Forward Neural Network architecture\n",
    "    x = o\n",
    "    # Iterate through the hidden dimensions. In each iteration create a dense layer and activate it with the\n",
    "    # self.nonlin activation function\n",
    "    for ilayer, hd in enumerate(hidden_dims):\n",
    "        shape = [x.get_shape()[1], hd]\n",
    "        std = 1.0\n",
    "        \n",
    "        # Initializer for the newly created weights. TODO possible replacement tf.keras.initializers.RandomNormal\n",
    "        out = np.random.randn(*shape).astype(np.float32)\n",
    "        out *= std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "        initializer= tf.constant(out)\n",
    "        \n",
    "        # Creates a Dense layer TODO possible replacement tf.keras.layers.Dense\n",
    "        w = tf.get_variable(\"l\" + str(ilayer) + \"/w\", shape, initializer=initializer)\n",
    "        b = tf.get_variable(\"l\" + str(ilayer) + \"/b\", [hd], initializer=tf.zeros_initializer)\n",
    "        dense = tf.matmul(x, w) + b\n",
    "       \n",
    "        x = nonlin(dense)\n",
    "\n",
    "\n",
    "    # Map to action\n",
    "    adim = ac_space.shape[0]\n",
    "    \n",
    "    # Initializer for the newly created weights. TODO possible replacement tf.keras.initializers.RandomNormal\n",
    "    out = np.random.randn(*adim).astype(np.float32)\n",
    "    out *=  0.01 / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "    initializer= tf.constant(out)\n",
    "    \n",
    "    # Creates a Dense layer TODO possible replacement tf.keras.layers.Dense\n",
    "    w = tf.get_variable(\"out\" + \"/w\", [x.get_shape()[1], adim], initializer=initializer)\n",
    "    b = tf.get_variable(\"out\" + \"/b\", [adim], initializer=tf.zeros_initializer)\n",
    "    dense = tf.matmul(x, w) + b\n",
    "    \n",
    "    a = dense\n",
    "    \n",
    "    # TODO _act\n",
    "\n",
    "\n",
    "all_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope.name)\n",
    "trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope.name)\n",
    "\n",
    "#self.num_params = sum(int(np.prod(v.get_shape().as_list())) for v in self.trainable_variables)\n",
    "\n",
    "#self._setfromflat = U.SetFromFlat(self.trainable_variables)\n",
    "#self._getflat = U.GetFlat(self.trainable_variables)\n",
    "\n",
    "#placeholders = [tf.placeholder(v.value().dtype, v.get_shape().as_list()) for v in self.all_variables]\n",
    "\n",
    "# self.set_all_vars = U.function(\n",
    "#     inputs=placeholders,\n",
    "#     outputs=[],\n",
    "#     updates=[tf.group(*[v.assign(p) for v, p in zip(self.all_variables, placeholders)])]\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#optimizer = {'sgd': SGD, 'adam': Adam}[exp['optimizer']['type']](policy, **exp['optimizer']['args'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shared Memory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ctypes, multiprocessing\n",
    "\n",
    "seed = 123\n",
    "count = 250000000  # 1 gigabyte of 32-bit numbers. Will actually sample 2 gigabytes below.\n",
    "\n",
    "# Instantiate an array of C float datatype with size count\n",
    "_shared_mem = multiprocessing.Array(ctypes.c_float, count)\n",
    "\n",
    "# Convert to numpy array\n",
    "_noise = np.ctypeslib.as_array(_shared_mem.get_obj())\n",
    "assert _noise.dtype == np.float32\n",
    "_noise[:] = np.random.RandomState(seed).randn(count)  # 64-bit to 32-bit conversion here\n",
    "\n",
    "# def get(self, i, dim):\n",
    "#     return self.noise[i:i + dim]\n",
    "# \n",
    "# def sample_index(self, stream, dim):\n",
    "#     return stream.randint(0, len(self.noise) - dim + 1)\n",
    "\n",
    "# noise = SharedNoiseTable()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "rs = np.random.RandomState()\n",
    "\n",
    "\n",
    "# ob_stat = RunningStat(\n",
    "#     env.observation_space.shape,\n",
    "#     eps=1e-2  # eps to prevent dividing by zero at the beginning when computing mean/stdev\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "tslimit, incr_tslimit_threshold, tslimit_incr_ratio = None, None, None\n",
    "adaptive_tslimit = False\n",
    "\n",
    "\n",
    "episodes_so_far = 0\n",
    "timesteps_so_far = 0\n",
    "tstart = time.time()\n",
    "\n",
    "task_counter = 0\n",
    "\n",
    "while True:\n",
    "    step_tstart = time.time()\n",
    "    theta = policy.get_trainable_flat()\n",
    "    assert theta.dtype == np.float32\n",
    "\n",
    "    # Task counter is used to recognize false tasks from previous iterations later\n",
    "    curr_task_id = task_counter\n",
    "    task_counter += 1\n",
    "\n",
    "    tasks.append(Task(\n",
    "            params=theta,\n",
    "            ob_mean=ob_stat.mean if policy.needs_ob_stat else None,\n",
    "            ob_std=ob_stat.std if policy.needs_ob_stat else None,\n",
    "            timestep_limit=tslimit,\n",
    "            task_id = curr_task_id\n",
    "    ))\n",
    "\n",
    "    tlogger.log('********** Iteration {} **********'.format(curr_task_id))\n",
    "\n",
    "    # Pop off results for the current task\n",
    "    curr_task_results, eval_rets, eval_lens, worker_ids = [], [], [], []\n",
    "    num_results_skipped, num_episodes_popped, num_timesteps_popped, ob_count_this_batch = 0, 0, 0, 0\n",
    "    while num_episodes_popped < config.episodes_per_batch:\n",
    "        # Wait for a result\n",
    "        result = pop_item(result_queue, lock)\n",
    "\n",
    "        assert isinstance(result, Result)\n",
    "        task_id = result.task_id\n",
    "        assert isinstance(task_id, int)\n",
    "\n",
    "        assert (result.eval_return is None) == (result.eval_length is None)\n",
    "        worker_ids.append(result.worker_id)\n",
    "\n",
    "        if result.eval_length is not None:\n",
    "            # This was an eval job\n",
    "            episodes_so_far += 1\n",
    "            timesteps_so_far += result.eval_length\n",
    "            # Store the result only for current tasks\n",
    "            if task_id == curr_task_id:\n",
    "                eval_rets.append(result.eval_return)\n",
    "                eval_lens.append(result.eval_length)\n",
    "        else:\n",
    "            # The real shit\n",
    "            assert (result.noise_inds_n.ndim == 1 and\n",
    "                    result.returns_n2.shape == result.lengths_n2.shape == (len(result.noise_inds_n), 2))\n",
    "            assert result.returns_n2.dtype == np.float32\n",
    "            # Update counts\n",
    "            result_num_eps = result.lengths_n2.size\n",
    "            result_num_timesteps = result.lengths_n2.sum()\n",
    "            episodes_so_far += result_num_eps\n",
    "            timesteps_so_far += result_num_timesteps\n",
    "            # Store results only for current tasks\n",
    "            if task_id == curr_task_id:\n",
    "                curr_task_results.append(result)\n",
    "                num_episodes_popped += result_num_eps\n",
    "                num_timesteps_popped += result_num_timesteps\n",
    "                # Update ob stats\n",
    "                if policy.needs_ob_stat and result.ob_count > 0:\n",
    "                    ob_stat.increment(result.ob_sum, result.ob_sumsq, result.ob_count)\n",
    "                    ob_count_this_batch += result.ob_count\n",
    "            else:\n",
    "                num_results_skipped += 1\n",
    "\n",
    "    # Compute skip fraction\n",
    "    frac_results_skipped = num_results_skipped / (num_results_skipped + len(curr_task_results))\n",
    "    if num_results_skipped > 0:\n",
    "        logger.warning('Skipped {} out of date results ({:.2f}%)'.format(\n",
    "            num_results_skipped, 100. * frac_results_skipped))\n",
    "\n",
    "    # Assemble results\n",
    "    noise_inds_n = np.concatenate([r.noise_inds_n for r in curr_task_results])\n",
    "    returns_n2 = np.concatenate([r.returns_n2 for r in curr_task_results])\n",
    "    lengths_n2 = np.concatenate([r.lengths_n2 for r in curr_task_results])\n",
    "    assert noise_inds_n.shape[0] == returns_n2.shape[0] == lengths_n2.shape[0]\n",
    "    # Process returns\n",
    "    if config.return_proc_mode == 'centered_rank':\n",
    "        proc_returns_n2 = compute_centered_ranks(returns_n2)\n",
    "    elif config.return_proc_mode == 'sign':\n",
    "        proc_returns_n2 = np.concatenate([r.signreturns_n2 for r in curr_task_results])\n",
    "    elif config.return_proc_mode == 'centered_sign_rank':\n",
    "        proc_returns_n2 = compute_centered_ranks(np.concatenate([r.signreturns_n2 for r in curr_task_results]))\n",
    "    else:\n",
    "        raise NotImplementedError(config.return_proc_mode)\n",
    "    # Compute and take step\n",
    "    g, count = batched_weighted_sum(\n",
    "        proc_returns_n2[:, 0] - proc_returns_n2[:, 1],\n",
    "        (noise.get(idx, policy.num_params) for idx in noise_inds_n),\n",
    "        batch_size=500\n",
    "    )\n",
    "    g /= returns_n2.size\n",
    "    assert g.shape == (policy.num_params,) and g.dtype == np.float32 and count == len(noise_inds_n)\n",
    "    #update_ratio = optimizer.update(-g + config.l2coeff * theta)\n",
    "    update_ratio = optimizer.update(config.l2coeff * g)\n",
    "\n",
    "    # Update ob stat (we're never running the policy in the master, but we might be snapshotting the policy)\n",
    "    if policy.needs_ob_stat:\n",
    "        policy.set_ob_stat(ob_stat.mean, ob_stat.std)\n",
    "\n",
    "    # Update number of steps to take\n",
    "    if adaptive_tslimit and (lengths_n2 == tslimit).mean() >= incr_tslimit_threshold:\n",
    "        old_tslimit = tslimit\n",
    "        tslimit = int(tslimit_incr_ratio * tslimit)\n",
    "        logger.info('Increased timestep limit from {} to {}'.format(old_tslimit, tslimit))\n",
    "\n",
    "    step_tend = time.time()\n",
    "    tlogger.record_tabular(\"EpRewMean\", returns_n2.mean())\n",
    "    tlogger.record_tabular(\"EpRewStd\", returns_n2.std())\n",
    "    tlogger.record_tabular(\"EpLenMean\", lengths_n2.mean())\n",
    "\n",
    "    tlogger.record_tabular(\"EvalEpRewMean\", np.nan if not eval_rets else np.mean(eval_rets))\n",
    "    tlogger.record_tabular(\"EvalEpRewStd\", np.nan if not eval_rets else np.std(eval_rets))\n",
    "    tlogger.record_tabular(\"EvalEpLenMean\", np.nan if not eval_rets else np.mean(eval_lens))\n",
    "    tlogger.record_tabular(\"EvalPopRank\", np.nan if not eval_rets else (\n",
    "        np.searchsorted(np.sort(returns_n2.ravel()), eval_rets).mean() / returns_n2.size))\n",
    "    tlogger.record_tabular(\"EvalEpCount\", len(eval_rets))\n",
    "\n",
    "    tlogger.record_tabular(\"Norm\", float(np.square(policy.get_trainable_flat()).sum()))\n",
    "    tlogger.record_tabular(\"GradNorm\", float(np.square(g).sum()))\n",
    "    tlogger.record_tabular(\"UpdateRatio\", float(update_ratio))\n",
    "\n",
    "    tlogger.record_tabular(\"EpisodesThisIter\", lengths_n2.size)\n",
    "    tlogger.record_tabular(\"EpisodesSoFar\", episodes_so_far)\n",
    "    tlogger.record_tabular(\"TimestepsThisIter\", lengths_n2.sum())\n",
    "    tlogger.record_tabular(\"TimestepsSoFar\", timesteps_so_far)\n",
    "\n",
    "    num_unique_workers = len(set(worker_ids))\n",
    "    tlogger.record_tabular(\"UniqueWorkers\", num_unique_workers)\n",
    "    tlogger.record_tabular(\"UniqueWorkersFrac\", num_unique_workers / len(worker_ids))\n",
    "    tlogger.record_tabular(\"ResultsSkippedFrac\", frac_results_skipped)\n",
    "    tlogger.record_tabular(\"ObCount\", ob_count_this_batch)\n",
    "\n",
    "    tlogger.record_tabular(\"TimeElapsedThisIter\", step_tend - step_tstart)\n",
    "    tlogger.record_tabular(\"TimeElapsed\", step_tend - tstart)\n",
    "    tlogger.dump_tabular()\n",
    "\n",
    "    if config.snapshot_freq != 0 and curr_task_id % config.snapshot_freq == 0:\n",
    "        import os.path as osp\n",
    "        filename = osp.join(tlogger.get_dir(), 'snapshot_iter{:05d}_rew{}.h5'.format(\n",
    "            curr_task_id,\n",
    "            np.nan if not eval_rets else int(np.mean(eval_rets))\n",
    "        ))\n",
    "        assert not osp.exists(filename)\n",
    "        policy.save(filename)\n",
    "        tlogger.log('Saved snapshot {}'.format(filename))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}