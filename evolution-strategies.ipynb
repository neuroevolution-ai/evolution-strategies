{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIT License\n",
    "\n",
    "Copyright (c) 2016 OpenAI (http://openai.com)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in\n",
    "all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using evolution strategies to train Roboschool Environments\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook is based on the [paper](https://arxiv.org/abs/1703.03864), [blog article](https://openai.com/blog/evolution-strategies/) and [implementation](https://github.com/openai/evolution-strategies-starter) of OpenAI on the topic of using an evolution strategy algorithm for a typical reinforcement learning task. \n",
    "\n",
    "My implementation summarizes their implementation, by simplifying, refactoring and organizing the code into this Jupyter notebook which can be used to test the algorithm. One can tweak the hyperparameters, change the environment which shall be trained or even expand the implementation to support for example Atari environments.\n",
    "\n",
    "I recommend reading the paper or at least the article before trying out the notebook. Also depending on the environment the training can be very computationally intense (for example training the Humanoid), so if you want to try out the harder ones I recommend using a highly parallelizable machine, i.e. a machine with a high number of cores/threads.\n",
    "\n",
    "## Algorithm overview\n",
    "\n",
    "This section gives a brief overview over the used strategy. First of all we need to define what this implementation is going to do. The Roboschool is a group of environments in the [OpenAi Gym](https://gym.openai.com/), a program to test the behavior of machine learning algorithms on _real world_ problems. In our case, we want to train different robotic environments using evolution strategies. We therefore define a neural net with a configurable number of hidden layers, where the input dimension equals the observation space of the environment and the dimension of the output layer equals the dimension of the action space of the environment. This neural net will be called policy in our context. Therefore we train our policy to output the best possible action sequence given an observation sequence. Now, how do we train this policy? Training an evolutionary strategy consists of a cycle which is repeated over and over. First, an initial weight vector is randomly generated. Then we perturb this vector. The number of perturbations is called the population size. Lets say we have a population size of 100. Therefore we now have 100 weight vectors which are slightly different from the initial one. We then take these new weight vectors and evaluate them on our environment. The environment gives us a reward back, a number which indicates how well the policy with our perturbed weight vectors has done. So now we have 100 perturbed weight vectors with 100 noise vectors and 100 rewards for each perturbed weight vector. We then sum over all the rewards and weight them with the used noise. We then multiply this sum with the learning rate and divide by the population size and the noise standard deviation. The result of this equation gives us the new step which we add to the inital weight vector. Then we have the initial weight vector for the next cycle. We call such a cycle a generation. What it essentially does is evaluate which noise we added resulted in the best reward and we want the next generation to base on that noise.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before starting any computation we need to configure the program and define some methods and objects we will use later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Note that here is not import of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import ctypes\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "import gym, roboschool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging and save directory\n",
    "\n",
    "First things first, we need to define a directory where we want to store the trained weights, as well as the log file to record the results of every generation.\n",
    "\n",
    "The default path a folder called `es_{PID}` inside the working directory of this Jupyter Notebook, where the PID is the Process ID. If you want to change this, set save_directory to a valid path of your choice in a non-root location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "save_directory = os.getcwd() + \"/es_{}/\".format(os.getpid())\n",
    "mkdir_p(save_directory)\n",
    "\n",
    "logger = logging.getLogger('main_logger')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "fh = logging.FileHandler(save_directory + 'log.txt')\n",
    "fh.setLevel(logging.INFO)\n",
    "fh.setFormatter(logging.Formatter('%(asctime)s %(message)s', ''))\n",
    "\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configuration & Result Classes\n",
    "\n",
    "Using a `namedtuple` allows use to quickly create a class with different attributes, which is ideal for defining a Config and Result Class.\n",
    "\n",
    "#### Config Class\n",
    "\n",
    "The Config class defines our general configuration of the program. The following table explains what each attribute does:\n",
    "\n",
    "\n",
    "| Attribute             | Explanation   |\n",
    "| :---------------------|:--------------|\n",
    "| `env_id`              | A string representing an environment of the Roboschool, e.g. `\"RoboschoolAnt-v1\"`|\n",
    "| `population_size`     | The size of the population of one generation    |\n",
    "| `num_workers`         | The number of workers doing computation in parallel, for maximum performance the default is `os.cpu_cores`|\n",
    "| `learning_rate`       | A floating point number which dictates how _strong_ the best candidate of a generation shall be influencing the paramter vector \n",
    "| `noise_stdev`         | The standard deviation used for the noise\n",
    "| `snapshot_freq`       | An integer which tells in which frequency the weights of the model shall be saved, e.g. a snapshot frequency of 10 would save the weights of the model every 10 generations\n",
    "| `return_proc_mode`    | The processing mode of the gathered returns, currentyl only `\"centered_rank\"` is available\n",
    "| `timesteps_per_gen` | Alternative exit condition for a generation, i.e. stop after x timesteps, currently not used\n",
    "| `calc_obstat_prob`    | The probability of calculating the new mean and standard deviation of the observation space\n",
    "| `eval_prob`           | The probability of inserting an evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Config = namedtuple('Config', [\n",
    "    'env_id',\n",
    "    'population_size',\n",
    "    'num_workers',\n",
    "    'learning_rate',\n",
    "    'noise_stdev',\n",
    "    'snapshot_freq',\n",
    "    'return_proc_mode',\n",
    "    #'timesteps_per_gen',\n",
    "    'calc_obstat_prob',\n",
    "    'l2coeff'\n",
    "    #'eval_prob'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizations = namedtuple('Optimizations', [\n",
    "    'mirrored_sampling',\n",
    "    'fitness_shaping',\n",
    "    'weight_decay', # TODO\n",
    "    'discretize_actions', # TODO how to save model with the output?\n",
    "    'neural_network_optimizer',\n",
    "    'observation_space_normalization'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Structure class\n",
    "\n",
    "| Attribute         | Explanation   |\n",
    "| :---------------- |:--------------|\n",
    "| `ac_noise_std`    |               |\n",
    "| `connection_type` |               |\n",
    "| `hidden_dims`     |               |\n",
    "| `nonlin_type`     |               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelStructure = namedtuple('ModelStructure', [\n",
    "    'ac_noise_std',\n",
    "    'ac_bins',\n",
    "    'connection_type',\n",
    "    'hidden_dims',\n",
    "    'nonlin_type',\n",
    "    'nn_optimizer',\n",
    "    'nn_optimizer_args'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result class\n",
    "\n",
    "| Attribute             | Explanation   |\n",
    "| :---------------------|:--------------|\n",
    "| `noise_inds_n`        | |\n",
    "| `returns_n2` |\n",
    "| `signreturns_n2` |\n",
    "| `lengths_n2` |\n",
    "| `eval_return` |\n",
    "| `eval_length` |\n",
    "| `ob_sum` |\n",
    "| `ob_sumsq` |\n",
    "| `ob_count` |\n",
    "| `task_id` | \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = namedtuple('Result', [\n",
    "    'noise_inds','returns', 'signreturns', 'lengths',\n",
    "    'eval_return', 'eval_length',\n",
    "    'ob_sum', 'ob_sumsq', 'ob_count',\n",
    "    'task_id'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    env_id=\"RoboschoolHumanoid-v1\",\n",
    "    population_size=1000,\n",
    "    num_workers=os.cpu_count(),\n",
    "    learning_rate=0.001,\n",
    "    noise_stdev=0.02,\n",
    "    snapshot_freq=1,\n",
    "    return_proc_mode=\"centered_rank\",\n",
    "    calc_obstat_prob=0.01,\n",
    "    l2coeff=0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Environment\n",
    "\n",
    "Create one for every worker -> done in worker method\n",
    "Master also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(config.env_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Policy setup\n",
    "\n",
    "Currently saves the arguments as local variable, then creates a TensorFlow variable scope where the neural network\n",
    "architecture gets created.\n",
    "\n",
    "Currently emitted:\n",
    "6. set_all_vars\n",
    "\n",
    "## Keras as Model\n",
    "\n",
    "Original implementation used hand written dense layers and tensorflow operations. I use a Keras model and their\n",
    "functional API to create the net. In testing the two version differ in 0.x float scope. Something to worry about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_structure = ModelStructure(\n",
    "    ac_noise_std=0.01,\n",
    "    ac_bins='continuous:',\n",
    "    connection_type='ff',\n",
    "    hidden_dims=[256, 256],\n",
    "    nonlin_type='tanh',\n",
    "    nn_optimizer='adam',\n",
    "    nn_optimizer_args={\n",
    "        'stepsize': 0.01\n",
    "    }\n",
    ")\n",
    "\n",
    "ob_space= env.observation_space\n",
    "ac_space = env.action_space\n",
    "#ac_bins = args[\"ac_bins\"] TODO ac_bins implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations = Optimizations(\n",
    "    mirrored_sampling=True,\n",
    "    fitness_shaping=True,\n",
    "    weight_decay=True,\n",
    "    discretize_actions=False,\n",
    "    neural_network_optimizer=True,\n",
    "    observation_space_normalization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningStat(object):\n",
    "    def __init__(self, shape, eps):\n",
    "        self.sum = np.zeros(shape, dtype=np.float32)\n",
    "        self.sumsq = np.full(shape, eps, dtype=np.float32)\n",
    "        self.count = eps\n",
    "\n",
    "    def increment(self, s, ssq, c):\n",
    "        self.sum += s\n",
    "        self.sumsq += ssq\n",
    "        self.count += c\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.sum / self.count\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(np.maximum(self.sumsq / self.count - np.square(self.mean), 1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Keras clearin backend to support multiprocessing\n",
    "\n",
    "$\\text{out } = \\frac{\\sigma}{\\sqrt{\\sum \\limits_{i \\in \\text{out}} i^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(initial_weights=None, model_name=\"model\", save_path=None):\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    class Normc_initializer(tf.keras.initializers.Initializer):\n",
    "        \"\"\"\n",
    "        Create a TensorFlow constant with random numbers normed in the given shape.\n",
    "        :param std:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        def __init__(self, std=1.0):\n",
    "            self.std=std\n",
    "\n",
    "        def __call__(self, shape, dtype=None, partition_info=None):#pylint: disable=W0613\n",
    "            out = np.random.randn(*shape).astype(np.float32)\n",
    "            out *= self.std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            return tf.constant(out)\n",
    "    \n",
    "    nonlin = tf.nn.tanh\n",
    "    \n",
    "    if model_structure.nonlin_type == 'relu':\n",
    "        nonlin = tf.nn.relu\n",
    "    elif model_structure.nonlin_type == 'lrelu':\n",
    "        nonlin = tf.nn.leaky_relu\n",
    "    elif model_structure.nonlin_type == 'elu':\n",
    "        nonlin = tf.nn.leaky_relu\n",
    "    \n",
    "\n",
    "    # Policy network\n",
    "    input_layer = x = tf.keras.Input(ob_space.shape, dtype=tf.float32)\n",
    "\n",
    "    for hd in model_structure.hidden_dims:\n",
    "        x = tf.keras.layers.Dense(\n",
    "            hd, activation=nonlin,\n",
    "            kernel_initializer=Normc_initializer(std=1.0),\n",
    "            bias_initializer=tf.initializers.zeros())(x)\n",
    "\n",
    "    # Map to action\n",
    "    adim = ac_space.shape[0]\n",
    "\n",
    "    a = tf.keras.layers.Dense(\n",
    "        adim,\n",
    "        kernel_initializer=Normc_initializer(std=1.0),\n",
    "        bias_initializer=tf.initializers.zeros())(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=a, name=model_name)\n",
    "    \n",
    "    if initial_weights is not None:\n",
    "        set_from_flat(model, initial_weights)\n",
    "        \n",
    "    if save_path:\n",
    "        model.save(save_path)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def act(ob, model, random_stream=None, ob_mean=None, ob_std=None):\n",
    "    ob_proc = ob\n",
    "    if ob_mean is not None and ob_std is not None:\n",
    "        ob_proc = np.clip((ob - ob_mean) / ob_std, -5.0, 5.0)\n",
    "    action = model.predict(ob)\n",
    "    \n",
    "    # TODO why randomstream? Better generalization?\n",
    "    if random_stream is not None and model_structure.ac_noise_std != 0:\n",
    "        action += random_stream.randn(*action.shape) * model_structure.ac_noise_std\n",
    "    return action\n",
    "\n",
    "def get_initial_weights():\n",
    "    model = create_model()\n",
    "    \n",
    "    # Print out the model\n",
    "    model.summary()\n",
    "    \n",
    "    return model.get_weights()\n",
    "\n",
    "with multiprocessing.Pool(1) as pool:\n",
    "    theta = pool.apply(func=get_initial_weights)\n",
    "\n",
    "num_params = sum(np.prod(v.shape) for v in theta)\n",
    "\n",
    "#placeholders = [tf.placeholder(v.value().dtype, v.get_shape().as_list()) for v in self.all_variables]\n",
    "\n",
    "# self.set_all_vars = U.function(\n",
    "#     inputs=placeholders,\n",
    "#     outputs=[],\n",
    "#     updates=[tf.group(*[v.assign(p) for v, p in zip(self.all_variables, placeholders)])]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Using Adam Optimizer\n",
    "\n",
    "Defining it manually since with Keras you have to define a loss function and use training set, etc. Manually seems\n",
    "easier for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self):\n",
    "        self.dim = num_params\n",
    "        self.t = 0\n",
    "\n",
    "    def update(self, theta, globalg):\n",
    "        self.t += 1\n",
    "        step = self._compute_step(globalg)\n",
    "        ratio = np.linalg.norm(step) / np.linalg.norm(theta)\n",
    "        theta_new = theta + step\n",
    "        return theta_new, ratio\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, stepsize, momentum=0.9):\n",
    "        Optimizer.__init__(self)\n",
    "        self.v = np.zeros(self.dim, dtype=np.float32)\n",
    "        self.stepsize, self.momentum = stepsize, momentum\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        self.v = self.momentum * self.v + (1. - self.momentum) * globalg\n",
    "        step = -self.stepsize * self.v\n",
    "        return step\n",
    "        \n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, stepsize, beta1=0.9, beta2=0.999, epsilon=1e-08):\n",
    "        Optimizer.__init__(self, theta)\n",
    "        self.stepsize = stepsize\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = np.zeros(self.dim, dtype=np.float32)\n",
    "        self.v = np.zeros(self.dim, dtype=np.float32)\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        a = self.stepsize * np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * globalg\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (globalg * globalg)\n",
    "        step = -a * self.m / (np.sqrt(self.v) + self.epsilon)\n",
    "        return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if optimizations.neural_network_optimizer:\n",
    "    if model_structure.nn_optimizer == 'adam':\n",
    "        optimizer = Adam(**model_structure.nn_optimizer_args)\n",
    "    elif model_structure.nn_optimizer == 'sgd':\n",
    "        optimizer = SGD(**model_structure.nn_optimizer_args)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Shared Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SharedNoiseTable(object):\n",
    "    def __init__(self):\n",
    "        seed = 123\n",
    "        count = 250000000  # 1 gigabyte of 32-bit numbers. Will actually sample 2 gigabytes below.\n",
    "        #logger.info('Sampling {} random numbers with seed {}'.format(count, seed))\n",
    "\n",
    "        # Instantiate an array of C float datatype with size count\n",
    "        self._shared_mem = multiprocessing.Array(ctypes.c_float, count)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        self.noise = np.ctypeslib.as_array(self._shared_mem.get_obj())\n",
    "        assert self.noise.dtype == np.float32\n",
    "        self.noise[:] = np.random.RandomState(seed).randn(count)  # 64-bit to 32-bit conversion here\n",
    "        #logger.info('Sampled {} bytes'.format(self.noise.size * 4))\n",
    "\n",
    "    def get(self, i, dim):\n",
    "        return self.noise[i:i + dim]\n",
    "\n",
    "    def sample_index(self, stream, dim):\n",
    "        return stream.randint(0, len(self.noise) - dim + 1)\n",
    "\n",
    "noise = SharedNoiseTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_flat(theta):\n",
    "     return np.concatenate([np.reshape(v, [-1]) for v in theta], 0)\n",
    "\n",
    "def set_from_flat(model, theta):\n",
    "    old_theta = model.get_weights()\n",
    "    shapes = [v.shape for v in old_theta]\n",
    "    total_size = theta.size\n",
    "    \n",
    "    start = 0\n",
    "    reshapes = []\n",
    "    \n",
    "    for (shape, v) in zip(shapes, theta):\n",
    "        size = int(np.prod(shape))\n",
    "        reshapes.append(np.reshape(theta[start:start+size], shape))\n",
    "        start += size\n",
    "    \n",
    "    assert start == total_size\n",
    "    model.set_weights(reshapes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set from flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rollout TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rollout(env, \n",
    "            model, \n",
    "            *, \n",
    "            render=False, \n",
    "            timestep_limit=None, \n",
    "            save_obs=False, \n",
    "            random_stream=None, \n",
    "            ob_mean=None, \n",
    "            ob_std=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "    \n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    t = 0\n",
    "    if save_obs:\n",
    "        obs = []\n",
    "    ob = env.reset()\n",
    "    for _ in range(timestep_limit):\n",
    "        ac = act(ob[None], model, random_stream=random_stream, ob_mean=ob_mean, ob_std=ob_std)[0]\n",
    "        if save_obs:\n",
    "            obs.append(ob)\n",
    "        ob, rew, done, _ = env.step(ac)\n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "        if done:\n",
    "            break\n",
    "    rews = np.array(rews, dtype=np.float32)\n",
    "    if save_obs:\n",
    "        return rews, t, np.array(obs)\n",
    "    return rews, t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Worker method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_and_update_ob_stat(env, model, rs, task_ob_stat, ob_mean=None, ob_std=None):\n",
    "    if ob_mean is not None and ob_std is not None and config.calc_obstat_prob != 0 and rs.rand() < config.calc_obstat_prob:\n",
    "        rollout_rews, rollout_len, obs = rollout(\n",
    "            env, model, save_obs=True, random_stream=rs)\n",
    "        task_ob_stat.increment(obs.sum(axis=0), np.square(obs).sum(axis=0), len(obs))\n",
    "    else:\n",
    "        rollout_rews, rollout_len = rollout(env, model, random_stream=rs)\n",
    "    return rollout_rews, rollout_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_worker(num_jobs, theta, ob_mean=None, ob_std=None): #min_task_runtime=.2):\n",
    "\n",
    "    print(\"PID \" + str(os.getpid()) + \": \" + \"Started worker with \" + str(num_jobs) + \"Jobs\")\n",
    "\n",
    "    assert isinstance(noise, SharedNoiseTable)\n",
    "\n",
    "    # Setup\n",
    "    #config, env, sess, policy = setup(exp, single_threaded=True)\n",
    "    env = gym.make(config.env_id)\n",
    "    model = create_model(initial_weights=theta, model_name=str(os.getpid()))\n",
    "    \n",
    "\n",
    "    # Random stream used for todo\n",
    "    rs = np.random.RandomState()\n",
    "\n",
    "    #assert policy.needs_ob_stat == (config.calc_obstat_prob != 0)\n",
    "\n",
    "    #while True:\n",
    "    # Prevent accessing empty array (master did not emit task yet)\n",
    "    #while not tasks:\n",
    "    #    time.sleep(0.05)\n",
    "\n",
    "    #task_data = tasks[-1]\n",
    "\n",
    "    #task_tstart = time.time()\n",
    "\n",
    "    #assert isinstance(task_data, Task)\n",
    "    #task_id = task_data.task_id\n",
    "    #assert isinstance(task_id, int)\n",
    "\n",
    "    #if policy.needs_ob_stat:\n",
    "    #    policy.set_ob_stat(task_data.ob_mean, task_data.ob_std)\n",
    "\n",
    "    # # todo whats this condition doing?\n",
    "    # if rs.rand() < config.eval_prob:\n",
    "    #     # Evaluation: noiseless weights and noiseless actions\n",
    "    #     policy.set_trainable_flat(task_data.params)\n",
    "    # \n",
    "    #     eval_rews, eval_length = policy.rollout(env)  # eval rollouts don't obey task_data.timestep_limit\n",
    "    #     eval_return = eval_rews.sum()\n",
    "    # \n",
    "    #     with lock:\n",
    "    #         logger.info('Eval result: task={} return={:.3f} length={}'.format(task_id, eval_return, eval_length))\n",
    "    # \n",
    "    #     result_queue.put(Result(\n",
    "    #         worker_id=worker_id,\n",
    "    #         noise_inds_n=None,\n",
    "    #         returns_n2=None,\n",
    "    #         signreturns_n2=None,\n",
    "    #         lengths_n2=None,\n",
    "    #         eval_return=eval_return,\n",
    "    #         eval_length=eval_length,\n",
    "    #         ob_sum=None,\n",
    "    #         ob_sumsq=None,\n",
    "    #         ob_count=None,\n",
    "    #         task_id=task_id\n",
    "    #     ))\n",
    "\n",
    "    # Rollouts with noise\n",
    "    noise_inds, returns, signreturns, lengths = [], [], [], []\n",
    "    task_ob_stat = RunningStat(env.observation_space.shape, eps=0.)  # eps=0 because we're incrementing only\n",
    "    \n",
    "    #while not noise_inds or time.time() - task_tstart < min_task_runtime:\n",
    "    \n",
    "    for _ in range(num_jobs):\n",
    "\n",
    "        # ------------- Noise sample -------------------------------\n",
    "        noise_idx = noise.sample_index(rs, num_params)\n",
    "        epsilon = config.noise_stdev * noise.get(noise_idx, num_params)\n",
    "\n",
    "        # Evaluate the sampled noise positive\n",
    "        set_from_flat(model, theta + epsilon)\n",
    "        rews_pos, len_pos = rollout_and_update_ob_stat(env, model, rs=rs, task_ob_stat=task_ob_stat, ob_mean=ob_mean, ob_std=ob_std)\n",
    "\n",
    "        # rews_pos, len_pos = rollout_and_update_ob_stat(\n",
    "        #     policy, env, task_data.timestep_limit, rs, task_ob_stat, config.calc_obstat_prob)\n",
    "        \n",
    "        if optimizations.mirrored_sampling:\n",
    "            # Evaluate the sample noise negative\n",
    "            set_from_flat(model, theta - epsilon)\n",
    "            rews_neg, len_neg = rollout_and_update_ob_stat(env, model, rs=rs, task_ob_stat=task_ob_stat, ob_mean=ob_mean, ob_std=ob_std)\n",
    "\n",
    "        # rews_neg, len_neg = rollout_and_update_ob_stat(\n",
    "        #     policy, env, task_data.timestep_limit, rs, task_ob_stat, config.calc_obstat_prob)\n",
    "        \n",
    "        # Gather results\n",
    "        noise_inds.append(noise_idx)\n",
    "        returns.append([rews_pos.sum()])\n",
    "        signreturns.append([np.sign(rews_pos).sum()])\n",
    "        lengths.append([len_pos])\n",
    "        \n",
    "        if optimizations.mirrored_sampling:\n",
    "            returns[-1].append(rews_neg.sum())\n",
    "            signreturns[-1].append(np.sign(rews_neg).sum())\n",
    "            lengths[-1].append(len_neg)\n",
    "        \n",
    "    # result_queue.put(Result(\n",
    "    #     worker_id=worker_id,\n",
    "    #     noise_inds_n=np.array(noise_inds),\n",
    "    #     returns_n2=np.array(returns, dtype=np.float32),\n",
    "    #     signreturns_n2=np.array(signreturns, dtype=np.float32),\n",
    "    #     lengths_n2=np.array(lengths, dtype=np.int32),\n",
    "    #     eval_return=None,\n",
    "    #     eval_length=None,\n",
    "    #     ob_sum=None if task_ob_stat.count == 0 else task_ob_stat.sum,\n",
    "    #     ob_sumsq=None if task_ob_stat.count == 0 else task_ob_stat.sumsq,\n",
    "    #     ob_count=task_ob_stat.count,\n",
    "    #     task_id=task_id\n",
    "    # ))\n",
    "    print(\"PID \" + str(os.getpid()) + \": \" + \"Returned result\")\n",
    "    result = Result(\n",
    "        noise_inds=np.array(noise_inds),\n",
    "        returns=np.array(returns, dtype=np.float32),\n",
    "        signreturns=np.array(signreturns, dtype=np.float32),\n",
    "        lengths=np.array(lengths, dtype=np.int32),\n",
    "        eval_return=None,\n",
    "        eval_length=None,\n",
    "        ob_sum=None if task_ob_stat.count == 0 else task_ob_stat.sum,\n",
    "        ob_sumsq=None if task_ob_stat.count == 0 else task_ob_stat.sumsq,\n",
    "        ob_count=task_ob_stat.count,\n",
    "        task_id = 0\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def itergroups(items, group_size):\n",
    "    assert group_size >= 1\n",
    "    group = []\n",
    "    for x in items:\n",
    "        group.append(x)\n",
    "        if len(group) == group_size:\n",
    "            yield tuple(group)\n",
    "            del group[:]\n",
    "    if group:\n",
    "        yield tuple(group)\n",
    "        \n",
    "def batched_weighted_sum(weights, vecs, batch_size):\n",
    "    total = 0.\n",
    "    num_items_summed = 0\n",
    "    for batch_weights, batch_vecs in zip(itergroups(weights, batch_size), itergroups(vecs, batch_size)):\n",
    "        assert len(batch_weights) == len(batch_vecs) <= batch_size\n",
    "        total += np.dot(np.asarray(batch_weights, dtype=np.float32), np.asarray(batch_vecs, dtype=np.float32))\n",
    "        num_items_summed += len(batch_weights)\n",
    "    return total, num_items_summed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Fitness shaping with a rank transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_ranks(x):\n",
    "    \"\"\"\n",
    "    Returns ranks in [0, len(x))\n",
    "    Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].\n",
    "    \"\"\"\n",
    "    assert x.ndim == 1\n",
    "    ranks = np.empty(len(x), dtype=int)\n",
    "    ranks[x.argsort()] = np.arange(len(x))\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def compute_centered_ranks(x):\n",
    "    y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(config.env_id)\n",
    "rs = np.random.RandomState()\n",
    "\n",
    "ob_stat = RunningStat(\n",
    "    env.observation_space.shape,\n",
    "    eps=1e-2  # eps to prevent dividing by zero at the beginning when computing mean/stdev\n",
    ")\n",
    "\n",
    "tslimit, incr_tslimit_threshold, tslimit_incr_ratio = None, None, None\n",
    "adaptive_tslimit = False\n",
    "\n",
    "\n",
    "episodes_so_far = 0\n",
    "timesteps_so_far = 0\n",
    "tstart = time.time()\n",
    "\n",
    "task_counter = 0\n",
    "\n",
    "assert config.num_workers != 0\n",
    "\n",
    "num_jobs_per_worker = [int(config.population_size / config.num_workers)] * config.num_workers\n",
    "\n",
    "mod = config.population_size % config.num_workers\n",
    "i = 0\n",
    "while mod > 0:\n",
    "    num_jobs_per_worker[i] += 1\n",
    "    mod -= 1\n",
    "    i += 1\n",
    "    \n",
    "assert len(num_jobs_per_worker) == config.num_workers\n",
    "generation_counter = 0\n",
    "\n",
    "theta = get_flat(theta)\n",
    "old_theta = theta\n",
    "\n",
    "while True:\n",
    "    print(\"----------------------GENERATION: \" + str(generation_counter) + \"------------------------------------\")\n",
    "    logger.info(\"Generation {} started\".format(generation_counter))\n",
    "    \n",
    "    step_tstart = time.time() \n",
    "            \n",
    "    #assert theta.dtype == np.float32\n",
    "\n",
    "    # Task counter is used to recognize false tasks from previous iterations later\n",
    "    curr_task_id = task_counter\n",
    "    task_counter += 1\n",
    "    \n",
    "    # Start workers\n",
    "    \n",
    "    workers = []\n",
    "    results = []\n",
    "    \n",
    "    with multiprocessing.Pool(processes=config.num_workers) as pool:\n",
    "    \n",
    "        print(\"PID \" + str(os.getpid()) + \": \" + \"Waiting for results\")\n",
    "        for i in num_jobs_per_worker:\n",
    "            results.append(pool.apply_async(func=run_worker, args=(i, theta, ob_stat.mean, ob_stat.std)))\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            results[i] = results[i].get()\n",
    "\n",
    "    # Pop off results for the current task\n",
    "    curr_task_results, eval_rets, eval_lens, worker_ids = [], [], [], []\n",
    "    num_results_skipped, num_episodes_popped, num_timesteps_popped, ob_count_this_batch = 0, 0, 0, 0\n",
    "   #while num_episodes_popped < config.episodes_per_batch:\n",
    "    for result in results:\n",
    "        assert isinstance(result, Result)\n",
    "        # task_id = result.task_id\n",
    "        # assert isinstance(task_id, int)\n",
    "\n",
    "        # assert (result.eval_return is None) == (result.eval_length is None)\n",
    "        # worker_ids.append(result.worker_id)\n",
    "        # \n",
    "        # if result.eval_length is not None:\n",
    "        #     # This was an eval job\n",
    "        #     episodes_so_far += 1\n",
    "        #     timesteps_so_far += result.eval_length\n",
    "        #     # Store the result only for current tasks\n",
    "        #     if task_id == curr_task_id:\n",
    "        #         eval_rets.append(result.eval_return)\n",
    "        #         eval_lens.append(result.eval_length)\n",
    "        # else:\n",
    "\n",
    "        \n",
    "        assert result.noise_inds_n.ndim == 1\n",
    "        if optimizations.mirrored_sampling:\n",
    "            assert result.returns.shape == result.lengths.shape == (len(result.noise_inds), 2)\n",
    "        else:\n",
    "            assert result.returns.shape == result.lengths.shape == (len(result.noise_inds), 1)\n",
    "        assert result.returns.dtype == np.float32\n",
    "        \n",
    "        # Update counts\n",
    "        result_num_eps = result.lengths.size\n",
    "        result_num_timesteps = result.lengths.sum()\n",
    "        episodes_so_far += result_num_eps\n",
    "        timesteps_so_far += result_num_timesteps\n",
    "        # Store results only for current tasks\n",
    "        curr_task_results.append(result)\n",
    "        num_episodes_popped += result_num_eps\n",
    "        num_timesteps_popped += result_num_timesteps\n",
    "        # Update ob stats\n",
    "        if result.ob_count > 0:\n",
    "            ob_stat.increment(result.ob_sum, result.ob_sumsq, result.ob_count)\n",
    "            ob_count_this_batch += result.ob_count\n",
    "\n",
    "    # Compute skip fraction\n",
    "    #frac_results_skipped = num_results_skipped / (num_results_skipped + len(curr_task_results))\n",
    "    # if num_results_skipped > 0:\n",
    "    #     logger.warning('Skipped {} out of date results ({:.2f}%)'.format(\n",
    "    #         num_results_skipped, 100. * frac_results_skipped))\n",
    "    \n",
    "    print(\"Gathered results\")\n",
    "\n",
    "    # Assemble results\n",
    "    noise_inds = np.concatenate([r.noise_inds for r in curr_task_results])\n",
    "    returns = np.concatenate([r.returns for r in curr_task_results])\n",
    "    lengths = np.concatenate([r.lengths for r in curr_task_results])\n",
    "    assert noise_inds.shape[0] == returns.shape[0] == lengths.shape[0]\n",
    "    \n",
    "    # Process returns\n",
    "    if optimizations.fitness_shaping:\n",
    "        if config.return_proc_mode == 'centered_rank':\n",
    "            proc_returns = compute_centered_ranks(returns)\n",
    "        # sign and centered_sign_rank are obviously only useful in combination with mirrored sampling\n",
    "        elif config.return_proc_mode == 'sign':\n",
    "            proc_returns = np.concatenate([r.signreturns for r in curr_task_results])\n",
    "        elif config.return_proc_mode == 'centered_sign_rank':\n",
    "            proc_returns = compute_centered_ranks(np.concatenate([r.signreturns for r in curr_task_results]))\n",
    "    else:\n",
    "        proc_returns = returns\n",
    "    \n",
    "    if optimizations.mirrored_sampling:\n",
    "        # Calculate the difference between the rewards sampled with the positive and negative noise\n",
    "        proc_returns = proc_returns[:, 0] - proc_returns[:, 1]\n",
    "    else:\n",
    "        proc_returns = proc_returns.ravel()\n",
    "    \n",
    "    g, count = batched_weighted_sum(\n",
    "        proc_returns,\n",
    "        (noise.get(idx, num_params) for idx in noise_inds),\n",
    "        batch_size=500\n",
    "    )\n",
    "    \n",
    "    assert g.shape == (num_params,) and g.dtype == np.float32 and count == len(noise_inds)\n",
    "    \n",
    "    # Update with the approximated gradient\n",
    "    g /= returns.size\n",
    "    \n",
    "    if optimizations.neural_network_optimizer:\n",
    "        theta, _ = optimizer.update(theta, -g + config.l2coeff * theta)\n",
    "    else:\n",
    "        theta += ((config.learning_rate / config.noise_stdev) * g)\n",
    "    \n",
    "\n",
    "    # Update ob stat (we're never running the policy in the master, but we might be snapshotting the policy)\n",
    "    # if policy.needs_ob_stat:\n",
    "    #     policy.set_ob_stat(ob_stat.mean, ob_stat.std)\n",
    "\n",
    "    # Update number of steps to take\n",
    "    # if adaptive_tslimit and (lengths_n2 == tslimit).mean() >= incr_tslimit_threshold:\n",
    "    #     old_tslimit = tslimit\n",
    "    #     tslimit = int(tslimit_incr_ratio * tslimit)\n",
    "    #     logger.info('Increased timestep limit from {} to {}'.format(old_tslimit, tslimit))\n",
    "\n",
    "    step_tend = time.time()\n",
    "    \n",
    "    logger.info(\"EpRewMean {}\".format(returns.mean()))\n",
    "    logger.info(\"EpRewStd {}\".format(returns.std()))\n",
    "    logger.info(\"EpLenMean {}\".format(lengths.mean()))\n",
    "    # \n",
    "    # tlogger.record_tabular(\"EvalEpRewMean\", np.nan if not eval_rets else np.mean(eval_rets))\n",
    "    # tlogger.record_tabular(\"EvalEpRewStd\", np.nan if not eval_rets else np.std(eval_rets))\n",
    "    # tlogger.record_tabular(\"EvalEpLenMean\", np.nan if not eval_rets else np.mean(eval_lens))\n",
    "    # tlogger.record_tabular(\"EvalPopRank\", np.nan if not eval_rets else (\n",
    "    #     np.searchsorted(np.sort(returns_n2.ravel()), eval_rets).mean() / returns_n2.size))\n",
    "    # tlogger.record_tabular(\"EvalEpCount\", len(eval_rets))\n",
    "    # \n",
    "    # tlogger.record_tabular(\"Norm\", float(np.square(policy.get_trainable_flat()).sum()))\n",
    "    # tlogger.record_tabular(\"GradNorm\", float(np.square(g).sum()))\n",
    "    # tlogger.record_tabular(\"UpdateRatio\", float(update_ratio))\n",
    "    # \n",
    "    logger.info(\"EpisodesThisIter {}\".format(lengths.size))\n",
    "    logger.info(\"EpisodesSoFar {}\".format(episodes_so_far))\n",
    "    logger.info(\"TimestepsThisIter {}\".format(lengths.sum()))\n",
    "    logger.info(\"TimestepsSoFar {}\".format(timesteps_so_far))\n",
    "    # \n",
    "    # num_unique_workers = len(set(worker_ids))\n",
    "    # tlogger.record_tabular(\"UniqueWorkers\", num_unique_workers)\n",
    "    # tlogger.record_tabular(\"UniqueWorkersFrac\", num_unique_workers / len(worker_ids))\n",
    "    # tlogger.record_tabular(\"ResultsSkippedFrac\", frac_results_skipped)\n",
    "    logger.info(\"ObCount {}\".format(ob_count_this_batch))\n",
    "    # \n",
    "    logger.info(\"TimeElapsedThisIter {}\".format(step_tend - step_tstart))\n",
    "    logger.info(\"TimeElapsed {}\".format(step_tend - tstart))\n",
    "\n",
    "    # tlogger.dump_tabular()\n",
    "\n",
    "    if config.snapshot_freq != 0 and generation_counter % config.snapshot_freq == 0:\n",
    "        from multiprocessing import Process\n",
    "        \n",
    "        p = Process(target=create_model, args=(theta, \n",
    "                                               config.env_id + \"_Generation_\" + str(generation_counter), \n",
    "                                               save_directory + 'snapshot_{:05d}'.format(generation_counter) + \".h5\"))\n",
    "        p.start()\n",
    "        p.join()\n",
    "        \n",
    "        print(\"Saved model in generation {}\".format(generation_counter))\n",
    "        logger.info(\"Saved model to {}\".format(save_directory))\n",
    "            \n",
    "    generation_counter+= 1\n",
    "    \n",
    "    logger.info(\"-----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    r = (-1) + (i * 2/9)\n",
    "    print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
