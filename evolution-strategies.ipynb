{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Config = namedtuple('Config', [\n",
    "    'env_id',\n",
    "    'population_size',\n",
    "    'learning_rate',\n",
    "    'noise_stdev',\n",
    "    'snapshot_freq',\n",
    "    'return_proc_mode'\n",
    "    #'timesteps_per_batch',\n",
    "    #'calc_obstat_prob',\n",
    "    #'eval_prob',\n",
    "    #'episode_cutoff_mode'\n",
    "])\n",
    "\n",
    "Result = namedtuple('Result', [\n",
    "    'worker_id',\n",
    "    'noise_inds_n','returns_n2', 'signreturns_n2', 'lengths_n2',\n",
    "    'eval_return', 'eval_length',\n",
    "    'ob_sum', 'ob_sumsq', 'ob_count',\n",
    "    'task_id'\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    env_id=\"RoboschoolInvertedPendulum-v1\",\n",
    "    population_size=300,\n",
    "    learning_rate=0.005,\n",
    "    noise_stdev=0.02,\n",
    "    snapshot_freq=20,\n",
    "    return_proc_mode=\"centered_rank\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment\n",
    "\n",
    "Create one for every worker -> done in worker method\n",
    "Master also"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gym, roboschool # Roboschool import needed to register the environments within gym\n",
    "env = gym.make(config.env_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorflow Session"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Policy setup\n",
    "\n",
    "Currently saves the arguments as local variable, then creates a TensorFlow variable scope where the neural network\n",
    "architecture gets created.\n",
    "\n",
    "Currently emitted:\n",
    "1. Observation normalization\n",
    "2. Obseration clipping\n",
    "3. _act function\n",
    "6. set_all_vars"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "args = {\n",
    "      \"ac_bins\": \"continuous:\",\n",
    "      \"ac_noise_std\": 0.01,\n",
    "      #\"connection_type\": \"ff\",\n",
    "      \"hidden_dims\": [\n",
    "        256,\n",
    "        256\n",
    "      ],\n",
    "      \"nonlin_type\": \"tanh\"\n",
    "}\n",
    "\n",
    "ob_space= env.observation_space\n",
    "ac_space = env.action_space\n",
    "ac_bins = args[\"ac_bins\"]\n",
    "ac_noise_std = args[\"ac_noise_std\"]\n",
    "hidden_dims = args[\"hidden_dims\"]\n",
    "nonlin = args[\"nonlin_type\"]\n",
    "\n",
    "with tf.variable_scope(\"RoboschoolPolicy\") as scope:\n",
    "    # Observation normalization\n",
    "    #ob_mean = tf.get_variable(\n",
    "    #    'ob_mean', ob_space.shape, tf.float32, tf.constant_initializer(np.nan), trainable=False)\n",
    "    #ob_std = tf.get_variable(\n",
    "    #    'ob_std', ob_space.shape, tf.float32, tf.constant_initializer(np.nan), trainable=False)\n",
    "    #in_mean = tf.placeholder(tf.float32, ob_space.shape)\n",
    "    #in_std = tf.placeholder(tf.float32, ob_space.shape)\n",
    "    #self._set_ob_mean_std = U.function([in_mean, in_std], [], updates=[\n",
    "        #tf.assign(ob_mean, in_mean),\n",
    "        #tf.assign(ob_std, in_std),\n",
    "    #])\n",
    "\n",
    "    # Policy network\n",
    "\n",
    "    # Create a placeholder of type float32 with dimension None and the shape of the observation space\n",
    "    o = tf.placeholder(tf.float32, [None] + list(ob_space.shape))\n",
    "\n",
    "    # Normalize observation space and clip to [-5.0, 5.0]\n",
    "    #o = tf.clip_by_value((o - ob_mean) / ob_std, -5.0, 5.0)\n",
    "\n",
    "\n",
    "    # Feed-Forward Neural Network architecture\n",
    "    x = o\n",
    "    # Iterate through the hidden dimensions. In each iteration create a dense layer and activate it with the\n",
    "    # self.nonlin activation function\n",
    "    for ilayer, hd in enumerate(hidden_dims):\n",
    "        shape = [x.get_shape()[1], hd]\n",
    "        std = 1.0\n",
    "        \n",
    "        # Initializer for the newly created weights. TODO possible replacement tf.keras.initializers.RandomNormal\n",
    "        out = np.random.randn(*shape).astype(np.float32)\n",
    "        out *= std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "        initializer= tf.constant(out)\n",
    "        \n",
    "        # Creates a Dense layer TODO possible replacement tf.keras.layers.Dense\n",
    "        w = tf.get_variable(\"l\" + str(ilayer) + \"/w\", shape, initializer=initializer)\n",
    "        b = tf.get_variable(\"l\" + str(ilayer) + \"/b\", [hd], initializer=tf.zeros_initializer)\n",
    "        dense = tf.matmul(x, w) + b\n",
    "       \n",
    "        x = nonlin(dense)\n",
    "\n",
    "\n",
    "    # Map to action\n",
    "    adim = ac_space.shape[0]\n",
    "    \n",
    "    # Initializer for the newly created weights. TODO possible replacement tf.keras.initializers.RandomNormal\n",
    "    out = np.random.randn(*adim).astype(np.float32)\n",
    "    out *=  0.01 / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "    initializer= tf.constant(out)\n",
    "    \n",
    "    # Creates a Dense layer TODO possible replacement tf.keras.layers.Dense\n",
    "    w = tf.get_variable(\"out\" + \"/w\", [x.get_shape()[1], adim], initializer=initializer)\n",
    "    b = tf.get_variable(\"out\" + \"/b\", [adim], initializer=tf.zeros_initializer)\n",
    "    dense = tf.matmul(x, w) + b\n",
    "    \n",
    "    a = dense\n",
    "    \n",
    "    # TODO _act\n",
    "\n",
    "\n",
    "all_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope.name)\n",
    "trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope.name)\n",
    "\n",
    "num_params = sum(int(np.prod(v.get_shape().as_list())) for v in trainable_variables)\n",
    "    \n",
    "#self._setfromflat = U.SetFromFlat(self.trainable_variables)\n",
    "#self._getflat = U.GetFlat(self.trainable_variables)\n",
    "\n",
    "#placeholders = [tf.placeholder(v.value().dtype, v.get_shape().as_list()) for v in self.all_variables]\n",
    "\n",
    "# self.set_all_vars = U.function(\n",
    "#     inputs=placeholders,\n",
    "#     outputs=[],\n",
    "#     updates=[tf.group(*[v.assign(p) for v, p in zip(self.all_variables, placeholders)])]\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#optimizer = {'sgd': SGD, 'adam': Adam}[exp['optimizer']['type']](policy, **exp['optimizer']['args'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shared Noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SharedNoiseTable(object):\n",
    "    def __init__(self):\n",
    "        import ctypes, multiprocessing\n",
    "        seed = 123\n",
    "        count = 250000000  # 1 gigabyte of 32-bit numbers. Will actually sample 2 gigabytes below.\n",
    "        #logger.info('Sampling {} random numbers with seed {}'.format(count, seed))\n",
    "\n",
    "        # Instantiate an array of C float datatype with size count\n",
    "        self._shared_mem = multiprocessing.Array(ctypes.c_float, count)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        self.noise = np.ctypeslib.as_array(self._shared_mem.get_obj())\n",
    "        assert self.noise.dtype == np.float32\n",
    "        self.noise[:] = np.random.RandomState(seed).randn(count)  # 64-bit to 32-bit conversion here\n",
    "        #logger.info('Sampled {} bytes'.format(self.noise.size * 4))\n",
    "\n",
    "    def get(self, i, dim):\n",
    "        return self.noise[i:i + dim]\n",
    "\n",
    "    def sample_index(self, stream, dim):\n",
    "        return stream.randint(0, len(self.noise) - dim + 1)\n",
    "\n",
    "noise = SharedNoiseTable()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get flat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "op_get_flat = tf.concat([tf.reshape(v, [-1]) for v in trainable_variables], 0)\n",
    "\n",
    "def get_flat(var_list):\n",
    "    return sess.run(op_get_flat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set from flat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _create_set_from_flat_op():\n",
    "    shapes = [v.shape for v in trainable_variables]\n",
    "    total_size = np.sum([shape.num_elements() for shape in shapes])\n",
    "    \n",
    "    theta = tf.placeholder(tf.float32, [total_size])\n",
    "    \n",
    "    start=0\n",
    "    assigns = []\n",
    "    for (shape, v) in zip(shapes, trainable_variables):\n",
    "        size = shape.num_elements()\n",
    "        assigns.append(tf.assign(v, tf.reshape(theta[start:start+size], shape)))\n",
    "        start += size\n",
    "        \n",
    "    assert start == total_size\n",
    "    \n",
    "    return tf.group(*assigns)\n",
    " \n",
    "op_set_from_flat = _create_set_from_flat_op()\n",
    "\n",
    "def set_from_flat(var_list):\n",
    "    return sess.run(op_set_from_flat)   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rollout TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rollout(env, *, render=False, timestep_limit=None, save_obs=False, random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    t = 0\n",
    "    if save_obs:\n",
    "        obs = []\n",
    "    ob = env.reset()\n",
    "    for _ in range(timestep_limit):\n",
    "        ac = self.act(ob[None], random_stream=random_stream)[0]\n",
    "        if save_obs:\n",
    "            obs.append(ob)\n",
    "        ob, rew, done, _ = env.step(ac)\n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "        if done:\n",
    "            break\n",
    "    rews = np.array(rews, dtype=np.float32)\n",
    "    if save_obs:\n",
    "        return rews, t, np.array(obs)\n",
    "    return rews, t\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Worker method\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_worker(num_jobs, theta): #min_task_runtime=.2):\n",
    "\n",
    "    #with lock:\n",
    "    #    logger.info('run_worker: {}'.format(locals()))\n",
    "\n",
    "    assert isinstance(noise, SharedNoiseTable)\n",
    "\n",
    "    # Setup\n",
    "    #config, env, sess, policy = setup(exp, single_threaded=True)\n",
    "    env = gym.make(config.env_id)\n",
    "\n",
    "\n",
    "    # Random stream used for todo\n",
    "    rs = np.random.RandomState()\n",
    "    #worker_id = rs.randint(2 ** 31)\n",
    "\n",
    "    #assert policy.needs_ob_stat == (config.calc_obstat_prob != 0)\n",
    "\n",
    "    #while True:\n",
    "    # Prevent accessing empty array (master did not emit task yet)\n",
    "    #while not tasks:\n",
    "    #    time.sleep(0.05)\n",
    "\n",
    "    #task_data = tasks[-1]\n",
    "\n",
    "    #task_tstart = time.time()\n",
    "\n",
    "    #assert isinstance(task_data, Task)\n",
    "    #task_id = task_data.task_id\n",
    "    #assert isinstance(task_id, int)\n",
    "\n",
    "    #if policy.needs_ob_stat:\n",
    "    #    policy.set_ob_stat(task_data.ob_mean, task_data.ob_std)\n",
    "\n",
    "    # # todo whats this condition doing?\n",
    "    # if rs.rand() < config.eval_prob:\n",
    "    #     # Evaluation: noiseless weights and noiseless actions\n",
    "    #     policy.set_trainable_flat(task_data.params)\n",
    "    # \n",
    "    #     eval_rews, eval_length = policy.rollout(env)  # eval rollouts don't obey task_data.timestep_limit\n",
    "    #     eval_return = eval_rews.sum()\n",
    "    # \n",
    "    #     with lock:\n",
    "    #         logger.info('Eval result: task={} return={:.3f} length={}'.format(task_id, eval_return, eval_length))\n",
    "    # \n",
    "    #     result_queue.put(Result(\n",
    "    #         worker_id=worker_id,\n",
    "    #         noise_inds_n=None,\n",
    "    #         returns_n2=None,\n",
    "    #         signreturns_n2=None,\n",
    "    #         lengths_n2=None,\n",
    "    #         eval_return=eval_return,\n",
    "    #         eval_length=eval_length,\n",
    "    #         ob_sum=None,\n",
    "    #         ob_sumsq=None,\n",
    "    #         ob_count=None,\n",
    "    #         task_id=task_id\n",
    "    #     ))\n",
    "\n",
    "    # Rollouts with noise\n",
    "    noise_inds, returns, signreturns, lengths = [], [], [], []\n",
    "    #task_ob_stat = RunningStat(env.observation_space.shape, eps=0.)  # eps=0 because we're incrementing only\n",
    "    \n",
    "    #while not noise_inds or time.time() - task_tstart < min_task_runtime:\n",
    "    \n",
    "    for _ in range(num_jobs):\n",
    "        # ------------- Noise sample -------------------------------\n",
    "        noise_idx = noise.sample_index(rs, num_params)\n",
    "        v = config.noise_stdev * noise.get(noise_idx, num_params)\n",
    "        \n",
    "        # Evaluate the sampled noise positive\n",
    "        set_from_flat(theta + v)\n",
    "        rews_pos, len_pos = rollout(env)\n",
    "\n",
    "        # rews_pos, len_pos = rollout_and_update_ob_stat(\n",
    "        #     policy, env, task_data.timestep_limit, rs, task_ob_stat, config.calc_obstat_prob)\n",
    "        \n",
    "        # Evaluate the sample noise negative\n",
    "        set_from_flat(theta - v)\n",
    "        rews_neg, len_neg = rollout(env)\n",
    "        \n",
    "        # rews_neg, len_neg = rollout_and_update_ob_stat(\n",
    "        #     policy, env, task_data.timestep_limit, rs, task_ob_stat, config.calc_obstat_prob)\n",
    "        \n",
    "        # Gather results\n",
    "        noise_inds.append(noise_idx)\n",
    "        returns.append([rews_pos.sum(), rews_neg.sum()])\n",
    "        signreturns.append([np.sign(rews_pos).sum(), np.sign(rews_neg).sum()])\n",
    "        lengths.append([len_pos, len_neg])\n",
    "        \n",
    "    # result_queue.put(Result(\n",
    "    #     worker_id=worker_id,\n",
    "    #     noise_inds_n=np.array(noise_inds),\n",
    "    #     returns_n2=np.array(returns, dtype=np.float32),\n",
    "    #     signreturns_n2=np.array(signreturns, dtype=np.float32),\n",
    "    #     lengths_n2=np.array(lengths, dtype=np.int32),\n",
    "    #     eval_return=None,\n",
    "    #     eval_length=None,\n",
    "    #     ob_sum=None if task_ob_stat.count == 0 else task_ob_stat.sum,\n",
    "    #     ob_sumsq=None if task_ob_stat.count == 0 else task_ob_stat.sumsq,\n",
    "    #     ob_count=task_ob_stat.count,\n",
    "    #     task_id=task_id\n",
    "    # ))\n",
    "    result = Result(\n",
    "        worker_id=None,\n",
    "        noise_inds=noise_inds,\n",
    "        returns_n2=returns,\n",
    "        signreturns_n2=signreturns,\n",
    "        lengths_n2=lengths,\n",
    "        eval_return=None,\n",
    "        eval_length=None,\n",
    "        ob_sum=None,\n",
    "        ob_count=None,\n",
    "        task_id = 0\n",
    "    )\n",
    "    \n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Master"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "env = gym.make(config.env_id)\n",
    "rs = np.random.RandomState()\n",
    "\n",
    "\n",
    "# ob_stat = RunningStat(\n",
    "#     env.observation_space.shape,\n",
    "#     eps=1e-2  # eps to prevent dividing by zero at the beginning when computing mean/stdev\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "tslimit, incr_tslimit_threshold, tslimit_incr_ratio = None, None, None\n",
    "adaptive_tslimit = False\n",
    "\n",
    "\n",
    "episodes_so_far = 0\n",
    "timesteps_so_far = 0\n",
    "tstart = time.time()\n",
    "\n",
    "task_counter = 0\n",
    "\n",
    "while True:\n",
    "    step_tstart = time.time()\n",
    "\n",
    "    # Flatten the trainable variables and store them in theta TODO shorten this code\n",
    "    def var_shape(x):\n",
    "        \"\"\"\n",
    "        Return the dimensions of a Tensor in an integer list.\n",
    "    \n",
    "        :param x: The Tensor from which one wants the dimensions\n",
    "        :return: A list of integers with the dimensions from x\n",
    "        \"\"\"\n",
    "        out = [k.value for k in x.get_shape()]\n",
    "        assert all(isinstance(a, int) for a in out), \\\n",
    "            \"shape function assumes that shape is fully known\"\n",
    "        return out\n",
    "    \n",
    "    def numel(x):\n",
    "        \"\"\"\n",
    "        Calculate the product of the dimensions of x.\n",
    "    \n",
    "        :param x: Tensor\n",
    "        :return: Integer value\n",
    "        \"\"\"\n",
    "        return intprod(var_shape(x))\n",
    "    \n",
    "    def intprod(x):\n",
    "        \"\"\"\n",
    "        Calculates the product of all members of the given array x and casts it to int.\n",
    "    \n",
    "        :param x: Array which elements shall be multiplied\n",
    "        :return: The integer value of the multiplication\n",
    "        \"\"\"\n",
    "        return int(np.prod(x))\n",
    "        \n",
    "    \n",
    "    x = [tf.reshape(v, [numel(v)]) for v in trainable_variables]\n",
    "    theta = session.run(tf.concat(x,0))\n",
    "    \n",
    "    #%%\n",
    "    \n",
    "    assert theta.dtype == np.float32\n",
    "\n",
    "    # Task counter is used to recognize false tasks from previous iterations later\n",
    "    curr_task_id = task_counter\n",
    "    task_counter += 1\n",
    "\n",
    "    # tasks.append(Task(\n",
    "    #         params=theta,\n",
    "    #         ob_mean=ob_stat.mean if policy.needs_ob_stat else None,\n",
    "    #         ob_std=ob_stat.std if policy.needs_ob_stat else None,\n",
    "    #         timestep_limit=tslimit,\n",
    "    #         task_id = curr_task_id\n",
    "    # ))\n",
    "    \n",
    "    # Start workers\n",
    "\n",
    "    # Pop off results for the current task\n",
    "    curr_task_results, eval_rets, eval_lens, worker_ids = [], [], [], []\n",
    "    num_results_skipped, num_episodes_popped, num_timesteps_popped, ob_count_this_batch = 0, 0, 0, 0\n",
    "    while num_episodes_popped < config.episodes_per_batch:\n",
    "        # Wait for a result\n",
    "        result = pop_item(result_queue, lock)\n",
    "\n",
    "        assert isinstance(result, Result)\n",
    "        task_id = result.task_id\n",
    "        assert isinstance(task_id, int)\n",
    "\n",
    "        assert (result.eval_return is None) == (result.eval_length is None)\n",
    "        worker_ids.append(result.worker_id)\n",
    "\n",
    "        if result.eval_length is not None:\n",
    "            # This was an eval job\n",
    "            episodes_so_far += 1\n",
    "            timesteps_so_far += result.eval_length\n",
    "            # Store the result only for current tasks\n",
    "            if task_id == curr_task_id:\n",
    "                eval_rets.append(result.eval_return)\n",
    "                eval_lens.append(result.eval_length)\n",
    "        else:\n",
    "            # The real shit\n",
    "            assert (result.noise_inds_n.ndim == 1 and\n",
    "                    result.returns_n2.shape == result.lengths_n2.shape == (len(result.noise_inds_n), 2))\n",
    "            assert result.returns_n2.dtype == np.float32\n",
    "            # Update counts\n",
    "            result_num_eps = result.lengths_n2.size\n",
    "            result_num_timesteps = result.lengths_n2.sum()\n",
    "            episodes_so_far += result_num_eps\n",
    "            timesteps_so_far += result_num_timesteps\n",
    "            # Store results only for current tasks\n",
    "            if task_id == curr_task_id:\n",
    "                curr_task_results.append(result)\n",
    "                num_episodes_popped += result_num_eps\n",
    "                num_timesteps_popped += result_num_timesteps\n",
    "                # Update ob stats\n",
    "                if policy.needs_ob_stat and result.ob_count > 0:\n",
    "                    ob_stat.increment(result.ob_sum, result.ob_sumsq, result.ob_count)\n",
    "                    ob_count_this_batch += result.ob_count\n",
    "            else:\n",
    "                num_results_skipped += 1\n",
    "\n",
    "    # Compute skip fraction\n",
    "    frac_results_skipped = num_results_skipped / (num_results_skipped + len(curr_task_results))\n",
    "    if num_results_skipped > 0:\n",
    "        logger.warning('Skipped {} out of date results ({:.2f}%)'.format(\n",
    "            num_results_skipped, 100. * frac_results_skipped))\n",
    "\n",
    "    # Assemble results\n",
    "    noise_inds_n = np.concatenate([r.noise_inds_n for r in curr_task_results])\n",
    "    returns_n2 = np.concatenate([r.returns_n2 for r in curr_task_results])\n",
    "    lengths_n2 = np.concatenate([r.lengths_n2 for r in curr_task_results])\n",
    "    assert noise_inds_n.shape[0] == returns_n2.shape[0] == lengths_n2.shape[0]\n",
    "    # Process returns\n",
    "    if config.return_proc_mode == 'centered_rank':\n",
    "        proc_returns_n2 = compute_centered_ranks(returns_n2)\n",
    "    elif config.return_proc_mode == 'sign':\n",
    "        proc_returns_n2 = np.concatenate([r.signreturns_n2 for r in curr_task_results])\n",
    "    elif config.return_proc_mode == 'centered_sign_rank':\n",
    "        proc_returns_n2 = compute_centered_ranks(np.concatenate([r.signreturns_n2 for r in curr_task_results]))\n",
    "    else:\n",
    "        raise NotImplementedError(config.return_proc_mode)\n",
    "    # Compute and take step\n",
    "    g, count = batched_weighted_sum(\n",
    "        proc_returns_n2[:, 0] - proc_returns_n2[:, 1],\n",
    "        (noise.get(idx, policy.num_params) for idx in noise_inds_n),\n",
    "        batch_size=500\n",
    "    )\n",
    "    g /= returns_n2.size\n",
    "    assert g.shape == (policy.num_params,) and g.dtype == np.float32 and count == len(noise_inds_n)\n",
    "    #update_ratio = optimizer.update(-g + config.l2coeff * theta)\n",
    "    update_ratio = optimizer.update(config.l2coeff * g)\n",
    "\n",
    "    # Update ob stat (we're never running the policy in the master, but we might be snapshotting the policy)\n",
    "    if policy.needs_ob_stat:\n",
    "        policy.set_ob_stat(ob_stat.mean, ob_stat.std)\n",
    "\n",
    "    # Update number of steps to take\n",
    "    if adaptive_tslimit and (lengths_n2 == tslimit).mean() >= incr_tslimit_threshold:\n",
    "        old_tslimit = tslimit\n",
    "        tslimit = int(tslimit_incr_ratio * tslimit)\n",
    "        logger.info('Increased timestep limit from {} to {}'.format(old_tslimit, tslimit))\n",
    "\n",
    "    step_tend = time.time()\n",
    "    tlogger.record_tabular(\"EpRewMean\", returns_n2.mean())\n",
    "    tlogger.record_tabular(\"EpRewStd\", returns_n2.std())\n",
    "    tlogger.record_tabular(\"EpLenMean\", lengths_n2.mean())\n",
    "\n",
    "    tlogger.record_tabular(\"EvalEpRewMean\", np.nan if not eval_rets else np.mean(eval_rets))\n",
    "    tlogger.record_tabular(\"EvalEpRewStd\", np.nan if not eval_rets else np.std(eval_rets))\n",
    "    tlogger.record_tabular(\"EvalEpLenMean\", np.nan if not eval_rets else np.mean(eval_lens))\n",
    "    tlogger.record_tabular(\"EvalPopRank\", np.nan if not eval_rets else (\n",
    "        np.searchsorted(np.sort(returns_n2.ravel()), eval_rets).mean() / returns_n2.size))\n",
    "    tlogger.record_tabular(\"EvalEpCount\", len(eval_rets))\n",
    "\n",
    "    tlogger.record_tabular(\"Norm\", float(np.square(policy.get_trainable_flat()).sum()))\n",
    "    tlogger.record_tabular(\"GradNorm\", float(np.square(g).sum()))\n",
    "    tlogger.record_tabular(\"UpdateRatio\", float(update_ratio))\n",
    "\n",
    "    tlogger.record_tabular(\"EpisodesThisIter\", lengths_n2.size)\n",
    "    tlogger.record_tabular(\"EpisodesSoFar\", episodes_so_far)\n",
    "    tlogger.record_tabular(\"TimestepsThisIter\", lengths_n2.sum())\n",
    "    tlogger.record_tabular(\"TimestepsSoFar\", timesteps_so_far)\n",
    "\n",
    "    num_unique_workers = len(set(worker_ids))\n",
    "    tlogger.record_tabular(\"UniqueWorkers\", num_unique_workers)\n",
    "    tlogger.record_tabular(\"UniqueWorkersFrac\", num_unique_workers / len(worker_ids))\n",
    "    tlogger.record_tabular(\"ResultsSkippedFrac\", frac_results_skipped)\n",
    "    tlogger.record_tabular(\"ObCount\", ob_count_this_batch)\n",
    "\n",
    "    tlogger.record_tabular(\"TimeElapsedThisIter\", step_tend - step_tstart)\n",
    "    tlogger.record_tabular(\"TimeElapsed\", step_tend - tstart)\n",
    "    tlogger.dump_tabular()\n",
    "\n",
    "    if config.snapshot_freq != 0 and curr_task_id % config.snapshot_freq == 0:\n",
    "        import os.path as osp\n",
    "        filename = osp.join(tlogger.get_dir(), 'snapshot_iter{:05d}_rew{}.h5'.format(\n",
    "            curr_task_id,\n",
    "            np.nan if not eval_rets else int(np.mean(eval_rets))\n",
    "        ))\n",
    "        assert not osp.exists(filename)\n",
    "        policy.save(filename)\n",
    "        tlogger.log('Saved snapshot {}'.format(filename))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}