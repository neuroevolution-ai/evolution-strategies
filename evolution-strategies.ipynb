{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIT License\n",
    "\n",
    "Copyright (c) 2016 OpenAI (http://openai.com)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in\n",
    "all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using evolution strategies to train Roboschool Environments\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook is based on the [paper](https://arxiv.org/abs/1703.03864), [blog article](https://openai.com/blog/evolution-strategies/) and [implementation](https://github.com/openai/evolution-strategies-starter) of OpenAI on the topic of using an evolution strategy algorithm for a typical reinforcement learning task. \n",
    "\n",
    "My implementation summarizes their implementation, by simplifying, refactoring and organizing the code into this Jupyter notebook which can be used to test the algorithm. One can tweak the hyperparameters, change the environment which shall be trained or even expand the implementation to support for example Atari environments.\n",
    "\n",
    "I recommend reading the paper or at least the article before trying out the notebook. Also depending on the environment the training can be very computationally intense (for example training the Humanoid), so if you want to try out the harder ones I recommend using a highly parallelizable machine, i.e. a machine with a high number of cores/threads which can use multiple processes simultaneously.\n",
    "\n",
    "## Algorithm overview\n",
    "\n",
    "This section gives a brief overview over the algorithm. First of all we need to define what this implementation is going to do. The Roboschool is a group of environments in the [OpenAi Gym](https://gym.openai.com/), a program to test the behavior of machine learning algorithms on _real world_ problems. In our case, we want to train different robotic environments using an evolutionary algorithm which belongs to the class of natural evolution strategies. We therefore define a neural net with a configurable number of hidden layers, where the input dimension equals the observation space of the environment and the dimension of the output layer equals the dimension of the action space of the environment. This neural net is also called policy or in this implementation also referred to as a model. Therefore we train our policy to output the best possible action sequence given an observation sequence. Now, how do we train this policy? Training an evolutionary strategy consists of a cycle which is repeated over and over. First, an initial weight vector is randomly generated. In our context this weight vector is equal to the weights of our policy. Then we perturb the vector with gaussian noise. The number of perturbations is called the population size. What we now have is a population of slightly different weight vectors compared with the weight vector we started. Each one of these vectors will then be evaluated by first updating our policy with the weights and then run the environment using the policy. When this is done for the whole population, we calculate a gradient ascent step in the direction of steepest ascent. In our case, where we are dealing with natural evolution strategies, we calculate the step with the natural gradient. This is done by approximating this gradient using Monte Carlo estimates.\n",
    "\n",
    "So lets say we have our initial weight vector $\\theta$, a population size $n$, random perturbations $\\epsilon_i$, $0 \\leq i \\leq n$, learning rate $\\alpha$, noise standard deviation $\\sigma$ and a fitness Function $F(\\cdot)$. We then calculate the resulting weight vector like this:\n",
    "$\\theta_{t+1} = \\theta_{t} + \\alpha \\frac{1}{n \\sigma} \\sum \\limits_{i=0}^n F(\\theta_{t} + \\epsilon_i)$\n",
    "\n",
    "\n",
    "This gives us the weight vector for the next cycle which we will then, again, perturb a number of times (depending on the population size). A cycle in the context of evolutionary strategies is called a generation.\n",
    "\n",
    "One might ask himself now what this fitness function is in the context of robotic simulations. When initializing such an environment one can call the `step` function on the environment with an array in the shape of the action space (in our case this would be the output of the policy). The environment then evaluates the provided action based on the current observation and other parameters in the environment and outputs a reward. This is done for either a fixed number of timesteps (some environments have a maximum of timesteps defined) or stops, when the action resulted in a state where the environment is `done`, for example when the `Humanoid` environment falls over and touches the surface. The rewards get summed up for every timestep which forms the reward for one action.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before starting any computation we need to configure the training and define some methods and objects we will use later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Note that TensorFlow does not get imported here. We will only import it inside of a function which runs in another process. This is due to the fact that when importing TensorFlow a session is created in the background which will interefere with our models which we run in subprocesses. When importing the package only inside a function and then running these functions inside of subprocesses, every process has its own TensorFlow session and they therefore don't interfere with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import errno\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import ctypes\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "import gym, roboschool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging and save directory\n",
    "\n",
    "For evaluating the trained data we need to define a directory where we want to store the trained policies, as well as the log file to record the results of every generation.\n",
    "\n",
    "Depending on your disk space you may not want to save every model, but for an indepth evaluation this is necessary. During training there will be so called _evaluation runs_ which will not add noise but test the currently trained policy to give insight on training. But since it relies on probability the number of evaluation runs will not be equal through generations. An additional Jupyter Notebook with the prefix **-visualization** can be used after training to load all saved weight files and evaluate them a given number of times.\n",
    "\n",
    "If you want to change the location change the variable `save_directory` to a directory where the user which runs this notebook has write permissions. If it does not exist the program will create it. The default location is the /tmp/es_xx directory where xx is the process id of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "save_directory = \"/tmp/es_{}/\".format(os.getpid())\n",
    "mkdir_p(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configuration, Task and Result Classes\n",
    "\n",
    "Using `namedtuple` from the `collections` package from python allows us to quickly create small classes with different attributes, which is ideal for quickly accessing different attributes during training as well as saving the configurations to a file.\n",
    "\n",
    "Each attribute will be explained in a bit, where objects of these classes are created and their parameters are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Config = namedtuple('Config', [\n",
    "    'env_id',\n",
    "    'population_size',\n",
    "    'num_workers',\n",
    "    'learning_rate',\n",
    "    'noise_stdev',\n",
    "    'snapshot_freq',\n",
    "    'return_proc_mode',\n",
    "    'calc_obstat_prob',\n",
    "    'l2coeff',\n",
    "    'eval_prob'\n",
    "])\n",
    "\n",
    "Optimizations = namedtuple('Optimizations', [\n",
    "    'mirrored_sampling',\n",
    "    'fitness_shaping',\n",
    "    'weight_decay',\n",
    "    'discretize_actions',\n",
    "    'neural_network_optimizer',\n",
    "    'observation_normalization'\n",
    "])\n",
    "\n",
    "ModelStructure = namedtuple('ModelStructure', [\n",
    "    'ac_noise_std',\n",
    "    'ac_bins',\n",
    "    'hidden_dims',\n",
    "    'nonlin_type',\n",
    "    'nn_optimizer',\n",
    "    'nn_optimizer_args'\n",
    "])\n",
    "\n",
    "Task = namedtuple('Task', [\n",
    "    'theta', 'ob_mean', 'ob_std', 'task_id'])\n",
    "\n",
    "Result = namedtuple('Result', [\n",
    "    'noise_inds','returns', 'signreturns', 'lengths',\n",
    "    'eval_return', 'eval_length',\n",
    "    'ob_sum', 'ob_sumsq', 'ob_count',\n",
    "    'task_id',\n",
    "    'times_per_mutation',\n",
    "    'time_create_model', 'time_clear_sess', 'time_set_sess',\n",
    "    'times_set_flat', 'times_sample', 'times_get_noise',\n",
    "    'times_predict'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "#### Optimizations object\n",
    "\n",
    "First we start with the optimizations for the training, since other parameters are only used when the respective optimization is activated.\n",
    "\n",
    "All values can only be either `True` or `False`. The term _activated_ means the value is set to `True` in this context.\n",
    "\n",
    "When `mirrored_sampling` is activated, sampled noise gets used twice: One time it will get added to the parameter vector and the result gets evaluated and the other time it gets subtracted from the parameter vector and the result will be evaluated.\n",
    "\n",
    "`fitness_shaping` processes the rewards by applying a rank transformation.\n",
    "\n",
    "`weight_decay` is currently not implemented.\n",
    "\n",
    "`discretize_actions` can be used to bin the actions. This means that you can provide a number of uniformely shaped bins in which the output of the model will be put. For some environments this can encourage exploration behavior.\n",
    "\n",
    "`neural_network_optimizer` will use a neural network optimizer for the gradient ascent step, for example the `Adam` optimizer.\n",
    "\n",
    "`observation_normalization` When turned on, before an observation gets feeded into the neural network it will be subtracted by the observation mean and divided with the observation standard deviation. The observation mean and standard deviation get constantly updated on training based on the configured probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "optimizations = Optimizations(\n",
    "    mirrored_sampling=True,\n",
    "    fitness_shaping=True,\n",
    "    weight_decay=True,\n",
    "    discretize_actions=False,\n",
    "    neural_network_optimizer=True,\n",
    "    observation_normalization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Config object\n",
    "\n",
    "The config object will serve us as a general configuration for the training.\n",
    "\n",
    "First of all it defines the `env_id` which has to be a valid ID for a `Roboschool` environment, for example `RoboschoolAnt-v1`. A complete list can be found [here](https://github.com/openai/roboschool/blob/master/roboschool/__init__.py).\n",
    "\n",
    "`population_size` defines the number of perturbations per generation.\n",
    "\n",
    "`num_workers` defines the amount of parallel processes to be created during calculation and must be larger than 0. By default this value is the output of `os.cpu_count()` which allows the program to use the maximum amount of computational power in terms of the provided hardware.\n",
    "\n",
    "`learning_rate` defines how much the estimated gradient influences the next generation and must be larger than 0 for the training to work.\n",
    "\n",
    "`noise_stdev` is the standard devation for the noise and should be larger than 0. It cannot be equal to 0 since if it would be at some point there could then be a division by zero. Other than that it would not benefit training.\n",
    "\n",
    "`snapshot_freq` describes the frequency in which generations shall be saved to a `.h5` file. For example a snapshot frequency of 5 would save every fifth generation to a file. Setting it to 0 disables snapshotting.\n",
    "\n",
    "`return_proc_mode` translates to return processing mode and describes how the calculated rewards for a generation shall be processed. By default this is `centered_rank` which will calculate the ranks of the rewards. This option is only used when also activating the `fitness_shaping` optimization. One can choose between the three strings `RETURN_PROC_MODE_CR`, `RETURN_PROC_MODE_SIGN` and `RETURN_PROC_MODE_CR_SIGN`.\n",
    "\n",
    "`calc_obstat_prob` is the probability of saving the observations during a rollout (evaluating the fitness of a policy) and updating the observation mean and standard deviation. These values are used to normalize the input of a model which helps a neural network to generalize faster. The parameter is only used in combination with the `observation_normalization` optimization. Must be greater than 0 when using the optimization since otherwise it would waste performance while not normalizing.\n",
    "\n",
    "`eval_prob` is the probability of inserting an evaluation run. This is useful for training to quickly monitor the reward mean, reward standard deviation and length mean of the current generation. The value must be greater or equal 0 (equal 0 turns of the evaluation runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RETURN_PROC_MODE_CR = 'centered_rank'\n",
    "RETURN_PROC_MODE_SIGN = 'sign'\n",
    "RETURN_PROC_MODE_CR_SIGN = 'centered_sign_rank'\n",
    "\n",
    "config = Config(\n",
    "    env_id=\"RoboschoolAnt-v1\",\n",
    "    population_size=300,\n",
    "    num_workers=os.cpu_count(),\n",
    "    learning_rate=0.001,\n",
    "    noise_stdev=0.02,\n",
    "    snapshot_freq=1,\n",
    "    return_proc_mode=RETURN_PROC_MODE_CR,\n",
    "    calc_obstat_prob=0.01,\n",
    "    l2coeff=0.005,\n",
    "    eval_prob=0.003\n",
    ")\n",
    "\n",
    "assert config.population_size > 0\n",
    "assert config.num_workers > 0\n",
    "assert config.learning_rate > 0\n",
    "assert config.noise_stdev != 0\n",
    "assert config.eval_prob >= 0\n",
    "\n",
    "\n",
    "if (config.return_proc_mode != RETURN_PROC_MODE_CR\n",
    "    and config.return_proc_mode != RETURN_PROC_MODE_SIGN\n",
    "    and config.return_proc_mode != RETURN_PROC_MODE_CR_SIGN):\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    \n",
    "if optimizations.observation_normalization:\n",
    "    assert config.calc_obstat_prob > 0\n",
    "\n",
    "if optimizations.neural_network_optimizer:\n",
    "    assert config.l2coeff > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelStructure object\n",
    "\n",
    "The ModelStructure object defines the overall structure of the neural network.\n",
    "\n",
    "`ac_noise_std` is the standard deviation for the noise which is added during training. Adding noise shall generalize the training. It must be greater than 0, or equal to 0 for no noise.\n",
    "\n",
    "When using the `discretize_actions` optimizations, `ac_bins` defines into how much uniformely spaced bins the actions shall be put. For example if the possible action values range from -1 to 1 and one defines 5 action bins the model will output values from $\\{-1, -0.5, 0, 0.5, 1\\}$. If you use the optimization the number of bins must be greater than 0.\n",
    "\n",
    "`hidden_dims` define the number of hidden layers and their dimensions. It must be a list of positive Integers.\n",
    "\n",
    "`nonlin_type` defines the activation function for the hidden layers. Can be `tanh`, `relu`, `lrelu` or `elu` for the hyperbolic tangent, rectified linear, leaky ReLU and the exponential linear. If something else is defined `tanh` will be picked.\n",
    "\n",
    "`nn_optimizer` is only used when the `neural_network_optimizer` optimization is turned on. It can be `adam` for the Adam optimizer or `sgd` for the SGD Optimizer. Defining anything other will result in an error.\n",
    "\n",
    "`nn_optimizer_args` is only used when the `neural_network_optimizer` optimization is turned on. This will be feeded into the constructor of the optimizer. For the Adam and SGD optimizer one must specify the `stepsize` but can also specify other optimizer specific attributes. Please check the constructor signature for the names. If you specify something else than stepsize be careful, this does not get checked for errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "OPTIMIZER_ADAM = 'adam'\n",
    "OPTIMIZER_SGD = 'sgd'\n",
    "\n",
    "model_structure = ModelStructure(\n",
    "    ac_noise_std=0.01,\n",
    "    ac_bins=5,\n",
    "    hidden_dims=[256, 256],\n",
    "    nonlin_type='tanh',\n",
    "    nn_optimizer=OPTIMIZER_ADAM,\n",
    "    nn_optimizer_args={\n",
    "        'stepsize': 0.01\n",
    "    }\n",
    ")\n",
    "\n",
    "assert model_structure.ac_noise_std >= 0\n",
    "assert isinstance(model_structure.hidden_dims, list)\n",
    "assert all(hd >= 0 for hd in model_structure.hidden_dims)\n",
    "\n",
    "if optimizations.neural_network_optimizer:\n",
    "    if model_structure.nn_optimizer != OPTIMIZER_ADAM and model_structure.nn_optimizer != OPTIMIZER_SGD:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    try:\n",
    "        stepsize = model_structure.nn_optimizer_args['stepsize']\n",
    "        assert stepsize > 0\n",
    "    except KeyError:\n",
    "        print(\"Please provide the stepsize parameter.\")\n",
    "\n",
    "if optimizations.discretize_actions:\n",
    "    assert model_structure.ac_bins > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task class\n",
    "\n",
    "During training the master will enqueue a new Task object per generation. The workers will then take the latest task, compute it and push a result object on a queue. In the following table the attributes of a task object are explained in depth.\n",
    "\n",
    "| Attribute | Explanation |\n",
    "| :---------|:------------|\n",
    "| `theta`   | The one-dimensional parameter vector of this task, i.e. the current generation|\n",
    "| `ob_mean` | When observation normalization is used this is the current mean of the observed observation |\n",
    "| `ob_std`  | When observation normalization is used this is the current standard deviation of the observed observation|\n",
    "| `task_id` | The ID of this Task, which equals the generation number |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result class\n",
    "\n",
    "An object of the Result class will define a computed task by the workers. This can either be an evaluation task, where no noise gets added and the policy will simply be evaluated on the environment or a regular task. This means that the noise gets sampled, added (and subtracted when mirrored sampling is used) and evaluated. The following table gives a more detailed information on each attribute.\n",
    "\n",
    "| Attribute             | Explanation   |\n",
    "| :---------------------|:--------------|\n",
    "| `noise_inds`        | A numpy array with the indices of the used noise|\n",
    "| `returns`        | A numpy array with the rewards. When mirrored sampling is used this list is two dimensional| |`signreturns` | The sum of the signs of the rewards. When mirrored sampling is used this list is two dimensional| |`lengths` | A numpy array with the sum of the timesteps. When mirrored sampling is used this list is two dimensional|\n",
    "| `eval_return` | np.nan if this was not an evaluation task, otherwise a numpy array with the reward of the evaluation|\n",
    "| `eval_length`|np.nan if this was not an evaluation task, otherwise a numpy array with the timesteps of the evaluation| |`ob_sum` | If observation normalization is used this contains the sum of the tracked observations |\n",
    "| `ob_sumsq` | If observation normalization is used this contains the squared sum of the tracked observations |\n",
    "| `ob_count` | If observation normalization is used this contains the amount of tracked observations|\n",
    "| `task_id` | The ID of the task that has been calculated|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the configuration\n",
    "\n",
    "After specifying all necessary configurations, they get saved to the `save_directory` so when training is done one can reproduce the training with the exact parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_directory + 'config.json', 'w', encoding='utf-8') as f:\n",
    "    chained_dict = OrderedDict([\n",
    "        ('config', config._asdict()),\n",
    "        ('model_structure', model_structure._asdict()),\n",
    "        ('optimizations', optimizations._asdict())])\n",
    "\n",
    "    json.dump(chained_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Function and variable definitions\n",
    "\n",
    "### Environment\n",
    "\n",
    "Before we continue we must create the environment object and the observation and action space variables. They are needed for constructing the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(config.env_id)\n",
    "\n",
    "ob_space = env.observation_space\n",
    "ac_space = env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using Keras for the models\n",
    "\n",
    "The original implementation from OpenAI used chained TensorFlow operations to construct the model. This notebook however, uses Keras (which is integrated into TensorFlow) as a high-level API to construct `Model` objects. These objects are, in our case, chained layers which will represent our neural network.\n",
    "\n",
    "Also, note that all imports of TensorFlow need to be inside function definitions and these functions can only be called inside subprocesses. This is needed since importing TensorFlow automatically starts a background session which would be inherited to then started subprocesses. Therefore each worker would have the same TensorFlow session which would interfere with their respective models. Another noteworthy finding is that when creating Keras models in a loop there will be a memory leak when one does not clear the session. This will be adressed in the `run_worker` method.\n",
    "\n",
    "In the following cell the method `create_model` creates and returns a Keras model as defined with the configurations. It needs to have the `ob_space` and `ac_space` variable set to the observation space and action space of the used environment in training, because they define the input and output dimension.\n",
    "\n",
    "After adding an input layer the method will add the custom `ObservationNormalizationLayer` if the `observation_normalization` optimization is turned on. This layer uses the method parameters `ob_mean` and `ob_std` to normalize the input $o$ with this equation $\\frac{o - \\text{ob_mean}}{\\text{ob_std}}$ and clip the values to $[-5, 5]$.\n",
    "\n",
    "After that depending on the dimension and number of hidden layers defined these hidden layers get added as Dense layers. If the `discretize_actions` optimization is turned on the custom `DiscretizeActionsLayer`\n",
    "\n",
    "All weights use the custom defined `Normc_initializer` to initialize their weights. This is copied from the OpenAI implementation, since initializing them differently can lead to a large minus reward when starting the training.\n",
    "**TODO** low std, e.g. std=0.01 leads to a more stable result.\n",
    "\n",
    "\n",
    "\n",
    "The method will create an input layer in the shape of the observation space, optionally add the custom `ObservationNormalizationLayer` if the `observation_normalization` optimization is turned on, add the specified hidden layers with their dimensions and adds the output layer. If the `discretize_actions` optimization is turned on another layer gets added which will serve as a transformation for the output into the bins.\n",
    "\n",
    "When `initial_weights` is provided the model will be updated with these weights. They need to be in the correct shape for the model. When the function is called with a valid `save_path` the model gets saved to this path.\n",
    "\n",
    "`ob_mean` and `ob_std` are only needed for the normalizing of the observation space. If it is turned on the input gets subtracted with `ob_mean`, divided by `ob_std` and clipped to $[-5,5]$.\n",
    "\n",
    "The two custom classes `ObservationNormalizationLayer` and `Normc_initializer` need to be supplied when loading a saved model. An example and also visualizing the trained data can be found in the other Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(initial_weights=None, model_name=\"model\", save_path=None, ob_mean=None, ob_std=None):\n",
    "       \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    class Normc_initializer(tf.keras.initializers.Initializer):\n",
    "        \"\"\"\n",
    "        Create a TensorFlow constant with random numbers normed in the given shape.\n",
    "        :param std:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        def __init__(self, std=1.0):\n",
    "            self.std=std\n",
    "\n",
    "        def __call__(self, shape, dtype=None, partition_info=None):#pylint: disable=W0613\n",
    "            out = np.random.randn(*shape).astype(np.float32)\n",
    "            out *= self.std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            return tf.constant(out)\n",
    "    \n",
    "    class ObservationNormalizationLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, ob_mean, ob_std, **kwargs):\n",
    "            self.ob_mean = ob_mean\n",
    "            self.ob_std = ob_std\n",
    "            super(ObservationNormalizationLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):\n",
    "            return tf.clip_by_value((x - self.ob_mean) / self.ob_std, -5.0, 5.0)\n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(ObservationNormalizationLayer, self).get_config()\n",
    "            base_config['ob_mean'] = self.ob_mean\n",
    "            base_config['ob_std'] = self.ob_std\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "        \n",
    "    class DiscretizeActionsUniformLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, num_ac_bins, adim, ahigh, alow, **kwargs):\n",
    "            self.num_ac_bins = num_ac_bins\n",
    "            self.adim = adim\n",
    "            self.ahigh = ahigh\n",
    "            self.alow = alow\n",
    "            super(DiscretizeActionsUniformLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):            \n",
    "            # Reshape to [n x i x j] where n is dynamically chosen, i equals action dimension and j equals the number\n",
    "            # of bins\n",
    "            scores_nab = tf.reshape(x, [-1, self.adim, self.num_ac_bins])\n",
    "            # This picks the bin with the greatest value\n",
    "            a = tf.argmax(scores_nab, 2)\n",
    "            \n",
    "            # Then transform the interval from [0, num_ac_bins - 1] to [-1, 1] which equals alow and ahigh\n",
    "            ac_range_1a = (self.ahigh - self.alow)[None, :]\n",
    "            return 1. / (self.num_ac_bins - 1.) * tf.keras.backend.cast(a, 'float32') * ac_range_1a + self.alow[None, :]        \n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(DiscretizeActionsUniformLayer, self).get_config()\n",
    "            base_config['num_ac_bins'] = self.num_ac_bins\n",
    "            base_config['adim'] = self.adim\n",
    "            base_config['ahigh'] = self.ahigh\n",
    "            base_config['alow'] = self.alow\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "    \n",
    "    nonlin = tf.nn.tanh\n",
    "    \n",
    "    if model_structure.nonlin_type == 'relu':\n",
    "        nonlin = tf.nn.relu\n",
    "    elif model_structure.nonlin_type == 'lrelu':\n",
    "        nonlin = tf.nn.leaky_relu\n",
    "    elif model_structure.nonlin_type == 'elu':\n",
    "        nonlin = tf.nn.leaky_relu\n",
    "\n",
    "    # Policy network\n",
    "    input_layer = x = tf.keras.Input(ob_space.shape, dtype=tf.float32)\n",
    "    \n",
    "    if ob_mean is not None and ob_std is not None and optimizations.observation_normalization:\n",
    "        if ob_std.all() != 0:\n",
    "            x = ObservationNormalizationLayer(ob_mean, ob_std)(x)\n",
    "                \n",
    "    for hd in model_structure.hidden_dims:\n",
    "        x = tf.keras.layers.Dense(\n",
    "            hd, activation=nonlin,\n",
    "            kernel_initializer=Normc_initializer(std=1.0),\n",
    "            bias_initializer=tf.initializers.zeros())(x)\n",
    "\n",
    "    # Action dimension and the lowest and highest possible values for an action\n",
    "    adim, ahigh, alow = ac_space.shape[0], ac_space.high, ac_space.low        \n",
    "    \n",
    "    if optimizations.discretize_actions:\n",
    "        num_ac_bins = int(model_structure.ac_bins)\n",
    "        x = tf.keras.layers.Dense(\n",
    "                        adim * num_ac_bins,\n",
    "                        kernel_initializer=Normc_initializer(std=0.01),\n",
    "                        bias_initializer=tf.initializers.zeros())(x)\n",
    "        a = DiscretizeActionsUniformLayer(num_ac_bins, adim, ahigh, alow)(x)\n",
    "    else:\n",
    "        a = tf.keras.layers.Dense(\n",
    "            adim,\n",
    "            kernel_initializer=Normc_initializer(std=0.01),\n",
    "            bias_initializer=tf.initializers.zeros())(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=a, name=model_name)\n",
    "    \n",
    "    if initial_weights is not None:\n",
    "        set_from_flat(model, initial_weights)\n",
    "        \n",
    "    if save_path:\n",
    "        model.save(save_path)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the act function\n",
    "\n",
    "The `act` function gets called every time the environment gives out the current observation. It will use the provided `ob` and `model` to predict the best action and returns it. When a `random_stream` is provided, which is done by default in training, noise gets added to the predicted training to make the model more robust and generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def act(ob, model, random_stream=None):\n",
    "    time_predict_s = time.time()\n",
    "    action = model.predict_on_batch(ob)\n",
    "    time_predict_e = time.time() - time_predict_s\n",
    "\n",
    "    if random_stream is not None and model_structure.ac_noise_std != 0:\n",
    "        action += random_stream.randn(*action.shape) * model_structure.ac_noise_std\n",
    "    return action, time_predict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class RunningStat(object):\n",
    "    def __init__(self, shape, eps):\n",
    "        self.sum = np.zeros(shape, dtype=np.float32)\n",
    "        self.sumsq = np.full(shape, eps, dtype=np.float32)\n",
    "        self.count = eps\n",
    "\n",
    "    def increment(self, s, ssq, c):\n",
    "        self.sum += s\n",
    "        self.sumsq += ssq\n",
    "        self.count += c\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.sum / self.count\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(np.maximum(self.sumsq / self.count - np.square(self.mean), 1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifiying the number of paramters\n",
    "\n",
    "For the Optimizer classes we need the total amount of parameters in our models. For this we define the `get_initial_weights` methods, which will create us a normal model, prints its layout and returns the random weights.\n",
    "Remember this needs to be done in a subprocess so we call a `multiprocessing` `Pool` which allows us to spawn a subprocess and return the weights. \n",
    "\n",
    "We then calculate the number of parameters from our weight vector $\\theta$. The weight vector is also important for later, because it will be the starting weight vector for our training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ob_stat = RunningStat(\n",
    "    env.observation_space.shape,\n",
    "    eps=1e-2  # eps to prevent dividing by zero at the beginning when computing mean/stdev\n",
    "    )\n",
    "\n",
    "model = create_model(ob_mean=ob_stat.mean, ob_std=ob_stat.std)\n",
    "model.summary()\n",
    "ob = np.ones(ob_space.shape)\n",
    "a = model.predict(ob[None])\n",
    "\n",
    "#a = np.reshape(a, [adim, 10])\n",
    "#a[1][0] += 1\n",
    "#a = np.argmax(a, 1)\n",
    "\n",
    "#a = np.clip(a, -1., 1.)\n",
    "#adim, ahigh, alow = ac_space.shape[0], ac_space.high, ac_space.low \n",
    "#ac_range_1a = (ahigh - alow)[None, :]\n",
    "#(lambda a: 1. / (10 - 1.) * a * ac_range_1a + alow[None, :])(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_weights(ob_mean=None, ob_std=None):\n",
    "    \n",
    "    model = create_model(ob_mean=ob_mean, ob_std=ob_std)\n",
    "    \n",
    "    # Print out the model\n",
    "    model.summary()\n",
    "    \n",
    "    return model.get_weights()\n",
    "\n",
    "with multiprocessing.Pool(1) as pool:\n",
    "    if optimizations.observation_normalization:\n",
    "        ob_stat = RunningStat(\n",
    "            env.observation_space.shape,\n",
    "            eps=1e-2  # eps to prevent dividing by zero at the beginning when computing mean/stdev\n",
    "            )\n",
    "        theta = pool.apply(func=get_initial_weights, args=(ob_stat.mean, ob_stat.std))\n",
    "    else:\n",
    "        theta = pool.apply(func=get_initial_weights)\n",
    "\n",
    "num_params = sum(np.prod(v.shape) for v in theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization: Using neural network optimizer\n",
    "\n",
    "These optimizer are copied from the implementation from OpenAI. They are impemented in Keras but need a loss function to work which we do not have when using \n",
    "\n",
    "Defining it manually since with Keras you have to define a loss function and use training set, etc. Manually seems\n",
    "easier for now.\n",
    "Completely copied from OpenAI, except for not using the policy variable but providing theta directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self):\n",
    "        self.dim = num_params\n",
    "        self.t = 0\n",
    "\n",
    "    def update(self, theta, globalg):\n",
    "        self.t += 1\n",
    "        step = self._compute_step(globalg)\n",
    "        ratio = np.linalg.norm(step) / np.linalg.norm(theta)\n",
    "        theta_new = theta + step\n",
    "        return theta_new, ratio\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, stepsize, momentum=0.9):\n",
    "        Optimizer.__init__(self)\n",
    "        self.v = np.zeros(self.dim, dtype=np.float32)\n",
    "        self.stepsize, self.momentum = stepsize, momentum\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        self.v = self.momentum * self.v + (1. - self.momentum) * globalg\n",
    "        step = -self.stepsize * self.v\n",
    "        return step\n",
    "        \n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, stepsize, beta1=0.9, beta2=0.999, epsilon=1e-08):\n",
    "        Optimizer.__init__(self)\n",
    "        self.stepsize = stepsize\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = np.zeros(self.dim, dtype=np.float32)\n",
    "        self.v = np.zeros(self.dim, dtype=np.float32)\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        a = self.stepsize * np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * globalg\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (globalg * globalg)\n",
    "        step = -a * self.m / (np.sqrt(self.v) + self.epsilon)\n",
    "        return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if optimizations.neural_network_optimizer:\n",
    "    if model_structure.nn_optimizer == OPTIMIZER_ADAM:\n",
    "        optimizer = Adam(**model_structure.nn_optimizer_args)\n",
    "    elif model_structure.nn_optimizer == OPTIMIZER_SGD:\n",
    "        optimizer = SGD(**model_structure.nn_optimizer_args)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Shared Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SharedNoiseTable(object):\n",
    "    def __init__(self):\n",
    "        seed = 123\n",
    "        count = 250000000  # 1 gigabyte of 32-bit numbers. Will actually sample 2 gigabytes below.\n",
    "        print('Sampling {} random numbers with seed {}'.format(count, seed))\n",
    "\n",
    "        # Instantiate an array of C float datatype with size count\n",
    "        self._shared_mem = multiprocessing.Array(ctypes.c_float, count)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        self.noise = np.ctypeslib.as_array(self._shared_mem.get_obj())\n",
    "        assert self.noise.dtype == np.float32\n",
    "        self.noise[:] = np.random.RandomState(seed).randn(count)  # 64-bit to 32-bit conversion here\n",
    "        print('Sampled {} bytes'.format(self.noise.size * 4))\n",
    "\n",
    "    def get(self, i, dim):\n",
    "        return self.noise[i:i + dim]\n",
    "\n",
    "    def sample_index(self, stream, dim):\n",
    "        return stream.randint(0, len(self.noise) - dim + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_flat(theta):\n",
    "     return np.concatenate([np.reshape(v, [-1]) for v in theta], 0)\n",
    "\n",
    "def set_from_flat(model, theta):\n",
    "    old_theta = model.get_weights()\n",
    "    shapes = [v.shape for v in old_theta]\n",
    "    total_size = theta.size\n",
    "        \n",
    "    start = 0\n",
    "    reshapes = []\n",
    "    \n",
    "    for (shape, v) in zip(shapes, theta):\n",
    "        size = int(np.prod(shape))\n",
    "        reshapes.append(np.reshape(theta[start:start+size], shape))\n",
    "        start += size\n",
    "    \n",
    "\n",
    "    assert start == total_size\n",
    "    model.set_weights(reshapes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set from flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rollout TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rollout(env, \n",
    "            model, \n",
    "            *, \n",
    "            render=False, \n",
    "            timestep_limit=None, \n",
    "            save_obs=False, \n",
    "            random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "    \n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    times_predict = []\n",
    "    t = 0\n",
    "    if save_obs:\n",
    "        obs = []\n",
    "    ob = env.reset()\n",
    "    for _ in range(timestep_limit):\n",
    "        ac, time_predict = act(ob[None], model, random_stream=random_stream)\n",
    "        ac = ac[0]\n",
    "        times_predict.append(time_predict)\n",
    "        if save_obs:\n",
    "            obs.append(ob)\n",
    "        ob, rew, done, _ = env.step(ac)\n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "        if done:\n",
    "            break\n",
    "    rews = np.array(rews, dtype=np.float32)\n",
    "    if save_obs:\n",
    "        return rews, t, np.array(obs), times_predict\n",
    "    return rews, t, times_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Worker method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rollout_and_update_ob_stat(env, model, rs, task_ob_stat):\n",
    "    if optimizations.observation_normalization and config.calc_obstat_prob != 0 and rs.rand() < config.calc_obstat_prob:\n",
    "        rollout_rews, rollout_len, obs, times_predict = rollout(\n",
    "            env, model, save_obs=True, random_stream=rs)\n",
    "        task_ob_stat.increment(obs.sum(axis=0), np.square(obs).sum(axis=0), len(obs))\n",
    "    else:\n",
    "        rollout_rews, rollout_len, times_predict = rollout(env, model, random_stream=rs)\n",
    "    return rollout_rews, rollout_len, times_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_worker(task_list, result_queue):\n",
    "    from tensorflow.keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    K.set_session(tf.Session(config=tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)))\n",
    "\n",
    "    while not task_list:\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    print(\"PID {}: Started worker\".format(os.getpid()))\n",
    "    \n",
    "    assert isinstance(noise, SharedNoiseTable)\n",
    "\n",
    "    # Setup\n",
    "    # Create a new gym environment object because each worker needs its own one\n",
    "    env = gym.make(config.env_id)\n",
    "    \n",
    "    # Initialize the model with the supplied weights 'theta' to calcualate based on the current generation\n",
    "    \n",
    "    # Random stream used for adding noise to the actions as well as deciding if the observation statistics shall be\n",
    "    # updated\n",
    "    rs = np.random.RandomState()\n",
    "    \n",
    "    wait_time = 1\n",
    "    \n",
    "    cached_task = None\n",
    "    cached_task_id = -1\n",
    "    model = None\n",
    "    \n",
    "    while True:\n",
    "        # Get the latest Task from the Manger list\n",
    "        try:\n",
    "            task_tuple = task_list[-1]\n",
    "        except IndexError:\n",
    "            if wait_time > 100:\n",
    "                print(\"The task list does not get tasks, something went wrong in the Master. Aborting.\")\n",
    "                break\n",
    "            print(\"Task list is empty, waiting {} seconds before trying again\".format(wait_time))\n",
    "            wait_time *= 2\n",
    "            time.sleep(wait_time)\n",
    "            continue\n",
    "    \n",
    "\n",
    "        #assert isinstance(task, Task)\n",
    "        assert isinstance(task_tuple, tuple)\n",
    "        #task_id = task.task_id\n",
    "        task_id = task_tuple[0]\n",
    "        assert isinstance(task_id, int)\n",
    "        \n",
    "        time_create_model_e = 0\n",
    "        time_set_sess_e = 0\n",
    "        time_clear_sess_e = 0\n",
    "        \n",
    "        if task_id != cached_task_id:\n",
    "            cached_task = task_tuple[1]\n",
    "            assert isinstance(cached_task, Task)\n",
    "            cached_task_id = task_id\n",
    "        \n",
    "            time_clear_sess_s = time.time()\n",
    "            K.clear_session()\n",
    "            time_clear_sess_e = time.time() - time_clear_sess_s\n",
    "\n",
    "            time_set_sess_s = time.time()\n",
    "            K.set_session(tf.Session(config=tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)))\n",
    "            time_set_sess_e = time.time() - time_set_sess_s\n",
    "\n",
    "            time_create_model_s = time.time()        \n",
    "            model = create_model(initial_weights=cached_task.theta, \n",
    "                             model_name=str(os.getpid()),\n",
    "                             ob_mean=cached_task.ob_mean,\n",
    "                             ob_std=cached_task.ob_std)\n",
    "\n",
    "            time_create_model_e = time.time() - time_create_model_s\n",
    "        \n",
    "        if rs.rand() < config.eval_prob:\n",
    "            # Evaluation sample\n",
    "            eval_rews, eval_length, times_predict = rollout(env, model)\n",
    "            \n",
    "            result_queue.put(Result(\n",
    "                noise_inds=None,\n",
    "                returns=None,\n",
    "                signreturns=None,\n",
    "                lengths=None,\n",
    "                eval_return=eval_rews.sum(),\n",
    "                eval_length=eval_length,\n",
    "                ob_sum=None,\n",
    "                ob_sumsq=None,\n",
    "                ob_count=None,\n",
    "                task_id=cached_task_id,\n",
    "                times_per_mutation=None,\n",
    "                time_create_model=None if time_create_model_e == 0 else time_create_model_e,\n",
    "                time_clear_sess=None if time_clear_sess_e == 0 else time_clear_sess_e,\n",
    "                time_set_sess=None if time_set_sess_e == 0 else time_set_sess_e,\n",
    "                times_set_flat=None,\n",
    "                times_sample=None,\n",
    "                times_get_noise=None,\n",
    "                times_predict=times_predict\n",
    "            ))\n",
    "            \n",
    "        else:\n",
    "            task_ob_stat = RunningStat(env.observation_space.shape, eps=0.)  # eps=0 because we're incrementing only\n",
    "            \n",
    "            noise_inds, returns, signreturns, lengths = [], [], [], []\n",
    "            times_per_mutation, times_set_flat, times_sample, times_get_noise = [], [], [], []\n",
    "            times_predict = []\n",
    "            \n",
    "            while not noise_inds:\n",
    "\n",
    "                # Noise sample\n",
    "                time_sample_s = time.time()\n",
    "                noise_idx = noise.sample_index(rs, num_params)\n",
    "                times_sample.append(time.time() - time_sample_s)\n",
    "                \n",
    "                time_get_noise_s = time.time()\n",
    "                epsilon = config.noise_stdev * noise.get(noise_idx, num_params)\n",
    "                times_get_noise.append(time.time() - time_get_noise_s)\n",
    "                \n",
    "                # Evaluate the sampled noise\n",
    "                time_set_flat_s = time.time()\n",
    "                set_from_flat(model, cached_task.theta + epsilon)\n",
    "                times_set_flat.append(time.time() - time_set_flat_s)\n",
    "                \n",
    "                time_mutation_s = time.time()\n",
    "                rews_pos, len_pos, times_predict_pos = rollout_and_update_ob_stat(env,\n",
    "                                                                                  model,\n",
    "                                                                                  rs=rs,\n",
    "                                                                                  task_ob_stat=task_ob_stat)\n",
    "                times_per_mutation.append(time.time() - time_mutation_s)\n",
    "                                \n",
    "                # Gather results\n",
    "                noise_inds.append(noise_idx)\n",
    "                returns.append([rews_pos.sum()])\n",
    "                signreturns.append([np.sign(rews_pos).sum()])\n",
    "                lengths.append([len_pos])\n",
    "                \n",
    "                times_predict += times_predict_pos\n",
    "\n",
    "                # Mirrored sampling also evaluates the noise by subtracting it\n",
    "                if optimizations.mirrored_sampling:\n",
    "                    time_set_flat_s = time.time()\n",
    "                    set_from_flat(model, cached_task.theta - epsilon)\n",
    "                    times_set_flat.append(time.time() - time_set_flat_s)\n",
    "                    \n",
    "                    times_mutation_s = time.time()\n",
    "                    rews_neg, len_neg, times_predict_neg = rollout_and_update_ob_stat(env,\n",
    "                                                                                      model, \n",
    "                                                                                      rs=rs, \n",
    "                                                                                      task_ob_stat=task_ob_stat)\n",
    "                    times_per_mutation.append(time.time() - times_mutation_s)\n",
    "\n",
    "                    returns[-1].append(rews_neg.sum())\n",
    "                    signreturns[-1].append(np.sign(rews_neg).sum())\n",
    "                    lengths[-1].append(len_neg)\n",
    "                    \n",
    "                    times_predict += times_predict_neg\n",
    "\n",
    "                times_per_mutation.append(time.time() - time_mutation_s)\n",
    "            \n",
    "            result_queue.put(Result(\n",
    "                noise_inds=np.array(noise_inds),\n",
    "                returns=np.array(returns, dtype=np.float32),\n",
    "                signreturns=np.array(signreturns, dtype=np.float32),\n",
    "                lengths=np.array(lengths, dtype=np.int32),\n",
    "                eval_return=None,\n",
    "                eval_length=None,\n",
    "                ob_sum=None if task_ob_stat.count == 0 else task_ob_stat.sum,\n",
    "                ob_sumsq=None if task_ob_stat.count == 0 else task_ob_stat.sumsq,\n",
    "                ob_count=task_ob_stat.count,\n",
    "                task_id=cached_task_id,\n",
    "                times_per_mutation=times_per_mutation,\n",
    "                time_create_model=None if time_create_model_e == 0 else time_create_model_e,\n",
    "                time_clear_sess=None if time_clear_sess_e == 0 else time_clear_sess_e,\n",
    "                time_set_sess=None if time_set_sess_e == 0 else time_set_sess_e,\n",
    "                times_set_flat=times_set_flat, \n",
    "                times_sample=times_sample,\n",
    "                times_get_noise=times_get_noise,\n",
    "                times_predict=times_predict\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def itergroups(items, group_size):\n",
    "    assert group_size >= 1\n",
    "    group = []\n",
    "    for x in items:\n",
    "        group.append(x)\n",
    "        if len(group) == group_size:\n",
    "            yield tuple(group)\n",
    "            del group[:]\n",
    "    if group:\n",
    "        yield tuple(group)\n",
    "        \n",
    "def batched_weighted_sum(weights, vecs, batch_size):\n",
    "    total = 0.\n",
    "    num_items_summed = 0\n",
    "    for batch_weights, batch_vecs in zip(itergroups(weights, batch_size), itergroups(vecs, batch_size)):\n",
    "        assert len(batch_weights) == len(batch_vecs) <= batch_size\n",
    "        total += np.dot(np.asarray(batch_weights, dtype=np.float32), np.asarray(batch_vecs, dtype=np.float32))\n",
    "        num_items_summed += len(batch_weights)\n",
    "    return total, num_items_summed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Fitness shaping with a rank transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_ranks(x):\n",
    "    \"\"\"\n",
    "    Returns ranks in [0, len(x))\n",
    "    Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].\n",
    "    \"\"\"\n",
    "    assert x.ndim == 1\n",
    "    ranks = np.empty(len(x), dtype=int)\n",
    "    ranks[x.argsort()] = np.arange(len(x))\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def compute_centered_ranks(x):\n",
    "    y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rs = np.random.RandomState()\n",
    "\n",
    "noise = SharedNoiseTable()\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "task_list = manager.list()\n",
    "result_queue = multiprocessing.Queue()\n",
    "\n",
    "# Start workers\n",
    "workers = []\n",
    "\n",
    "for _ in range(int(config.num_workers)):\n",
    "    worker_p = multiprocessing.Process(target=run_worker, args=(task_list, result_queue))\n",
    "    workers.append(worker_p)\n",
    "    worker_p.start()\n",
    "    \n",
    "theta = get_flat(theta)\n",
    "\n",
    "episodes_so_far = 0\n",
    "timesteps_so_far = 0\n",
    "generations = 0\n",
    "tstart = time.time()\n",
    "\n",
    "ob_mean = ob_stat.mean if optimizations.observation_normalization else None\n",
    "ob_std = ob_stat.std if optimizations.observation_normalization else None\n",
    "\n",
    "generation_log = OrderedDict()\n",
    "generation_log_file = save_directory + 'log.csv'\n",
    "fieldnames = [\n",
    "    'Generation',\n",
    "    'GenRewMean', 'GenRewStd', 'GenLenMean', \n",
    "    'EvalGenRewardMean', 'EvalGenRewardStd', 'EvalGenLengthMean', 'EvalGenCount',\n",
    "    'EpisodesThisGen', 'EpisodesSoFar', 'TimestepsThisGen', 'TimestepsSoFar',\n",
    "    'UniqueWorkers', 'ResultsSkippedFrac', 'ObCount',\n",
    "    'TimeElapsedThisGen', 'TimeElapsed',\n",
    "    'TimePerMutationMin', 'TimePerMutationMax', 'TimePerMutationMean', 'TimePerMutationCount',\n",
    "    'TimeCreateModelMin', 'TimeCreateModelMax', 'TimeCreateModelMean', 'TimeCreateModelCount',                     \n",
    "    'TimeSetFlatMin', 'TimeSetFlatMax', 'TimeSetFlatMean', 'TimeSetFlatCount', \n",
    "    'TimeSampleMin', 'TimeSampleMax', 'TimeSampleMean', 'TimeSampleCount',\n",
    "    'TimeGetNoiseMin', 'TimeGetNoiseMax', 'TimeGetNoiseMean', 'TimeGetNoiseCount',\n",
    "    'TimePredictMin', 'TimePredictMax', 'TimePredictMean', 'TimePredictCount',\n",
    "    'TimeClearSessMin', 'TimeClearSessMax', 'TimeClearSessMean', 'TimeClearSessCount',\n",
    "    'TimeSetSessMin', 'TimeSetSessMax', 'TimeSetSessMean', 'TimeSetSessCount']\n",
    "\n",
    "with open(generation_log_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "\n",
    "while True:\n",
    "    step_tstart = time.time()\n",
    "\n",
    "    task_list.append(\n",
    "        (generations, Task(\n",
    "        theta=theta,\n",
    "        ob_mean=ob_mean,\n",
    "        ob_std=ob_std,\n",
    "        task_id = generations\n",
    "    )))\n",
    "    \n",
    "    print(\"---------------- Generation: \" + str(generations) + \"----------------\")\n",
    "            \n",
    "    assert theta.dtype == np.float32\n",
    "    \n",
    "    curr_task_results, eval_returns, eval_lengths = [], [], []\n",
    "    num_results_skipped, num_episodes_popped, ob_count_this_gen = 0, 0, 0\n",
    "    \n",
    "    times_per_mutation, times_create_model, times_clear_sess, times_set_sess = [], [], [], []\n",
    "    times_set_flat, times_sample, times_get_noise = [], [], []\n",
    "    times_predict = []\n",
    "        \n",
    "    print(\"PID \" + str(os.getpid()) + \": \" + \"Waiting for results\")\n",
    "   \n",
    "    while num_episodes_popped < config.population_size:\n",
    "        result = result_queue.get()\n",
    "        \n",
    "        assert isinstance(result, Result)\n",
    "        task_id = result.task_id\n",
    "        assert isinstance(task_id, int)\n",
    "        \n",
    "        assert (result.eval_return is None) == (result.eval_length is None)\n",
    "        \n",
    "        if result.time_create_model is not None:\n",
    "            times_create_model.append(result.time_create_model)\n",
    "        if result.time_clear_sess is not None:\n",
    "            times_clear_sess.append(result.time_clear_sess)\n",
    "        if result.time_set_sess is not None:\n",
    "            times_set_sess.append(result.time_set_sess)\n",
    "        \n",
    "        if result.eval_length is not None:\n",
    "            # The result was an evaluation job\n",
    "            \n",
    "            episodes_so_far += 1\n",
    "            timesteps_so_far += result.eval_length\n",
    "            \n",
    "            if task_id == generations:\n",
    "                eval_returns.append(result.eval_return)\n",
    "                eval_lengths.append(result.eval_length)\n",
    "                times_predict += result.times_predict\n",
    "        else:\n",
    "            assert result.noise_inds.ndim == 1 and result.returns.dtype == np.float32\n",
    "\n",
    "            if optimizations.mirrored_sampling:\n",
    "                assert result.returns.shape == result.lengths.shape == (len(result.noise_inds), 2)\n",
    "            else:\n",
    "                assert result.returns.shape == result.lengths.shape == (len(result.noise_inds), 1)\n",
    "\n",
    "            # Update counts\n",
    "            result_num_eps = result.lengths.size\n",
    "            result_num_timesteps = result.lengths.sum()\n",
    "            episodes_so_far += result_num_eps\n",
    "            timesteps_so_far += result_num_timesteps\n",
    "            \n",
    "            \n",
    "            if task_id == generations:\n",
    "                curr_task_results.append(result)\n",
    "                num_episodes_popped += result_num_eps\n",
    "\n",
    "                # Update observation stats if the optimization is used\n",
    "                if optimizations.observation_normalization and result.ob_count > 0:\n",
    "                    ob_stat.increment(result.ob_sum, result.ob_sumsq, result.ob_count)\n",
    "                    ob_count_this_gen += result.ob_count\n",
    "\n",
    "                times_per_mutation += result.times_per_mutation\n",
    "                times_set_flat += result.times_set_flat\n",
    "                times_sample += result.times_sample\n",
    "                times_get_noise += result.times_get_noise\n",
    "                times_predict += result.times_predict\n",
    "            else:\n",
    "                num_results_skipped += 1\n",
    "                \n",
    "    print(\"Gathered results\")\n",
    "    \n",
    "    # Compute skip fraction\n",
    "    frac_results_skipped = num_results_skipped / (num_results_skipped + len(curr_task_results))\n",
    "    if num_results_skipped > 0:\n",
    "        print(\"Skipped {} out of date results ({:.2f}%)\".format(\n",
    "            num_results_skipped, 100. * frac_results_skipped))\n",
    "    \n",
    "    # Assemble results\n",
    "    noise_inds = np.concatenate([r.noise_inds for r in curr_task_results])\n",
    "    returns = np.concatenate([r.returns for r in curr_task_results])\n",
    "    lengths = np.concatenate([r.lengths for r in curr_task_results])\n",
    "    assert noise_inds.shape[0] == returns.shape[0] == lengths.shape[0]\n",
    "    \n",
    "    # If fitness shaping is turned on rank the results\n",
    "    if optimizations.fitness_shaping:\n",
    "        if config.return_proc_mode == RETURN_PROC_MODE_CR:\n",
    "            proc_returns = compute_centered_ranks(returns)\n",
    "        # sign and centered_sign_rank are obviously only useful in combination with mirrored sampling\n",
    "        elif config.return_proc_mode == RETURN_PROC_MODE_SIGN:\n",
    "            proc_returns = np.concatenate([r.signreturns for r in curr_task_results])\n",
    "        elif config.return_proc_mode == RETURN_PROC_MODE_CR_SIGN:\n",
    "            proc_returns = compute_centered_ranks(np.concatenate([r.signreturns for r in curr_task_results]))\n",
    "        else:\n",
    "            # Throw error to indicate the false input instead of silently pass on.\n",
    "            # This should have been already catched in the configuration section, so this here is a misconfiguration.\n",
    "            raise NotImplementedError\n",
    "    else:\n",
    "        proc_returns = returns\n",
    "    \n",
    "    # Mirrored sampling returns a 2D numpy array therefore we need to preprocess it accordingly\n",
    "    if optimizations.mirrored_sampling:\n",
    "        # Calculates the difference between the rewards sampled with the positive and negative noise\n",
    "        proc_returns = proc_returns[:, 0] - proc_returns[:, 1]\n",
    "    else:\n",
    "        proc_returns = proc_returns.ravel()\n",
    "    \n",
    "    # Calculate the approximated gradient with a batch variant which saves time TODO saving time true?\n",
    "    g, count = batched_weighted_sum(\n",
    "        proc_returns,\n",
    "        (noise.get(idx, num_params) for idx in noise_inds),\n",
    "        batch_size=500\n",
    "    )\n",
    "    \n",
    "    assert g.shape == (num_params,) and g.dtype == np.float32 and count == len(noise_inds)\n",
    "    \n",
    "    # Update with the approximated gradient\n",
    "    g /= returns.size\n",
    "    \n",
    "    if optimizations.neural_network_optimizer:\n",
    "        theta, _ = optimizer.update(theta, -g + config.l2coeff * theta)\n",
    "    else:\n",
    "        theta += ((config.learning_rate / config.noise_stdev) * g)\n",
    "    \n",
    "    # Update ob_mean and ob_std\n",
    "    if optimizations.observation_normalization and ob_count_this_gen > 0:\n",
    "        ob_mean = ob_stat.mean\n",
    "        ob_std = ob_stat.std\n",
    "    \n",
    "    step_tend = time.time()\n",
    "    \n",
    "    # Log the generation and print to stdout\n",
    "    generation_log['Generation'] = generations\n",
    "    \n",
    "    generation_log['GenRewMean'] = returns.mean()\n",
    "    generation_log['GenRewStd'] = returns.std()\n",
    "    generation_log['GenLenMean'] = lengths.mean()\n",
    "    \n",
    "    generation_log['EvalGenRewardMean'] = np.nan if not eval_returns else np.mean(eval_returns)\n",
    "    generation_log['EvalGenRewardStd'] = np.nan if not eval_returns else np.std(eval_returns)\n",
    "    generation_log['EvalGenLengthMean'] = np.nan if not eval_lengths else np.mean(eval_lengths)\n",
    "    generation_log['EvalGenCount'] = len(eval_returns)\n",
    "    \n",
    "    generation_log['EpisodesThisGen'] = lengths.size\n",
    "    generation_log['EpisodesSoFar'] = episodes_so_far\n",
    "    generation_log['TimestepsThisGen'] = lengths.sum()\n",
    "    generation_log['TimestepsSoFar'] = timesteps_so_far\n",
    "    \n",
    "    generation_log['UniqueWorkers'] = config.num_workers\n",
    "    generation_log['ResultsSkippedFrac'] = frac_results_skipped\n",
    "    generation_log['ObCount'] = ob_count_this_gen\n",
    "    \n",
    "    generation_log['TimeElapsedThisGen'] = step_tend - step_tstart\n",
    "    generation_log['TimeElapsed'] = step_tend - tstart\n",
    "    \n",
    "    generation_log['TimePerMutationMin'] = np.amin(times_per_mutation)\n",
    "    generation_log['TimePerMutationMax'] = np.amax(times_per_mutation)\n",
    "    generation_log['TimePerMutationMean'] = np.mean(times_per_mutation)\n",
    "    generation_log['TimePerMutationCount'] = len(times_per_mutation)\n",
    "    \n",
    "    generation_log['TimeCreateModelMin'] = np.amin(times_create_model)\n",
    "    generation_log['TimeCreateModelMax'] = np.amax(times_create_model)\n",
    "    generation_log['TimeCreateModelMean'] = np.mean(times_create_model)\n",
    "    generation_log['TimeCreateModelCount'] = len(times_create_model)\n",
    "    \n",
    "    generation_log['TimeSetFlatMin'] = np.amin(times_set_flat)\n",
    "    generation_log['TimeSetFlatMax'] = np.amax(times_set_flat)\n",
    "    generation_log['TimeSetFlatMean'] = np.mean(times_set_flat)\n",
    "    generation_log['TimeSetFlatCount'] = len(times_set_flat)\n",
    "    \n",
    "    generation_log['TimeSampleMin'] = np.amin(times_sample)\n",
    "    generation_log['TimeSampleMax'] = np.amax(times_sample)\n",
    "    generation_log['TimeSampleMean'] = np.mean(times_sample)\n",
    "    generation_log['TimeSampleCount'] = len(times_sample)\n",
    "    \n",
    "    generation_log['TimeGetNoiseMin'] = np.amin(times_get_noise)\n",
    "    generation_log['TimeGetNoiseMax'] = np.amax(times_get_noise)\n",
    "    generation_log['TimeGetNoiseMean'] = np.mean(times_get_noise)\n",
    "    generation_log['TimeGetNoiseCount'] = len(times_get_noise)\n",
    "    \n",
    "    generation_log['TimePredictMin'] = np.amin(times_predict)\n",
    "    generation_log['TimePredictMax'] = np.amax(times_predict)\n",
    "    generation_log['TimePredictMean'] = np.mean(times_predict)\n",
    "    generation_log['TimePredictCount'] = len(times_predict)\n",
    "    \n",
    "    generation_log['TimeClearSessMin'] = np.amin(times_clear_sess)\n",
    "    generation_log['TimeClearSessMax'] = np.amax(times_clear_sess)\n",
    "    generation_log['TimeClearSessMean'] = np.mean(times_clear_sess)\n",
    "    generation_log['TimeClearSessCount'] = len(times_clear_sess)\n",
    "    \n",
    "    generation_log['TimeSetSessMin'] = np.amin(times_set_sess)\n",
    "    generation_log['TimeSetSessMax'] = np.amax(times_set_sess)\n",
    "    generation_log['TimeSetSessMean'] = np.mean(times_set_sess)\n",
    "    generation_log['TimeSetSessCount'] = len(times_set_sess)\n",
    "    \n",
    "    for key, value in generation_log.items():\n",
    "        print(f'{key:25} {value}')\n",
    "    \n",
    "    # Append the log the csv file\n",
    "    with open(generation_log_file, 'a', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writerow(generation_log)\n",
    "\n",
    "    # Note that the model is created with a custom layer and custom initializer, and therefore needs these two\n",
    "    # custom classes if one wants to load a saved model\n",
    "    if config.snapshot_freq != 0 and generations % config.snapshot_freq == 0:\n",
    "        from multiprocessing import Process\n",
    "        \n",
    "        p = Process(target=create_model, args=(\n",
    "                                            theta, \n",
    "                                            config.env_id + \"_Generation_\" + str(generations), \n",
    "                                            save_directory + 'snapshot_{:05d}'.format(generations) + \".h5\",\n",
    "                                            ob_mean,\n",
    "                                            ob_std))\n",
    "        p.start()\n",
    "        p.join()\n",
    "        \n",
    "        print(\"Saved model in generation {} to {}\".format(generations, save_directory))\n",
    "            \n",
    "    generations += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
