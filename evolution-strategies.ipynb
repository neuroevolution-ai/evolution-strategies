{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIT License\n",
    "\n",
    "Copyright (c) 2016 OpenAI (http://openai.com)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in\n",
    "all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Evolution Strategies to train Roboschool Environments\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook is based on the [paper](https://arxiv.org/abs/1703.03864), [blog article](https://openai.com/blog/evolution-strategies/) and [implementation](https://github.com/openai/evolution-strategies-starter) of OpenAI on the topic of using an Evolution Strategy algorithm for a typical reinforcement learning task. \n",
    "\n",
    "My implementation summarizes their implementation, by simplifying, refactoring and organizing the code into this Jupyter notebook which can be used to test the algorithm. One can tweak the hyperparameters, change the environment which shall be trained or even expand the implementation to support for example Atari environments.\n",
    "\n",
    "I recommend reading the paper or at least the article before trying out the notebook. Also depending on the environment the training can be very computationally intense (for example training the Humanoid), so if you want to try out the harder ones I recommend using a highly parallelizable machine, i.e. a machine with a high number of cores/threads.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before starting any computation we need to configure the program and define some methods and objects we will use later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configuration & Result Classes\n",
    "\n",
    "Using a `namedtuple` allows use to quickly create a class with different attributes, which is ideal for defining a Config and Result Class.\n",
    "\n",
    "The Config class defines our general configuration of the program. The following table explains what each attribute does:\n",
    "\n",
    "\n",
    "| Attribute             | Explanation   |\n",
    "| :---------------------|:--------------|\n",
    "| `env_id`              |  |\n",
    "| `population_size`     |      |\n",
    "| `population_size`     |       |\n",
    "| `learning_rate`       |\n",
    "| `noise_stdev`         |\n",
    "| `snapshot_freq`       |\n",
    "| `return_proc_mode`    |\n",
    "| `timesteps_per_batch` |\n",
    "| `calc_obstat_prob`    |\n",
    "| `eval_prob`           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Config = namedtuple('Config', [\n",
    "    'env_id',\n",
    "    'population_size',\n",
    "    'num_workers',\n",
    "    'learning_rate',\n",
    "    'noise_stdev',\n",
    "    'snapshot_freq',\n",
    "    'return_proc_mode'\n",
    "    #'timesteps_per_batch',\n",
    "    #'calc_obstat_prob',\n",
    "    #'eval_prob'\n",
    "])\n",
    "\n",
    "Result = namedtuple('Result', [\n",
    "    'worker_id',\n",
    "    'noise_inds_n','returns_n2', 'signreturns_n2', 'lengths_n2',\n",
    "    'eval_return', 'eval_length',\n",
    "    'ob_sum', 'ob_sumsq', 'ob_count',\n",
    "    'task_id'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config = Config(\n",
    "    env_id=\"RoboschoolAnt-v1\",\n",
    "    population_size=32,\n",
    "    num_workers=os.cpu_count(),\n",
    "    learning_rate=0.005,\n",
    "    noise_stdev=0.02,\n",
    "    snapshot_freq=1,\n",
    "    return_proc_mode=\"centered_rank\"\n",
    ")\n",
    "\n",
    "#config.num_workers = config.num_workers if config.num_workers else os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Environment\n",
    "\n",
    "Create one for every worker -> done in worker method\n",
    "Master also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym, roboschool # Roboschool import needed to register the environments within gym\n",
    "env = gym.make(config.env_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tensorflow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Policy setup\n",
    "\n",
    "Currently saves the arguments as local variable, then creates a TensorFlow variable scope where the neural network\n",
    "architecture gets created.\n",
    "\n",
    "Currently emitted:\n",
    "1. Observation normalization\n",
    "2. Obseration clipping\n",
    "3. _act function\n",
    "6. set_all_vars\n",
    "\n",
    "## Keras as Model\n",
    "\n",
    "Original implementation used hand written dense layers and tensorflow operations. I use a Keras model and their\n",
    "functional API to create the net. In testing the two version differ in 0.x float scope. Something to worry about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "args = {\n",
    "      \"ac_bins\": \"continuous:\",\n",
    "      \"ac_noise_std\": 0.01,\n",
    "      #\"connection_type\": \"ff\",\n",
    "      \"hidden_dims\": [\n",
    "        256,\n",
    "        256\n",
    "      ],\n",
    "      \"nonlin_type\": \"tanh\"\n",
    "}\n",
    "\n",
    "ob_space= env.observation_space\n",
    "ac_space = env.action_space\n",
    "ac_bins = args[\"ac_bins\"]\n",
    "ac_noise_std = args[\"ac_noise_std\"]\n",
    "hidden_dims = args[\"hidden_dims\"]\n",
    "nonlin = args[\"nonlin_type\"]\n",
    "\n",
    "# TODO more nonlinear functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Keras clearin backend to support multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(initial_weights=None, model_name=\"model\", save_path=None):\n",
    "    #tf.keras.backend.clear_session()\n",
    "    import tensorflow as tf\n",
    "    nonlin = tf.tanh\n",
    "\n",
    "    with tf.variable_scope(\"RoboschoolPolicy/\" + model_name):\n",
    "        # Observation normalization\n",
    "        #ob_mean = tf.get_variable(\n",
    "        #    'ob_mean', ob_space.shape, tf.float32, tf.constant_initializer(np.nan), trainable=False)\n",
    "        #ob_std = tf.get_variable(\n",
    "        #    'ob_std', ob_space.shape, tf.float32, tf.constant_initializer(np.nan), trainable=False)\n",
    "        #in_mean = tf.placeholder(tf.float32, ob_space.shape)\n",
    "        #in_std = tf.placeholder(tf.float32, ob_space.shape)\n",
    "        #self._set_ob_mean_std = U.function([in_mean, in_std], [], updates=[\n",
    "            #tf.assign(ob_mean, in_mean),\n",
    "            #tf.assign(ob_std, in_std),\n",
    "        #])\n",
    "\n",
    "        # Normalize observation space and clip to [-5.0, 5.0]\n",
    "        #o = tf.clip_by_value((o - ob_mean) / ob_std, -5.0, 5.0)\n",
    "\n",
    "        # Policy network\n",
    "\n",
    "        input = x = tf.keras.Input(ob_space.shape, dtype=tf.float32)\n",
    "\n",
    "        for hd in hidden_dims:\n",
    "            x = tf.keras.layers.Dense(\n",
    "                hd, activation=nonlin,\n",
    "                kernel_initializer=tf.initializers.random_normal,\n",
    "                bias_initializer=tf.initializers.zeros)(x)\n",
    "\n",
    "        # Map to action\n",
    "        adim = ac_space.shape[0]\n",
    "\n",
    "        a = tf.keras.layers.Dense(\n",
    "        adim,\n",
    "        kernel_initializer=tf.initializers.random_normal,\n",
    "        bias_initializer=tf.initializers.zeros)(x)\n",
    "        model = tf.keras.Model(inputs=input, outputs=a, name=model_name)\n",
    "\n",
    "        # Initializer for the newly created weights. TODO possible replacement tf.keras.initializers.RandomNormal\n",
    "        # out = np.random.randn(*adim).astype(np.float32)\n",
    "        # out *=  0.01 / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "        # initializer= tf.constant(out)\n",
    "\n",
    "\n",
    "    if initial_weights is not None:\n",
    "        set_from_flat(model, initial_weights)\n",
    "        \n",
    "    if save_path:\n",
    "        model.save_weights(save_path)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def act(ob, model, random_stream=None):\n",
    "    action = model.predict(ob)\n",
    "    \n",
    "    # TODO why randomstream? Better generalization?\n",
    "    if random_stream is not None and ac_noise_std != 0:\n",
    "        action += random_stream.randn(*action.shape) * ac_noise_std\n",
    "    return action\n",
    "\n",
    "def get_initial_weights():\n",
    "    model = create_model()\n",
    "    \n",
    "    # Print out the model\n",
    "    model.summary()\n",
    "    \n",
    "    return model.get_weights()\n",
    "\n",
    "# Plot the Neural Network Architecture\n",
    "#master_model.summary()\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "with Pool(1) as pool:\n",
    "    theta = pool.apply(func=get_initial_weights)\n",
    "\n",
    "\n",
    "# Plot the Neural Network Architecture\n",
    "#master_model.summary()\n",
    "#all_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope.name)\n",
    "\n",
    "\n",
    "#trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, master_scope.name)\n",
    "#trainable_variables = model.get_weights()\n",
    "\n",
    "num_params = sum(np.prod(v.shape) for v in theta)\n",
    "\n",
    "#placeholders = [tf.placeholder(v.value().dtype, v.get_shape().as_list()) for v in self.all_variables]\n",
    "\n",
    "# self.set_all_vars = U.function(\n",
    "#     inputs=placeholders,\n",
    "#     outputs=[],\n",
    "#     updates=[tf.group(*[v.assign(p) for v, p in zip(self.all_variables, placeholders)])]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = {'sgd': SGD, 'adam': Adam}[exp['optimizer']['type']](policy, **exp['optimizer']['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Shared Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SharedNoiseTable(object):\n",
    "    def __init__(self):\n",
    "        import ctypes, multiprocessing\n",
    "        seed = 123\n",
    "        count = 250000000  # 1 gigabyte of 32-bit numbers. Will actually sample 2 gigabytes below.\n",
    "        #logger.info('Sampling {} random numbers with seed {}'.format(count, seed))\n",
    "\n",
    "        # Instantiate an array of C float datatype with size count\n",
    "        self._shared_mem = multiprocessing.Array(ctypes.c_float, count)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        self.noise = np.ctypeslib.as_array(self._shared_mem.get_obj())\n",
    "        assert self.noise.dtype == np.float32\n",
    "        self.noise[:] = np.random.RandomState(seed).randn(count)  # 64-bit to 32-bit conversion here\n",
    "        #logger.info('Sampled {} bytes'.format(self.noise.size * 4))\n",
    "\n",
    "    def get(self, i, dim):\n",
    "        return self.noise[i:i + dim]\n",
    "\n",
    "    def sample_index(self, stream, dim):\n",
    "        return stream.randint(0, len(self.noise) - dim + 1)\n",
    "\n",
    "noise = SharedNoiseTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def set_new_weights(model, theta, epsilon):\n",
    "#     assert isinstance(model, tf.keras.Model)\n",
    "#     assert isinstance(theta, list)\n",
    "#         \n",
    "#     for t in theta:\n",
    "#         t += epsilon\n",
    "#     \n",
    "#     model.set_weights(theta)\n",
    "\n",
    "def get_flat(theta):\n",
    "     return np.concatenate([np.reshape(v, [-1]) for v in theta], 0)\n",
    "\n",
    "def set_from_flat(model, theta):\n",
    "    old_theta = model.get_weights()\n",
    "    shapes = [v.shape for v in old_theta]\n",
    "    total_size = theta.size\n",
    "    \n",
    "    start = 0\n",
    "    reshapes = []\n",
    "    \n",
    "    for (shape, v) in zip(shapes, theta):\n",
    "        size = int(np.prod(shape))\n",
    "        reshapes.append(np.reshape(theta[start:start+size], shape))\n",
    "        start += size\n",
    "    \n",
    "    assert start == total_size\n",
    "    model.set_weights(reshapes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set from flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def _create_set_from_flat_op(var_list, orig):\n",
    "#     shapes = [v.shape for v in orig]\n",
    "#     total_size = np.sum([v.size for v in orig])\n",
    "#         \n",
    "#     start=0\n",
    "#     assigns = []\n",
    "#     for (shape, v) in zip(shapes, var_list):\n",
    "#         size = v.size\n",
    "#         assigns.append(np.reshape(var_list[start:start+size], shape))\n",
    "#         start += size\n",
    "#         \n",
    "#     assert start == total_size\n",
    "#     \n",
    "#     return assigns\n",
    "#  \n",
    "# \n",
    "# def set_from_flat(var_list):\n",
    "#     old_weights = get_flat(model.get_weights())\n",
    "# \n",
    "#     new_weights = old_weights + var_list\n",
    "#     op_set_from_flat = _create_set_from_flat_op(new_weights)\n",
    "#     model.set_weights(sess.run(op_set_from_flat))\n",
    "#     \n",
    "#     print(\"PID \" + str(os.getpid()) + \": \" + \"Set weights from flat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rollout TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rollout(env, model, *, render=False, timestep_limit=None, save_obs=False, random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "    \n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    t = 0\n",
    "    if save_obs:\n",
    "        obs = []\n",
    "    ob = env.reset()\n",
    "    for _ in range(timestep_limit):\n",
    "        ac = act(ob[None], model, random_stream=random_stream)[0]\n",
    "        if save_obs:\n",
    "            obs.append(ob)\n",
    "        ob, rew, done, _ = env.step(ac)\n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "        if done:\n",
    "            break\n",
    "    rews = np.array(rews, dtype=np.float32)\n",
    "    if save_obs:\n",
    "        return rews, t, np.array(obs)\n",
    "    return rews, t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Worker method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_worker(num_jobs, theta): #min_task_runtime=.2):\n",
    "\n",
    "    print(\"PID \" + str(os.getpid()) + \": \" + \"Started worker with \" + str(num_jobs) + \"Jobs\")\n",
    "    #with lock:\n",
    "    #    logger.info('run_worker: {}'.format(locals()))\n",
    "\n",
    "    assert isinstance(noise, SharedNoiseTable)\n",
    "\n",
    "    # Setup\n",
    "    #config, env, sess, policy = setup(exp, single_threaded=True)\n",
    "    env = gym.make(config.env_id)\n",
    "    model = create_model(initial_weights=theta, model_name=str(os.getpid()))\n",
    "    \n",
    "\n",
    "    # Random stream used for todo\n",
    "    rs = np.random.RandomState()\n",
    "    #worker_id = rs.randint(2 ** 31)\n",
    "\n",
    "    #assert policy.needs_ob_stat == (config.calc_obstat_prob != 0)\n",
    "\n",
    "    #while True:\n",
    "    # Prevent accessing empty array (master did not emit task yet)\n",
    "    #while not tasks:\n",
    "    #    time.sleep(0.05)\n",
    "\n",
    "    #task_data = tasks[-1]\n",
    "\n",
    "    #task_tstart = time.time()\n",
    "\n",
    "    #assert isinstance(task_data, Task)\n",
    "    #task_id = task_data.task_id\n",
    "    #assert isinstance(task_id, int)\n",
    "\n",
    "    #if policy.needs_ob_stat:\n",
    "    #    policy.set_ob_stat(task_data.ob_mean, task_data.ob_std)\n",
    "\n",
    "    # # todo whats this condition doing?\n",
    "    # if rs.rand() < config.eval_prob:\n",
    "    #     # Evaluation: noiseless weights and noiseless actions\n",
    "    #     policy.set_trainable_flat(task_data.params)\n",
    "    # \n",
    "    #     eval_rews, eval_length = policy.rollout(env)  # eval rollouts don't obey task_data.timestep_limit\n",
    "    #     eval_return = eval_rews.sum()\n",
    "    # \n",
    "    #     with lock:\n",
    "    #         logger.info('Eval result: task={} return={:.3f} length={}'.format(task_id, eval_return, eval_length))\n",
    "    # \n",
    "    #     result_queue.put(Result(\n",
    "    #         worker_id=worker_id,\n",
    "    #         noise_inds_n=None,\n",
    "    #         returns_n2=None,\n",
    "    #         signreturns_n2=None,\n",
    "    #         lengths_n2=None,\n",
    "    #         eval_return=eval_return,\n",
    "    #         eval_length=eval_length,\n",
    "    #         ob_sum=None,\n",
    "    #         ob_sumsq=None,\n",
    "    #         ob_count=None,\n",
    "    #         task_id=task_id\n",
    "    #     ))\n",
    "\n",
    "    # Rollouts with noise\n",
    "    noise_inds, returns, signreturns, lengths = [], [], [], []\n",
    "    #task_ob_stat = RunningStat(env.observation_space.shape, eps=0.)  # eps=0 because we're incrementing only\n",
    "    \n",
    "    #while not noise_inds or time.time() - task_tstart < min_task_runtime:\n",
    "    \n",
    "    for _ in range(num_jobs):\n",
    "\n",
    "        # ------------- Noise sample -------------------------------\n",
    "        noise_idx = noise.sample_index(rs, num_params)\n",
    "        epsilon = config.noise_stdev * noise.get(noise_idx, num_params)\n",
    "\n",
    "        # Evaluate the sampled noise positive\n",
    "        set_from_flat(model, theta + epsilon)\n",
    "        rews_pos, len_pos = rollout(env, model, random_stream=rs)\n",
    "\n",
    "        # rews_pos, len_pos = rollout_and_update_ob_stat(\n",
    "        #     policy, env, task_data.timestep_limit, rs, task_ob_stat, config.calc_obstat_prob)\n",
    "        \n",
    "        # Evaluate the sample noise negative\n",
    "        set_from_flat(model, theta - epsilon)\n",
    "        rews_neg, len_neg = rollout(env, model, random_stream=rs)\n",
    "\n",
    "        # rews_neg, len_neg = rollout_and_update_ob_stat(\n",
    "        #     policy, env, task_data.timestep_limit, rs, task_ob_stat, config.calc_obstat_prob)\n",
    "        \n",
    "    \n",
    "        # Gather results\n",
    "        noise_inds.append(noise_idx)\n",
    "        returns.append([rews_pos.sum(), rews_neg.sum()])\n",
    "        signreturns.append([np.sign(rews_pos).sum(), np.sign(rews_neg).sum()])\n",
    "        lengths.append([len_pos, len_neg])\n",
    "        \n",
    "        \n",
    "    # result_queue.put(Result(\n",
    "    #     worker_id=worker_id,\n",
    "    #     noise_inds_n=np.array(noise_inds),\n",
    "    #     returns_n2=np.array(returns, dtype=np.float32),\n",
    "    #     signreturns_n2=np.array(signreturns, dtype=np.float32),\n",
    "    #     lengths_n2=np.array(lengths, dtype=np.int32),\n",
    "    #     eval_return=None,\n",
    "    #     eval_length=None,\n",
    "    #     ob_sum=None if task_ob_stat.count == 0 else task_ob_stat.sum,\n",
    "    #     ob_sumsq=None if task_ob_stat.count == 0 else task_ob_stat.sumsq,\n",
    "    #     ob_count=task_ob_stat.count,\n",
    "    #     task_id=task_id\n",
    "    # ))\n",
    "    print(\"PID \" + str(os.getpid()) + \": \" + \"Returned result\")\n",
    "    result = Result(\n",
    "        worker_id=None,\n",
    "        noise_inds_n=np.array(noise_inds),\n",
    "        returns_n2=np.array(returns, dtype=np.float32),\n",
    "        signreturns_n2=np.array(signreturns, dtype=np.float32),\n",
    "        lengths_n2=np.array(lengths, dtype=np.int32),\n",
    "        eval_return=None,\n",
    "        eval_length=None,\n",
    "        ob_sum=None,\n",
    "        ob_count=None,\n",
    "        ob_sumsq=None,\n",
    "        task_id = 0\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def itergroups(items, group_size):\n",
    "    assert group_size >= 1\n",
    "    group = []\n",
    "    for x in items:\n",
    "        group.append(x)\n",
    "        if len(group) == group_size:\n",
    "            yield tuple(group)\n",
    "            del group[:]\n",
    "    if group:\n",
    "        yield tuple(group)\n",
    "        \n",
    "def batched_weighted_sum(weights, vecs, batch_size):\n",
    "    total = 0.\n",
    "    num_items_summed = 0\n",
    "    for batch_weights, batch_vecs in zip(itergroups(weights, batch_size), itergroups(vecs, batch_size)):\n",
    "        assert len(batch_weights) == len(batch_vecs) <= batch_size\n",
    "        total += np.dot(np.asarray(batch_weights, dtype=np.float32), np.asarray(batch_vecs, dtype=np.float32))\n",
    "        num_items_summed += len(batch_weights)\n",
    "    return total, num_items_summed\n",
    "\n",
    "import errno\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Fitness shaping with a rank transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_ranks(x):\n",
    "    \"\"\"\n",
    "    Returns ranks in [0, len(x))\n",
    "    Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].\n",
    "    \"\"\"\n",
    "    assert x.ndim == 1\n",
    "    ranks = np.empty(len(x), dtype=int)\n",
    "    ranks[x.argsort()] = np.arange(len(x))\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def compute_centered_ranks(x):\n",
    "    y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Using Adam Optimizer\n",
    "\n",
    "Defining it manually since with Keras you have to define a loss function and use training set, etc. Manually seems\n",
    "easier for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self):\n",
    "        self.dim = num_params\n",
    "        self.t = 0\n",
    "\n",
    "    def update(self, globalg):\n",
    "        self.t += 1\n",
    "        step = self._compute_step(globalg)\n",
    "        ratio = np.linalg.norm(step) / np.linalg.norm(theta)\n",
    "        theta_new = theta + step\n",
    "        return theta_new, ratio\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, stepsize, beta1=0.9, beta2=0.999, epsilon=1e-08):\n",
    "        Optimizer.__init__(self)\n",
    "        self.stepsize = stepsize\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = np.zeros(self.dim, dtype=np.float32)\n",
    "        self.v = np.zeros(self.dim, dtype=np.float32)\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        a = self.stepsize * np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * globalg\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (globalg * globalg)\n",
    "        step = -a * self.m / (np.sqrt(self.v) + self.epsilon)\n",
    "        return step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "env = gym.make(config.env_id)\n",
    "rs = np.random.RandomState()\n",
    "\n",
    "optimizer = Adam(stepsize=0.01)\n",
    "\n",
    "save_directory = \"/tmp/es_master_{}/\".format(os.getpid())\n",
    "\n",
    "mkdir_p(save_directory)\n",
    "\n",
    "# ob_stat = RunningStat(\n",
    "#     env.observation_space.shape,\n",
    "#     eps=1e-2  # eps to prevent dividing by zero at the beginning when computing mean/stdev\n",
    "# )\n",
    "\n",
    "tslimit, incr_tslimit_threshold, tslimit_incr_ratio = None, None, None\n",
    "adaptive_tslimit = False\n",
    "\n",
    "\n",
    "episodes_so_far = 0\n",
    "timesteps_so_far = 0\n",
    "tstart = time.time()\n",
    "\n",
    "task_counter = 0\n",
    "\n",
    "assert config.num_workers != 0\n",
    "\n",
    "num_jobs_per_worker = [int(config.population_size / config.num_workers)] * config.num_workers\n",
    "\n",
    "mod = config.population_size % config.num_workers\n",
    "i = 0\n",
    "while mod > 0:\n",
    "    num_jobs_per_worker[i] += 1\n",
    "    mod -= 1\n",
    "    i += 1\n",
    "    \n",
    "assert len(num_jobs_per_worker) == config.num_workers\n",
    "generation_counter = 0\n",
    "\n",
    "theta = get_flat(theta)\n",
    "\n",
    "while True:\n",
    "    print(\"----------------------GENERATION: \" + str(generation_counter) + \"------------------------------------\")\n",
    "    \n",
    "    step_tstart = time.time() \n",
    "            \n",
    "    #assert theta.dtype == np.float32\n",
    "\n",
    "    # Task counter is used to recognize false tasks from previous iterations later\n",
    "    curr_task_id = task_counter\n",
    "    task_counter += 1\n",
    "    \n",
    "    # Start workers\n",
    "    \n",
    "    workers = []\n",
    "    results = []\n",
    "    \n",
    "    pool = Pool(processes=config.num_workers)\n",
    "    \n",
    "    print(\"PID \" + str(os.getpid()) + \": \" + \"Waiting for results\")\n",
    "    for i in num_jobs_per_worker:\n",
    "        result = pool.apply_async(func=run_worker, args=(i, theta))\n",
    "        results.append(result)\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        results[i] = results[i].get()\n",
    "\n",
    "    pool.close()   \n",
    "    pool.join()  \n",
    "\n",
    "    # Pop off results for the current task\n",
    "    curr_task_results, eval_rets, eval_lens, worker_ids = [], [], [], []\n",
    "    num_results_skipped, num_episodes_popped, num_timesteps_popped, ob_count_this_batch = 0, 0, 0, 0\n",
    "   #while num_episodes_popped < config.episodes_per_batch:\n",
    "    for result in results:\n",
    "        assert isinstance(result, Result)\n",
    "        # task_id = result.task_id\n",
    "        # assert isinstance(task_id, int)\n",
    "\n",
    "        # assert (result.eval_return is None) == (result.eval_length is None)\n",
    "        # worker_ids.append(result.worker_id)\n",
    "        # \n",
    "        # if result.eval_length is not None:\n",
    "        #     # This was an eval job\n",
    "        #     episodes_so_far += 1\n",
    "        #     timesteps_so_far += result.eval_length\n",
    "        #     # Store the result only for current tasks\n",
    "        #     if task_id == curr_task_id:\n",
    "        #         eval_rets.append(result.eval_return)\n",
    "        #         eval_lens.append(result.eval_length)\n",
    "        # else:\n",
    "\n",
    "        assert (result.noise_inds_n.ndim == 1 and\n",
    "                result.returns_n2.shape == result.lengths_n2.shape == (len(result.noise_inds_n), 2))\n",
    "        assert result.returns_n2.dtype == np.float32\n",
    "        \n",
    "        # Update counts\n",
    "        result_num_eps = result.lengths_n2.size\n",
    "        result_num_timesteps = result.lengths_n2.sum()\n",
    "        episodes_so_far += result_num_eps\n",
    "        timesteps_so_far += result_num_timesteps\n",
    "        # Store results only for current tasks\n",
    "        curr_task_results.append(result)\n",
    "        num_episodes_popped += result_num_eps\n",
    "        num_timesteps_popped += result_num_timesteps\n",
    "        # Update ob stats\n",
    "        # if policy.needs_ob_stat and result.ob_count > 0:\n",
    "        #     ob_stat.increment(result.ob_sum, result.ob_sumsq, result.ob_count)\n",
    "        #     ob_count_this_batch += result.ob_count\n",
    "\n",
    "\n",
    "    # Compute skip fraction\n",
    "    #frac_results_skipped = num_results_skipped / (num_results_skipped + len(curr_task_results))\n",
    "    # if num_results_skipped > 0:\n",
    "    #     logger.warning('Skipped {} out of date results ({:.2f}%)'.format(\n",
    "    #         num_results_skipped, 100. * frac_results_skipped))\n",
    "    \n",
    "    print(\"Gathered results\")\n",
    "\n",
    "    # Assemble results\n",
    "    noise_inds_n = np.concatenate([r.noise_inds_n for r in curr_task_results])\n",
    "    returns_n2 = np.concatenate([r.returns_n2 for r in curr_task_results])\n",
    "    lengths_n2 = np.concatenate([r.lengths_n2 for r in curr_task_results])\n",
    "    assert noise_inds_n.shape[0] == returns_n2.shape[0] == lengths_n2.shape[0]\n",
    "    \n",
    "    # Process returns\n",
    "    if config.return_proc_mode == 'centered_rank':\n",
    "        proc_returns_n2 = compute_centered_ranks(returns_n2)\n",
    "    else:\n",
    "        proc_returns_n2 = returns_n2\n",
    "    \n",
    "    g, count = batched_weighted_sum(\n",
    "        proc_returns_n2[:, 0] - proc_returns_n2[:, 1],\n",
    "        (noise.get(idx, num_params) for idx in noise_inds_n),\n",
    "        batch_size=500\n",
    "    )\n",
    "    \n",
    "    g /= returns_n2.size\n",
    "    \n",
    "    #g /= config.noise_stdev\n",
    "    #g *= config.learning_rate\n",
    "    \n",
    "    assert g.shape == (num_params,) and g.dtype == np.float32 and count == len(noise_inds_n)\n",
    "    #update_ratio = optimizer.update(-g + config.l2coeff * theta)\n",
    "    #update_ratio = optimizer.update(config.l2coeff * g)\n",
    "\n",
    "    # UPDATE\n",
    "\n",
    "    theta, _ = optimizer.update(-g + config.learning_rate * theta)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #set_from_flat(master_model, theta + g)\n",
    "    #set_from_flat(master_model, theta + g)\n",
    "   \n",
    "    #theta += g\n",
    "\n",
    "    # Update ob stat (we're never running the policy in the master, but we might be snapshotting the policy)\n",
    "    # if policy.needs_ob_stat:\n",
    "    #     policy.set_ob_stat(ob_stat.mean, ob_stat.std)\n",
    "\n",
    "    # Update number of steps to take\n",
    "    # if adaptive_tslimit and (lengths_n2 == tslimit).mean() >= incr_tslimit_threshold:\n",
    "    #     old_tslimit = tslimit\n",
    "    #     tslimit = int(tslimit_incr_ratio * tslimit)\n",
    "    #     logger.info('Increased timestep limit from {} to {}'.format(old_tslimit, tslimit))\n",
    "\n",
    "    step_tend = time.time()\n",
    "    # tlogger.record_tabular(\"EpRewMean\", returns_n2.mean())\n",
    "    # tlogger.record_tabular(\"EpRewStd\", returns_n2.std())\n",
    "    # tlogger.record_tabular(\"EpLenMean\", lengths_n2.mean())\n",
    "    # \n",
    "    # tlogger.record_tabular(\"EvalEpRewMean\", np.nan if not eval_rets else np.mean(eval_rets))\n",
    "    # tlogger.record_tabular(\"EvalEpRewStd\", np.nan if not eval_rets else np.std(eval_rets))\n",
    "    # tlogger.record_tabular(\"EvalEpLenMean\", np.nan if not eval_rets else np.mean(eval_lens))\n",
    "    # tlogger.record_tabular(\"EvalPopRank\", np.nan if not eval_rets else (\n",
    "    #     np.searchsorted(np.sort(returns_n2.ravel()), eval_rets).mean() / returns_n2.size))\n",
    "    # tlogger.record_tabular(\"EvalEpCount\", len(eval_rets))\n",
    "    # \n",
    "    # tlogger.record_tabular(\"Norm\", float(np.square(policy.get_trainable_flat()).sum()))\n",
    "    # tlogger.record_tabular(\"GradNorm\", float(np.square(g).sum()))\n",
    "    # tlogger.record_tabular(\"UpdateRatio\", float(update_ratio))\n",
    "    # \n",
    "    # tlogger.record_tabular(\"EpisodesThisIter\", lengths_n2.size)\n",
    "    # tlogger.record_tabular(\"EpisodesSoFar\", episodes_so_far)\n",
    "    # tlogger.record_tabular(\"TimestepsThisIter\", lengths_n2.sum())\n",
    "    # tlogger.record_tabular(\"TimestepsSoFar\", timesteps_so_far)\n",
    "    # \n",
    "    # num_unique_workers = len(set(worker_ids))\n",
    "    # tlogger.record_tabular(\"UniqueWorkers\", num_unique_workers)\n",
    "    # tlogger.record_tabular(\"UniqueWorkersFrac\", num_unique_workers / len(worker_ids))\n",
    "    # tlogger.record_tabular(\"ResultsSkippedFrac\", frac_results_skipped)\n",
    "    # tlogger.record_tabular(\"ObCount\", ob_count_this_batch)\n",
    "    # \n",
    "    # tlogger.record_tabular(\"TimeElapsedThisIter\", step_tend - step_tstart)\n",
    "    # tlogger.record_tabular(\"TimeElapsed\", step_tend - tstart)\n",
    "    # tlogger.dump_tabular()\n",
    "\n",
    "    if config.snapshot_freq != 0 and generation_counter % config.snapshot_freq == 0:\n",
    "        from multiprocessing import Process\n",
    "        \n",
    "        p = Process(target=create_model, args=(theta, \n",
    "                                               config.env_id + \"_Generation_\" + str(generation_counter), \n",
    "                                               save_directory + 'snapshot_{:05d}'.format(generation_counter) + \".h5\"))\n",
    "        p.start()\n",
    "        p.join()\n",
    "        \n",
    "        print(\"Saved model in generation {}\".format(generation_counter))\n",
    "            \n",
    "    generation_counter+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "trained_model = create_model()\n",
    "trained_model.load_weights(save_directory + \"snapshot_0.h5\")\n",
    "\n",
    "\n",
    "import gym, roboschool\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "def rollout_rend(env, model, *, render=False, timestep_limit=None, save_obs=False, random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "    \n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    t = 0\n",
    "    if save_obs:\n",
    "        obs = []\n",
    "    ob = env.reset()\n",
    "    for _ in range(timestep_limit):\n",
    "        ac = act(ob[None], model, random_stream=random_stream)[0]\n",
    "        if save_obs:\n",
    "            obs.append(ob)\n",
    "        ob, rew, done, _ = env.step(ac)\n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "        if render:\n",
    "            img.set_data(env.render(mode='rgb_array'))\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        if done:\n",
    "            break\n",
    "    rews = np.array(rews, dtype=np.float32)\n",
    "    if save_obs:\n",
    "        return rews, t, np.array(obs)\n",
    "    return rews, t\n",
    "\n",
    "#rollout_rend(env, trained_model, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
