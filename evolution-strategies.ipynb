{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIT License\n",
    "\n",
    "Copyright (c) 2016 OpenAI (http://openai.com)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in\n",
    "all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using evolution strategies to train Roboschool Environments\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook is based on the [paper](https://arxiv.org/abs/1703.03864), [blog article](https://openai.com/blog/evolution-strategies/) and [implementation](https://github.com/openai/evolution-strategies-starter) of OpenAI on the topic of using an evolution strategy algorithm for a typical reinforcement learning task. \n",
    "\n",
    "My implementation summarizes their implementation, by simplifying, refactoring and organizing the code into this Jupyter notebook which can be used to test the algorithm. One can tweak the hyperparameters, change the environment which shall be trained or even expand the implementation to support for example Atari environments.\n",
    "\n",
    "I recommend reading the paper or at least the article before trying out the notebook. Also depending on the environment the training can be very computationally intense (for example training the Humanoid), so if you want to try out the harder ones I recommend using a highly parallelizable machine, i.e. a machine with a high number of cores/threads.\n",
    "\n",
    "## Algorithm overview\n",
    "\n",
    "This section gives a brief overview over the algorithm. First of all we need to define what this implementation is going to do. The Roboschool is a group of environments in the [OpenAi Gym](https://gym.openai.com/), a program to test the behavior of machine learning algorithms on _real world_ problems. In our case, we want to train different robotic environments using an evolutionary algorithm which belongs to the class of natural evolution strategies. We therefore define a neural net with a configurable number of hidden layers, where the input dimension equals the observation space of the environment and the dimension of the output layer equals the dimension of the action space of the environment. This neural net is also called policy or in this implementation also referred to as a model. Therefore we train our policy to output the best possible action sequence given an observation sequence. Now, how do we train this policy? Training an evolutionary strategy consists of a cycle which is repeated over and over. First, an initial weight vector is randomly generated. In our context this weight vector equals to the weights of our policy. Then we perturb the vector with gaussian noise. The amount of perturbations is called the population size. What we now have is a population of slightly different weight vectors compared with the weight vector we started. Each one of these vectors will then be evaluated by first updating our policy with the weights and then run the environment using the policy. When this is done for the whole population we calculate a gradient ascent step in the direction of steepest ascent. In our case, where we are dealing with natural evolution strategies, we calculate the step with the natural gradient. This is done by approximating this gradient using Monte Carlo estimates.\n",
    "\n",
    "So lets say we have our initial weight vector $\\theta$, a population size $n$, random perturbations $\\epsilon_i$, $0 \\leq i \\leq n$, learning rate $\\alpha$, noise standard deviation $\\sigma$ and a fitness Function $F(\\cdot)$. We then calculate the resulting weight vector like this:\n",
    "$\\theta_{t+1} = \\theta_{t} + \\alpha \\frac{1}{n \\sigma} \\sum \\limits_{i=0}^n F(\\theta_{t} + \\epsilon_i)$\n",
    "\n",
    "\n",
    "This gives us the weight vector for the next cycle which we will then, again, perturb a number of times (depending on the population size). A cycle in the context of evolutionary strategies is called a generation.\n",
    "\n",
    "One might ask himself now what this fitness function is in the context of robotic simulations. When initializing such an environment one can call the `step` function on the environment with an array in the shape of the action space (in our case this would be the output of the policy). The environment then evaluates the provided action based on the current observation and other parameters in the environment and outputs a reward. This is done for either a fixed number of timesteps (some environments have a maximum of timesteps defined) or stops, when the action resulted in a state where the environment is `done`, for example when the `Ant` environment touches the surface with its torso. The rewards get summed up for every timestep which forms the reward for one action.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before starting any computation we need to configure the program and define some methods and objects we will use later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Note that TensorFlow does not get imported here. We will only import it inside of a function which runs in another process. This is due to the fact that when importing TensorFlow a session is created in the background which will interefere with our models which we run in subprocesses. When importing the package only inside a function and then running these functions inside of subprocesses, every process has its own TensorFlow session and they therefore don't interfere with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import errno\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import ctypes\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "import gym, roboschool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging and save directory\n",
    "\n",
    "For evaluating the trained data we need to define a directory where we want to store the trained policies, as well as the log file to record the results of every generation (Depending on your disk space you may not want to save every model).\n",
    "\n",
    "If you want to change the location change the variable `save_directory` to a directory where the user which runs this notebook has write permissions. If it does not exist the program will create it. The default location is the /tmp/es_xx directory where xx is the process id of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "save_directory = \"/tmp/\" + \"/es_{}/\".format(os.getpid())\n",
    "mkdir_p(save_directory)\n",
    "\n",
    "logger = logging.getLogger('main_logger')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "fh = logging.FileHandler(save_directory + 'log.txt')\n",
    "fh.setLevel(logging.INFO)\n",
    "fh.setFormatter(logging.Formatter('%(asctime)s %(message)s', ''))\n",
    "\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configuration & Result Classes\n",
    "\n",
    "Using a `namedtuple` allows use to quickly create a small class with different attributes, which is ideal for quickly accessing different attributes during training.\n",
    "\n",
    "#### Config Class\n",
    "\n",
    "The Config class defines our general configuration of the program. The following table explains what each attribute does:\n",
    "\n",
    "\n",
    "| Attribute             | Explanation   |\n",
    "| :---------------------|:--------------|\n",
    "| `env_id`              | A string representing an environment of the Roboschool, e.g. `\"RoboschoolAnt-v1\"`|\n",
    "| `population_size`     | The size of the population of one generation    |\n",
    "| `num_workers`         | The number of workers doing computation in parallel, for maximum performance the default is `os.cpu_cores()`|\n",
    "| `learning_rate`       | A floating point number which dictates how _strong_ the calculated gradient influences the next generation\n",
    "| `noise_stdev`         | The standard deviation used for the noise\n",
    "| `snapshot_freq`       | An integer which tells in which frequency the weights of the model shall be saved, e.g. a snapshot frequency of 10 would save the weights of the model every 10 generations\n",
    "| `return_proc_mode`    | The processing mode of the gathered returns. Only used when fitness shaping is active. \n",
    "| `timesteps_per_gen` | Alternative exit condition for a generation, i.e. stop after x timesteps, currently not used\n",
    "| `calc_obstat_prob`    | The probability of calculating the new mean and standard deviation of the observation space\n",
    "| `eval_prob`           | The probability of inserting an evaluation result, i.e. calculating the fitness without adding noise. This is useful to have insight on the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Config = namedtuple('Config', [\n",
    "    'env_id',\n",
    "    'population_size',\n",
    "    'num_workers',\n",
    "    'learning_rate',\n",
    "    'noise_stdev',\n",
    "    'snapshot_freq',\n",
    "    'return_proc_mode',\n",
    "    'calc_obstat_prob',\n",
    "    'l2coeff',\n",
    "    'eval_prob'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Optimizations = namedtuple('Optimizations', [\n",
    "    'mirrored_sampling',\n",
    "    'fitness_shaping',\n",
    "    'weight_decay', # TODO\n",
    "    'discretize_actions', # TODO custom bins\n",
    "    'neural_network_optimizer',\n",
    "    'observation_normalization'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Structure class\n",
    "\n",
    "| Attribute         | Explanation   |\n",
    "| :---------------- |:--------------|\n",
    "| `ac_noise_std`    | Standard deviation of noise that is added to the input (action) to make trained model more robust|\n",
    "| `ac_bins`         | When discretizing actions use this to specify how the bins are structured.       |\n",
    "| `hidden_dims`     | A list with the hidden dimensions. Each entry is one layer with the number representing the number of neurons in that layer              |\n",
    "| `nonlin_type`     |  The activation function used for every layer (except ObservationNormalizationLayer and Output, more on that later)             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ModelStructure = namedtuple('ModelStructure', [\n",
    "    'ac_noise_std',\n",
    "    'ac_bins',\n",
    "    'hidden_dims',\n",
    "    'nonlin_type',\n",
    "    'nn_optimizer',\n",
    "    'nn_optimizer_args'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result class\n",
    "\n",
    "| Attribute             | Explanation   |\n",
    "| :---------------------|:--------------|\n",
    "| `noise_inds`        | A numpy array with the indices of the used noise.|\n",
    "| `returns`        | A numpy array with the rewards. When mirrored sampling is used this list is two dimensional.| |`signreturns` | The sum of the signs of the rewards. When mirrored sampling is used this list is two dimensional. | |`lengths` | A numpy array with the sum of the timesteps. When mirrored sampling is used this list is two dimensional. |\n",
    "| `eval_returns` | np.nan if no evaluations have been done, otherwise a numpy array with evaluation rewards. |\n",
    "| `eval_lengths` |np.nan if no evaluations have been done, otherwise a numpy array with evaluation timesteps. |\n",
    "| `ob_sum` | If observation normalization is used this contains the sum of the tracked observations. |\n",
    "| `ob_sumsq` | If observation normalization is used this contains the squared sum of the tracked observations. |\n",
    "| `ob_count` | If observation normalization is used this contains number of tracked observations. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Result = namedtuple('Result', [\n",
    "    'noise_inds','returns', 'signreturns', 'lengths',\n",
    "    'eval_returns', 'eval_lengths',\n",
    "    'ob_sum', 'ob_sumsq', 'ob_count'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Config\n",
    "\n",
    "This is the base configuration of the program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    env_id=\"RoboschoolAnt-v1\",\n",
    "    population_size=20,\n",
    "    num_workers=os.cpu_count(),\n",
    "    learning_rate=0.001,\n",
    "    noise_stdev=0.02,\n",
    "    snapshot_freq=1,\n",
    "    return_proc_mode=\"centered_rank\",\n",
    "    calc_obstat_prob=0.01,\n",
    "    l2coeff=0.005,\n",
    "    eval_prob=0.003\n",
    ")\n",
    "\n",
    "assert config.eval_prob > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(config.env_id)\n",
    "\n",
    "ob_space= env.observation_space\n",
    "ac_space = env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Keras as Model\n",
    "\n",
    "Original implementation used hand written dense layers and tensorflow operations. I use a Keras model and their\n",
    "functional API to create the net. In testing the two version differ in 0.x float scope. Something to worry about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_structure = ModelStructure(\n",
    "    ac_noise_std=0.01,\n",
    "    ac_bins='uniform:10',\n",
    "    hidden_dims=[256, 256],\n",
    "    nonlin_type='tanh',\n",
    "    nn_optimizer='adam',\n",
    "    nn_optimizer_args={\n",
    "        'stepsize': 0.01\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "optimizations = Optimizations(\n",
    "    mirrored_sampling=True,\n",
    "    fitness_shaping=True,\n",
    "    weight_decay=True,\n",
    "    discretize_actions=False,\n",
    "    neural_network_optimizer=True,\n",
    "    observation_normalization=True\n",
    ")\n",
    "\n",
    "if optimizations.observation_normalization:\n",
    "    assert config.calc_obstat_prob > 0\n",
    "    \n",
    "# TODO config and optimizations asserts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Keras clearin backend to support multiprocessing\n",
    "\n",
    "$\\text{out } = \\frac{\\sigma}{\\sqrt{\\sum \\limits_{i \\in \\text{out}} i^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(initial_weights=None, model_name=\"model\", save_path=None, ob_mean=None, ob_std=None):\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    class Normc_initializer(tf.keras.initializers.Initializer):\n",
    "        \"\"\"\n",
    "        Create a TensorFlow constant with random numbers normed in the given shape.\n",
    "        :param std:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        def __init__(self, std=1.0):\n",
    "            self.std=std\n",
    "\n",
    "        def __call__(self, shape, dtype=None, partition_info=None):#pylint: disable=W0613\n",
    "            out = np.random.randn(*shape).astype(np.float32)\n",
    "            out *= self.std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            return tf.constant(out)\n",
    "    \n",
    "    class ObservationNormalizationLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, ob_mean, ob_std, **kwargs):\n",
    "            self.ob_mean = ob_mean\n",
    "            self.ob_std = ob_std\n",
    "            super(ObservationNormalizationLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, input):\n",
    "            return tf.clip_by_value((input - self.ob_mean) / self.ob_std, -5.0, 5.0)\n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(ObservationNormalizationLayer, self).get_config()\n",
    "            base_config['ob_mean'] = self.ob_mean\n",
    "            base_config['ob_std'] = self.ob_std\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "    \n",
    "    nonlin = tf.nn.tanh\n",
    "    \n",
    "    if model_structure.nonlin_type == 'relu':\n",
    "        nonlin = tf.nn.relu\n",
    "    elif model_structure.nonlin_type == 'lrelu':\n",
    "        nonlin = tf.nn.leaky_relu\n",
    "    elif model_structure.nonlin_type == 'elu':\n",
    "        nonlin = tf.nn.leaky_relu\n",
    "\n",
    "    # Policy network\n",
    "    input_layer = x = tf.keras.Input(ob_space.shape, dtype=tf.float32)\n",
    "\n",
    "    if ob_mean is not None and ob_std is not None and optimizations.observation_normalization:\n",
    "        if ob_std.all() != 0:\n",
    "            x = ObservationNormalizationLayer(ob_mean, ob_std)(x)\n",
    "                \n",
    "    for hd in model_structure.hidden_dims:\n",
    "        x = tf.keras.layers.Dense(\n",
    "            hd, activation=nonlin,\n",
    "            kernel_initializer=Normc_initializer(std=1.0),\n",
    "            bias_initializer=tf.initializers.zeros())(x)\n",
    "\n",
    "    # Map to action\n",
    "    adim, ahigh, alow = ac_space.shape[0], ac_space.high, ac_space.low        \n",
    "    \n",
    "    a = tf.keras.layers.Dense(\n",
    "        adim,\n",
    "        kernel_initializer=Normc_initializer(std=1.0),\n",
    "        bias_initializer=tf.initializers.zeros())(x)\n",
    "    \n",
    "    if optimizations.discretize_actions:\n",
    "        # discretize, if else for uniform/custom\n",
    "        ac_bin_mode, ac_bin_arg = model_structure.ac_bins.split(':')\n",
    "        if ac_bin_mode == 'uniform':\n",
    "            num_ac_bins = int(ac_bin_arg)\n",
    "            assert num_ac_bins > 1\n",
    "            ac_range_1a = (ahigh - alow)[None, :]\n",
    "            # Transforms the interval from the normal Dense output layer to the interval [0, num_ac_bins-1]\n",
    "            a = tf.keras.layers.Lambda(lambda a: 1. / (num_ac_bins - 1.) * a * ac_range_1a + alow[None, :])(a)\n",
    "        elif ac_bin_mode == 'custom':\n",
    "            #Custom, TODO\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=a, name=model_name)\n",
    "    \n",
    "    if initial_weights is not None:\n",
    "        set_from_flat(model, initial_weights)\n",
    "        \n",
    "    if save_path:\n",
    "        model.save(save_path)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def act(ob, model, random_stream=None):   \n",
    "    action = model.predict(ob)\n",
    "    \n",
    "    # TODO why randomstream? Better generalization?\n",
    "    if random_stream is not None and model_structure.ac_noise_std != 0:\n",
    "        action += random_stream.randn(*action.shape) * model_structure.ac_noise_std\n",
    "    return action\n",
    "\n",
    "def get_initial_weights():\n",
    "    model = create_model()\n",
    "    \n",
    "    # Print out the model\n",
    "    model.summary()\n",
    "    \n",
    "    return model.get_weights()\n",
    "\n",
    "with multiprocessing.Pool(1) as pool:\n",
    "    theta = pool.apply(func=get_initial_weights)\n",
    "\n",
    "num_params = sum(np.prod(v.shape) for v in theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Using Adam Optimizer\n",
    "\n",
    "Defining it manually since with Keras you have to define a loss function and use training set, etc. Manually seems\n",
    "easier for now.\n",
    "Completely copied from OpenAI, except for not using the policy variable but providing theta directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self):\n",
    "        self.dim = num_params\n",
    "        self.t = 0\n",
    "\n",
    "    def update(self, theta, globalg):\n",
    "        self.t += 1\n",
    "        step = self._compute_step(globalg)\n",
    "        ratio = np.linalg.norm(step) / np.linalg.norm(theta)\n",
    "        theta_new = theta + step\n",
    "        return theta_new, ratio\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, stepsize, momentum=0.9):\n",
    "        Optimizer.__init__(self)\n",
    "        self.v = np.zeros(self.dim, dtype=np.float32)\n",
    "        self.stepsize, self.momentum = stepsize, momentum\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        self.v = self.momentum * self.v + (1. - self.momentum) * globalg\n",
    "        step = -self.stepsize * self.v\n",
    "        return step\n",
    "        \n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, stepsize, beta1=0.9, beta2=0.999, epsilon=1e-08):\n",
    "        Optimizer.__init__(self)\n",
    "        self.stepsize = stepsize\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = np.zeros(self.dim, dtype=np.float32)\n",
    "        self.v = np.zeros(self.dim, dtype=np.float32)\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        a = self.stepsize * np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * globalg\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (globalg * globalg)\n",
    "        step = -a * self.m / (np.sqrt(self.v) + self.epsilon)\n",
    "        return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if optimizations.neural_network_optimizer:\n",
    "    if model_structure.nn_optimizer == 'adam':\n",
    "        optimizer = Adam(**model_structure.nn_optimizer_args)\n",
    "    elif model_structure.nn_optimizer == 'sgd':\n",
    "        optimizer = SGD(**model_structure.nn_optimizer_args)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Shared Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SharedNoiseTable(object):\n",
    "    def __init__(self):\n",
    "        seed = 123\n",
    "        count = 250000000  # 1 gigabyte of 32-bit numbers. Will actually sample 2 gigabytes below.\n",
    "        logger.info('Sampling {} random numbers with seed {}'.format(count, seed))\n",
    "\n",
    "        # Instantiate an array of C float datatype with size count\n",
    "        self._shared_mem = multiprocessing.Array(ctypes.c_float, count)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        self.noise = np.ctypeslib.as_array(self._shared_mem.get_obj())\n",
    "        assert self.noise.dtype == np.float32\n",
    "        self.noise[:] = np.random.RandomState(seed).randn(count)  # 64-bit to 32-bit conversion here\n",
    "        logger.info('Sampled {} bytes'.format(self.noise.size * 4))\n",
    "\n",
    "    def get(self, i, dim):\n",
    "        return self.noise[i:i + dim]\n",
    "\n",
    "    def sample_index(self, stream, dim):\n",
    "        return stream.randint(0, len(self.noise) - dim + 1)\n",
    "\n",
    "noise = SharedNoiseTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_flat(theta):\n",
    "     return np.concatenate([np.reshape(v, [-1]) for v in theta], 0)\n",
    "\n",
    "def set_from_flat(model, theta):\n",
    "    old_theta = model.get_weights()\n",
    "    shapes = [v.shape for v in old_theta]\n",
    "    total_size = theta.size\n",
    "    \n",
    "    start = 0\n",
    "    reshapes = []\n",
    "    \n",
    "    for (shape, v) in zip(shapes, theta):\n",
    "        size = int(np.prod(shape))\n",
    "        reshapes.append(np.reshape(theta[start:start+size], shape))\n",
    "        start += size\n",
    "    \n",
    "    assert start == total_size\n",
    "    model.set_weights(reshapes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set from flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rollout TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rollout(env, \n",
    "            model, \n",
    "            *, \n",
    "            render=False, \n",
    "            timestep_limit=None, \n",
    "            save_obs=False, \n",
    "            random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "    \n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    t = 0\n",
    "    if save_obs:\n",
    "        obs = []\n",
    "    ob = env.reset()\n",
    "    for _ in range(timestep_limit):\n",
    "        ac = act(ob[None], model, random_stream=random_stream)[0]\n",
    "        if save_obs:\n",
    "            obs.append(ob)\n",
    "        ob, rew, done, _ = env.step(ac)\n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "        if done:\n",
    "            break\n",
    "    rews = np.array(rews, dtype=np.float32)\n",
    "    if save_obs:\n",
    "        return rews, t, np.array(obs)\n",
    "    return rews, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class RunningStat(object):\n",
    "    def __init__(self, shape, eps):\n",
    "        self.sum = np.zeros(shape, dtype=np.float32)\n",
    "        self.sumsq = np.full(shape, eps, dtype=np.float32)\n",
    "        self.count = eps\n",
    "\n",
    "    def increment(self, s, ssq, c):\n",
    "        self.sum += s\n",
    "        self.sumsq += ssq\n",
    "        self.count += c\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.sum / self.count\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(np.maximum(self.sumsq / self.count - np.square(self.mean), 1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Worker method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rollout_and_update_ob_stat(env, model, rs, task_ob_stat):\n",
    "    if optimizations.observation_normalization and config.calc_obstat_prob != 0 and rs.rand() < config.calc_obstat_prob:\n",
    "        rollout_rews, rollout_len, obs = rollout(\n",
    "            env, model, save_obs=True, random_stream=rs)\n",
    "        task_ob_stat.increment(obs.sum(axis=0), np.square(obs).sum(axis=0), len(obs))\n",
    "    else:\n",
    "        rollout_rews, rollout_len = rollout(env, model, random_stream=rs)\n",
    "    return rollout_rews, rollout_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_worker(num_jobs, theta, ob_mean=None, ob_std=None): #min_task_runtime=.2):\n",
    "\n",
    "    print(\"PID \" + str(os.getpid()) + \": \" + \"Started worker with \" + str(num_jobs) + \"Jobs\")\n",
    "\n",
    "    assert isinstance(noise, SharedNoiseTable)\n",
    "\n",
    "    # Setup\n",
    "    # Create a new gym environment object because each worker needs its own one\n",
    "    env = gym.make(config.env_id)\n",
    "    \n",
    "    # Initialize the model with the supplied weights 'theta' to calcualate based on the current generation\n",
    "    model = create_model(initial_weights=theta, model_name=str(os.getpid()), ob_mean=ob_mean, ob_std=ob_std)\n",
    "    \n",
    "    # Random stream used for adding noise to the actions as well as deciding if the observation statistics shall be\n",
    "    # updated\n",
    "    rs = np.random.RandomState()\n",
    "    \n",
    "    task_ob_stat = RunningStat(env.observation_space.shape, eps=0.)  # eps=0 because we're incrementing only\n",
    "    noise_inds, returns, signreturns, lengths, eval_returns, eval_lengths = [], [], [], [], [], []\n",
    "\n",
    "    assert optimizations.observation_normalization == (config.calc_obstat_prob != 0)\n",
    "    \n",
    "\n",
    "    i = 0\n",
    "    while i < num_jobs:\n",
    "\n",
    "        if rs.rand() < config.eval_prob:\n",
    "            # Evaluation sample\n",
    "            set_from_flat(model, theta)\n",
    "            eval_rews, eval_length = rollout(env, model)\n",
    "            eval_returns.append(eval_rews.sum())\n",
    "            eval_lengths.append(eval_length)\n",
    "        \n",
    "        # Rollouts with noise\n",
    "        \n",
    "        # Noise sample\n",
    "        noise_idx = noise.sample_index(rs, num_params)\n",
    "        epsilon = config.noise_stdev * noise.get(noise_idx, num_params)\n",
    "\n",
    "        # Evaluate the sampled noise\n",
    "        set_from_flat(model, theta + epsilon)\n",
    "        rews_pos, len_pos = rollout_and_update_ob_stat(env, model, rs=rs, task_ob_stat=task_ob_stat)\n",
    "        \n",
    "        # Mirrored sampling also evaluates the noise by subtracting it\n",
    "        if optimizations.mirrored_sampling:\n",
    "            set_from_flat(model, theta - epsilon)\n",
    "            rews_neg, len_neg = rollout_and_update_ob_stat(env, model, rs=rs, task_ob_stat=task_ob_stat)\n",
    "        \n",
    "        # Gather results\n",
    "        noise_inds.append(noise_idx)\n",
    "        returns.append([rews_pos.sum()])\n",
    "        signreturns.append([np.sign(rews_pos).sum()])\n",
    "        lengths.append([len_pos])\n",
    "        \n",
    "        if optimizations.mirrored_sampling:\n",
    "            returns[-1].append(rews_neg.sum())\n",
    "            signreturns[-1].append(np.sign(rews_neg).sum())\n",
    "            lengths[-1].append(len_neg)\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "    result = Result(\n",
    "        noise_inds=np.array(noise_inds),\n",
    "        returns=np.array(returns, dtype=np.float32),\n",
    "        signreturns=np.array(signreturns, dtype=np.float32),\n",
    "        lengths=np.array(lengths, dtype=np.int32),\n",
    "        eval_returns=np.array(eval_returns, dtype=np.float32),\n",
    "        eval_lengths=np.array(eval_lengths, dtype=np.int32),\n",
    "        ob_sum=None if task_ob_stat.count == 0 else task_ob_stat.sum,\n",
    "        ob_sumsq=None if task_ob_stat.count == 0 else task_ob_stat.sumsq,\n",
    "        ob_count=task_ob_stat.count\n",
    "    )\n",
    "    \n",
    "    print(\"PID \" + str(os.getpid()) + \": \" + \"Returned result\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def itergroups(items, group_size):\n",
    "    assert group_size >= 1\n",
    "    group = []\n",
    "    for x in items:\n",
    "        group.append(x)\n",
    "        if len(group) == group_size:\n",
    "            yield tuple(group)\n",
    "            del group[:]\n",
    "    if group:\n",
    "        yield tuple(group)\n",
    "        \n",
    "def batched_weighted_sum(weights, vecs, batch_size):\n",
    "    total = 0.\n",
    "    num_items_summed = 0\n",
    "    for batch_weights, batch_vecs in zip(itergroups(weights, batch_size), itergroups(vecs, batch_size)):\n",
    "        assert len(batch_weights) == len(batch_vecs) <= batch_size\n",
    "        total += np.dot(np.asarray(batch_weights, dtype=np.float32), np.asarray(batch_vecs, dtype=np.float32))\n",
    "        num_items_summed += len(batch_weights)\n",
    "    return total, num_items_summed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Fitness shaping with a rank transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_ranks(x):\n",
    "    \"\"\"\n",
    "    Returns ranks in [0, len(x))\n",
    "    Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].\n",
    "    \"\"\"\n",
    "    assert x.ndim == 1\n",
    "    ranks = np.empty(len(x), dtype=int)\n",
    "    ranks[x.argsort()] = np.arange(len(x))\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def compute_centered_ranks(x):\n",
    "    y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rs = np.random.RandomState()\n",
    "\n",
    "if optimizations.observation_normalization:\n",
    "    ob_stat = RunningStat(\n",
    "        env.observation_space.shape,\n",
    "        eps=1e-2  # eps to prevent dividing by zero at the beginning when computing mean/stdev\n",
    "    )\n",
    "\n",
    "tslimit, incr_tslimit_threshold, tslimit_incr_ratio = None, None, None\n",
    "adaptive_tslimit = False\n",
    "\n",
    "\n",
    "episodes_so_far = 0\n",
    "timesteps_so_far = 0\n",
    "tstart = time.time()\n",
    "\n",
    "assert config.num_workers > 0\n",
    "\n",
    "num_jobs_per_worker = [int(config.population_size / config.num_workers)] * config.num_workers\n",
    "\n",
    "mod = config.population_size % config.num_workers\n",
    "i = 0\n",
    "while mod > 0:\n",
    "    num_jobs_per_worker[i] += 1\n",
    "    mod -= 1\n",
    "    i += 1\n",
    "    \n",
    "assert len(num_jobs_per_worker) == config.num_workers\n",
    "\n",
    "generations = 0\n",
    "\n",
    "theta = get_flat(theta)\n",
    "\n",
    "while True:\n",
    "    print(\"----------------------GENERATION: \" + str(generations) + \"------------------------------------\")\n",
    "    logger.info(\"Generation {}\".format(generations))\n",
    "    \n",
    "    step_tstart = time.time() \n",
    "            \n",
    "    assert theta.dtype == np.float32\n",
    "    \n",
    "    # Start workers\n",
    "    \n",
    "    workers = []\n",
    "    results = []\n",
    "    \n",
    "    with multiprocessing.Pool(processes=config.num_workers) as pool:\n",
    "    \n",
    "        print(\"PID \" + str(os.getpid()) + \": \" + \"Waiting for results\")\n",
    "        \n",
    "        # Spawns the worker without blocking\n",
    "        for i in num_jobs_per_worker:\n",
    "            results.append(pool.apply_async(func=run_worker, args=(i, theta, ob_stat.mean, ob_stat.std)))\n",
    "\n",
    "        # Blocks until all results are gathered\n",
    "        for i in range(len(results)):\n",
    "            results[i] = results[i].get()\n",
    "\n",
    "    # Pop off results for the current task\n",
    "    curr_task_results, eval_returns, eval_lengths, worker_ids = [], [], [], []\n",
    "    num_results_skipped, num_episodes_popped, num_timesteps_popped, ob_count_this_gen, eval_count = 0, 0, 0, 0, 0\n",
    "   \n",
    "    #while num_episodes_popped < config.episodes_per_batch:\n",
    "    for result in results:\n",
    "        assert isinstance(result, Result)\n",
    "\n",
    "        assert (result.eval_returns is None) == (result.eval_lengths is None)\n",
    "        # worker_ids.append(result.worker_id)\n",
    "         \n",
    "        if result.eval_lengths is not None:\n",
    "        # This was an eval job\n",
    "            #episodes_so_far += 1\n",
    "            #timesteps_so_far += result.eval_length\n",
    "            # Store the result only for current tasks\n",
    "            eval_returns.extend(result.eval_returns)\n",
    "            eval_lengths.extend(result.eval_lengths)\n",
    "            eval_count += 1\n",
    "        \n",
    "        assert result.noise_inds.ndim == 1 and result.returns.dtype == np.float32\n",
    "        \n",
    "        if optimizations.mirrored_sampling:\n",
    "            assert result.returns.shape == result.lengths.shape == (len(result.noise_inds), 2)\n",
    "        else:\n",
    "            assert result.returns.shape == result.lengths.shape == (len(result.noise_inds), 1)\n",
    "        \n",
    "        # Update counts\n",
    "        result_num_eps = result.lengths.size\n",
    "        result_num_timesteps = result.lengths.sum()\n",
    "        episodes_so_far += result_num_eps\n",
    "        timesteps_so_far += result_num_timesteps\n",
    "        # Store results only for current tasks\n",
    "        curr_task_results.append(result)\n",
    "        num_episodes_popped += result_num_eps\n",
    "        num_timesteps_popped += result_num_timesteps\n",
    "        # Update ob stats\n",
    "        if result.ob_count > 0:\n",
    "            ob_stat.increment(result.ob_sum, result.ob_sumsq, result.ob_count)\n",
    "            ob_count_this_gen += result.ob_count\n",
    "    \n",
    "    print(\"Gathered results\")\n",
    "\n",
    "    # Process evaluation\n",
    "    eval_gen_reward_mean = np.nan if eval_count == 0 else np.mean(np.array(eval_returns, dtype=np.float32))\n",
    "    eval_gen_reward_std = np.nan if eval_count == 0 else np.std(np.array(eval_returns, dtype=np.float32))\n",
    "    eval_gen_length_mean= np.nan if eval_count == 0 else np.mean(np.array(eval_lengths, dtype=np.int32))   \n",
    "    \n",
    "    # Assemble results\n",
    "    noise_inds = np.concatenate([r.noise_inds for r in curr_task_results])\n",
    "    returns = np.concatenate([r.returns for r in curr_task_results])\n",
    "    lengths = np.concatenate([r.lengths for r in curr_task_results])\n",
    "    assert noise_inds.shape[0] == returns.shape[0] == lengths.shape[0]\n",
    "    \n",
    "    # If fitness shaping is turned on rank the results\n",
    "    if optimizations.fitness_shaping:\n",
    "        if config.return_proc_mode == 'centered_rank':\n",
    "            proc_returns = compute_centered_ranks(returns)\n",
    "        # sign and centered_sign_rank are obviously only useful in combination with mirrored sampling\n",
    "        elif config.return_proc_mode == 'sign':\n",
    "            proc_returns = np.concatenate([r.signreturns for r in curr_task_results])\n",
    "        elif config.return_proc_mode == 'centered_sign_rank':\n",
    "            proc_returns = compute_centered_ranks(np.concatenate([r.signreturns for r in curr_task_results]))\n",
    "        else:\n",
    "            # Throw error to indicate the false input instead of silently pass on\n",
    "            raise NotImplementedError\n",
    "    else:\n",
    "        proc_returns = returns\n",
    "    \n",
    "    # Mirrored sampling returns a 2D numpy array therefore we need to preprocess it accordingly\n",
    "    if optimizations.mirrored_sampling:\n",
    "        # Calculates the difference between the rewards sampled with the positive and negative noise\n",
    "        proc_returns = proc_returns[:, 0] - proc_returns[:, 1]\n",
    "    else:\n",
    "        proc_returns = proc_returns.ravel()\n",
    "    \n",
    "    # Calculate the approximated gradient with a batch variant which saves time TODO saving time true?\n",
    "    g, count = batched_weighted_sum(\n",
    "        proc_returns,\n",
    "        (noise.get(idx, num_params) for idx in noise_inds),\n",
    "        batch_size=500\n",
    "    )\n",
    "    \n",
    "    assert g.shape == (num_params,) and g.dtype == np.float32 and count == len(noise_inds)\n",
    "    \n",
    "    # Update with the approximated gradient\n",
    "    g /= returns.size\n",
    "    \n",
    "    if optimizations.neural_network_optimizer:\n",
    "        theta, _ = optimizer.update(theta, -g + config.l2coeff * theta)\n",
    "    else:\n",
    "        theta += ((config.learning_rate / config.noise_stdev) * g)\n",
    "    \n",
    "    # Update number of steps to take\n",
    "    # if adaptive_tslimit and (lengths_n2 == tslimit).mean() >= incr_tslimit_threshold:\n",
    "    #     old_tslimit = tslimit\n",
    "    #     tslimit = int(tslimit_incr_ratio * tslimit)\n",
    "    #     logger.info('Increased timestep limit from {} to {}'.format(old_tslimit, tslimit))\n",
    "    \n",
    "    step_tend = time.time()\n",
    "    \n",
    "    # Print to stdout for evaluate training \n",
    "    print(\"EvalGenRewardMean\", eval_gen_reward_mean)\n",
    "    print(\"EvalGenRewardStd\", eval_gen_reward_std)\n",
    "    print(\"EvalGenLengthMean\", eval_gen_length_mean)\n",
    "    print(\"EvalGenCount\", eval_count)\n",
    "    \n",
    "    \n",
    "    logger.info(\"GenRewMean {}\".format(returns.mean()))\n",
    "    logger.info(\"GenRewStd {}\".format(returns.std()))\n",
    "    logger.info(\"GenLenMean {}\".format(lengths.mean()))\n",
    "\n",
    "    logger.info(\"EvalGenRewardMean {}\".format(eval_gen_reward_mean))\n",
    "    logger.info(\"EvalGenRewardStd {}\".format(eval_gen_reward_std))\n",
    "    logger.info(\"EvalGenLengthMean {}\".format(eval_gen_length_mean))\n",
    "    logger.info(\"EvalGenCount {}\".format(eval_count))\n",
    "    \n",
    "    logger.info(\"EpisodesThisGen {}\".format(lengths.size))\n",
    "    logger.info(\"EpisodesSoFar {}\".format(episodes_so_far))\n",
    "    logger.info(\"TimestepsThisGen {}\".format(lengths.sum()))\n",
    "    logger.info(\"TimestepsSoFar {}\".format(timesteps_so_far))\n",
    "     \n",
    "    \n",
    "    logger.info(\"UniqueWorkers {}\".format(config.num_workers))\n",
    "    logger.info(\"ObCount {}\".format(ob_count_this_gen))\n",
    "    \n",
    "    logger.info(\"TimeElapsedThisGen {}\".format(step_tend - step_tstart))\n",
    "    logger.info(\"TimeElapsed {}\".format(step_tend - tstart))\n",
    "\n",
    "    # Note that the model is created with a custom layer and custom initializer, and therefore needs these two\n",
    "    # custom classes if one wants to load a saved model\n",
    "    if config.snapshot_freq != 0 and generations % config.snapshot_freq == 0:\n",
    "        from multiprocessing import Process\n",
    "        \n",
    "        p = Process(target=create_model, args=(\n",
    "                                            theta, \n",
    "                                            config.env_id + \"_Generation_\" + str(generations), \n",
    "                                            save_directory + 'snapshot_{:05d}'.format(generations) + \".h5\",\n",
    "                                            ob_stat.mean,\n",
    "                                            ob_stat.std))\n",
    "        p.start()\n",
    "        p.join()\n",
    "        \n",
    "        print(\"Saved model in generation {}\".format(generations))\n",
    "        logger.info(\"Saved model to {}\".format(save_directory))\n",
    "            \n",
    "    generations += 1\n",
    "    \n",
    "    logger.info(\"-----------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
